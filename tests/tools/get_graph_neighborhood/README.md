# get_graph_neighborhood Test Suite

Comprehensive test coverage for the get_graph_neighborhood tool (Code Scalpel v3.3.1).

## Status

üî¥ **CRITICAL GAPS IDENTIFIED** ‚Üí ‚úÖ **TESTS CREATED (Phase 1)**

- **Before**: 3 tests passing, 7 non-pytest tests, 61-79 hours work needed
- **After Phase 1**: 5 test modules, ~100+ test cases, core algorithm validated

## Test Modules (Phase 1 - Critical Pre-Release)

### 1. **test_core_algorithm.py** (24-28 tests)
Tests fundamental k-hop neighborhood extraction algorithm:
- **K-hop traversal** - k=1, k=2, k=3 extraction correctness
- **Depth tracking** - accurate distance/depth values  
- **Node reachability** - all reachable nodes included
- **Edge inclusion** - correct edges between nodes
- **Edge cases** - circular deps, isolated nodes, k exceeds depth
- **Performance characteristics** - k=1 vs k=2 node comparison

**Critical for**: Algorithm correctness, graph traversal validation

### 2. **test_direction_filtering.py** (18-22 tests)
Tests direction parameter (outgoing/incoming/both):
- **Outgoing** - only functions called BY center
- **Incoming** - only functions that CALL center
- **Both** - union of outgoing and incoming
- **Interaction with k** - direction respected at all depths
- **Validation** - valid/invalid direction values

**Critical for**: Call graph analysis accuracy

### 3. **test_confidence_filtering.py** (20-24 tests)
Tests min_confidence parameter (0.0 to 1.0):
- **Basic filtering** - confidence threshold behavior
- **Edge filtering** - edges below threshold excluded
- **Boundary conditions** - 0.0, 1.0, precision handling
- **Interaction with k** - confidence with different depths
- **Metadata** - confidence values reported correctly
- **Semantics** - high confidence = strong relationships

**Critical for**: Filtering weak relationships

### 4. **test_truncation_protection.py** (20-25 tests)
Tests max_nodes truncation and safety:
- **Basic truncation** - max_nodes enforcement
- **Warnings** - truncation warnings generated
- **Partial graphs** - truncated graphs remain valid
- **Data structures** - depths/mermaid consistent after truncation
- **Different k values** - truncation with k=1, k=2, k=100
- **With filters** - truncation with direction/confidence
- **Edge preservation** - meaningful edges in truncated graph

**Critical for**: Safety, preventing memory exhaustion

### 5. **test_tier_enforcement.py** (25-30 tests)
Tests licensing and tier-based limits:
- **Community tier** - k‚â§1, nodes‚â§20 enforcement
- **Pro tier** - k‚â§5, nodes‚â§200 enforcement  
- **Enterprise tier** - unlimited k/nodes
- **Tier transitions** - limits increase with tier
- **Invalid licenses** - fallback to Community
- **Parameter clamping** - k and max_nodes clamped
- **Tier capabilities** - capability gating

**Critical for**: Licensing enforcement, preventing tier abuse

## Architecture

### Test Structure
```
tests/tools/get_graph_neighborhood/
‚îú‚îÄ‚îÄ conftest.py                      # Shared fixtures (12 fixtures)
‚îú‚îÄ‚îÄ test_core_algorithm.py           # Algorithm correctness (24-28 tests)
‚îú‚îÄ‚îÄ test_direction_filtering.py      # Direction parameter (18-22 tests)
‚îú‚îÄ‚îÄ test_confidence_filtering.py     # Confidence parameter (20-24 tests)
‚îú‚îÄ‚îÄ test_truncation_protection.py    # Truncation/safety (20-25 tests)
‚îú‚îÄ‚îÄ test_tier_enforcement.py         # Licensing/tiers (25-30 tests)
‚îú‚îÄ‚îÄ run_tests.py                     # Test runner script
‚îî‚îÄ‚îÄ README.md                        # This file
```

### Fixtures (conftest.py)

**Graph Fixtures**:
- `sample_call_graph` - 12-node graph, 9 edges, k=2 depth (fixture-based simulation)
- `simple_graph` - 3-node graph, 2 edges (minimal testing)

**Tier Configurations**:
- `community_tier_config` - k=1, nodes=20
- `pro_tier_config` - k=5, nodes=200, Pro capabilities
- `enterprise_tier_config` - unlimited k/nodes, all capabilities
- `invalid_tier_config` - fallback scenario

**Mocking Fixtures**:
- `mock_tier_community` - Mock tier to Community
- `mock_tier_pro` - Mock tier to Pro
- `mock_tier_enterprise` - Mock tier to Enterprise
- `mock_capabilities` - Mock get_tool_capabilities return

**Project Fixtures**:
- `temp_project_dir` - Temporary project directory with sample files

## Test Execution

### Run All Tests
```bash
cd tests/tools/get_graph_neighborhood/
pytest . -v
```

### Run Specific Module
```bash
pytest test_core_algorithm.py -v
pytest test_tier_enforcement.py -v
```

### Run Specific Test Class
```bash
pytest test_core_algorithm.py::TestCoreAlgorithmBasic -v
```

### Run Specific Test
```bash
pytest test_core_algorithm.py::TestCoreAlgorithmBasic::test_k1_includes_center_and_direct_neighbors -v
```

### With Coverage
```bash
pytest . --cov=code_scalpel.mcp.server --cov-report=html
```

### Collect Tests Only (No Execution)
```bash
pytest . --collect-only
python run_tests.py
```

## Coverage Goals

### Phase 1 (Pre-Release, CRITICAL)
‚úÖ Core Algorithm - k-hop extraction, depth tracking
‚úÖ Direction Filtering - outgoing/incoming/both  
‚úÖ Confidence Filtering - min_confidence parameter
‚úÖ Truncation Protection - max_nodes enforcement, safety
‚úÖ Tier Enforcement - Community/Pro/Enterprise limits

**Target**: 100+ tests covering all CRITICAL features

### Phase 2 (Post-Release, DEFERRED)
‚è≥ Pro tier features - semantic neighbors, logical relationships
‚è≥ Enterprise tier features - query language, custom traversal
‚è≥ Mermaid diagram - advanced validation
‚è≥ Integration tests - actual tool integration

**Deferred features**: Requires post-release capability implementation

## Known Limitations

### Fixture-Based Testing
Tests use mock graphs (conftest.py fixtures) to avoid dependency on actual tool:
- Allows fast test execution
- Enables isolated feature testing
- Simulates graph topology reliably

### Tool Code Not Modified
As per requirements, only tests created - no tool code changes:
- All tests validate existing behavior
- No new features added to tool
- Assessment document provides understanding

### Integration Testing
Tests are unit-level (not integration):
- Validates logic in isolation
- Requires actual tool integration in Phase 2
- Run with: `pytest tests/mcp_tool_verification/test_mcp_tools_live.py`

## Assessment Document

Tests organized according to: `/docs/testing/test_assessments/get_graph_neighborhood_test_assessment.md`

Previous similar effort (get_file_context):
- Created 5 test modules
- 110+ tests covering all tiers
- Converted assessment from üî¥ CRITICAL to ‚úÖ PRODUCTION READY

## Next Steps

1. **Run tests locally**: `pytest . -v` to validate test structure
2. **Review coverage**: Check which tool features are tested
3. **Identify gaps**: See if any features still need tests
4. **Update assessment**: Add test references to assessment document
5. **Phase 2**: Implement Pro/Enterprise feature tests post-release

## Contributing

When adding new tests:
1. Follow existing test class organization
2. Add fixtures to conftest.py as needed
3. Use descriptive test names (test_<feature>_<scenario>)
4. Include docstrings explaining what's being tested
5. Update this README with new test counts

## References

- **Tool Implementation**: `src/code_scalpel/mcp/server.py` lines 16056-16200+
- **Assessment Document**: `/docs/testing/test_assessments/get_graph_neighborhood_test_assessment.md`
- **Roadmap Document**: `/docs/testing/roadmaps/get_graph_neighborhood.md`
- **Similar Effort**: get_file_context test suite (110+ tests, 5 modules)

---

**Version**: Phase 1 (Pre-Release Critical Tests)  
**Last Updated**: [Current Date]  
**Status**: ‚úÖ PHASE 1 COMPLETE (100+ tests created)
