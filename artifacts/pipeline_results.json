{
  "timestamp": "2026-02-01T18:22:30.072118",
  "checks": {
    "black": {
      "status": "failed",
      "output": "--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_invisible_enforcement.py\t2026-02-01 22:08:21.273268+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_invisible_enforcement.py\t2026-02-01 23:22:54.886987+00:00\n@@ -20,13 +20,11 @@\n     max_lines_per_file: 100\n     max_total_lines: {max_total_lines}\n     max_complexity_increase: 100\n     allowed_file_patterns: [\"*.py\"]\n     forbidden_paths: [\".git/\", \"node_modules/\", \"__pycache__/\"]\n-\"\"\".format(\n-            max_total_lines=max_total_lines\n-        ),\n+\"\"\".format(max_total_lines=max_total_lines),\n         encoding=\"utf-8\",\n     )\n \n \n def _write_noop_policy_yaml(policy_dir: Path) -> None:\n--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_crypto_verify.py\t2026-02-01 22:08:21.306509+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_crypto_verify.py\t2026-02-01 23:22:54.901613+00:00\n@@ -45,20 +45,18 @@\n         policy_path = tmp_path / \".code-scalpel\"\n         policy_path.mkdir()\n \n         # Create sample policy file\n         policy_file = policy_path / \"policy.yaml\"\n-        policy_file.write_text(\n-            \"\"\"\n+        policy_file.write_text(\"\"\"\n policies:\n   - name: no_sql_injection\n     description: Prevent SQL injection\n     rule: |\n       package scalpel.security\n       deny[msg] { msg := \"SQL injection detected\" }\n-\"\"\"\n-        )\n+\"\"\")\n \n         return policy_path\n \n     @pytest.fixture\n     def secret_key(self):\n--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_policy_evaluation_enforcement.py\t2026-02-01 22:08:21.243211+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_policy_evaluation_enforcement.py\t2026-02-01 23:22:54.927549+00:00\n@@ -89,16 +89,13 @@\n     assert result[\"tool_id\"] == \"update_symbol\"\n     assert result[\"error\"] is not None\n     assert result[\"error\"][\"error_code\"] == \"forbidden\"\n \n     # Ensure file was not modified.\n-    assert (\n-        target_file.read_text(encoding=\"utf-8\")\n-        == \"\"\"def f():\n+    assert target_file.read_text(encoding=\"utf-8\") == \"\"\"def f():\n     return 1\n \"\"\"\n-    )\n \n \n @pytest.mark.skip(\n     reason=\"[20250112_TEST] Test hangs - needs cross-file reference scanning mocks\"\n )\n@@ -328,11 +325,8 @@\n     assert result[\"tool_id\"] == \"update_symbol\"\n     assert result[\"error\"] is not None\n     assert result[\"error\"][\"error_code\"] == \"forbidden\"\n \n     # Ensure file was not modified.\n-    assert (\n-        target_file.read_text(encoding=\"utf-8\")\n-        == \"\"\"def f():\n+    assert target_file.read_text(encoding=\"utf-8\") == \"\"\"def f():\n     return 1\n \"\"\"\n-    )\n--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_policy_engine_guardian.py\t2026-02-01 22:08:21.340325+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_policy_engine_guardian.py\t2026-02-01 23:22:54.987961+00:00\n@@ -12,24 +12,20 @@\n # [20251216_TEST] Cover PolicyEngine happy-path and failure-path behavior\n \n \n def _write_policy_file(tmp_path: Path, action: str = \"WARN\") -> Path:\n     policy_path = tmp_path / \"policy.yaml\"\n-    policy_path.write_text(\n-        \"\"\"\n+    policy_path.write_text(\"\"\"\n policies:\n   - name: safe-edit\n     description: Test policy\n     rule: |\n       package scalpel.security\n       deny = []\n     severity: MEDIUM\n     action: {action}\n-\"\"\".format(\n-            action=action\n-        )\n-    )\n+\"\"\".format(action=action))\n     return policy_path\n \n \n def _make_run(side_effects):\n     def _runner(args, **kwargs):\n--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_budget_enforcement.py\t2026-02-01 22:08:21.307516+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_budget_enforcement.py\t2026-02-01 23:22:54.989783+00:00\n@@ -27,13 +27,11 @@\n     max_lines_per_file: 100\n     max_total_lines: {max_total_lines}\n     max_complexity_increase: 100\n     allowed_file_patterns: [\"*.py\"]\n     forbidden_paths: [\".git/\", \"node_modules/\", \"__pycache__/\"]\n-\"\"\".format(\n-            max_total_lines=max_total_lines, max_files=max_files\n-        ),\n+\"\"\".format(max_total_lines=max_total_lines, max_files=max_files),\n         encoding=\"utf-8\",\n     )\n \n \n @pytest.mark.anyio\n@@ -142,16 +140,13 @@\n         assert result[\"tool_id\"] == \"update_symbol\"\n         assert result[\"error\"] is not None\n         assert result[\"error\"][\"error_code\"] == \"forbidden\"\n \n         # Ensure file was not modified.\n-        assert (\n-            target_file.read_text(encoding=\"utf-8\")\n-            == \"\"\"def f():\n+        assert target_file.read_text(encoding=\"utf-8\") == \"\"\"def f():\n     return 1\n \"\"\"\n-        )\n     finally:\n         # [20250112_BUGFIX] Restore original run method to avoid leaking mock to other tests\n         object.__setattr__(tool, \"run\", original_run)\n \n \n--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/integration_test_integrations_wrappers.py\t2026-02-01 22:08:21.418391+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/integration_test_integrations_wrappers.py\t2026-02-01 23:22:55.196564+00:00\n@@ -44,29 +44,25 @@\n \n \n def test_crewai_symbolic_and_security_analysis():\n     scalpel = CrewAIScalpel(cache_enabled=False)\n \n-    symbolic_result = scalpel.analyze_symbolic(\n-        \"\"\"\\\n+    symbolic_result = scalpel.analyze_symbolic(\"\"\"\\\n import math\n \n def branch(x: int) -> int:\n     if x > 0:\n         return x + 1\n     return -x\n-\"\"\"\n-    )\n+\"\"\")\n     assert symbolic_result[\"success\"] is True\n     assert symbolic_result[\"total_paths\"] >= 1\n \n-    security_result = scalpel.analyze_security(\n-        \"\"\"\\\n+    security_result = scalpel.analyze_security(\"\"\"\\\n def safe_path(value: str) -> str:\n     return value.replace(\"..\", \"\")\n-\"\"\"\n-    )\n+\"\"\")\n     assert security_result[\"success\"] is True\n     assert security_result.get(\"risk_level\") in {\"low\", \"medium\", \"high\", \"critical\"}\n \n \n def test_autogen_generate_suggestions_for_style_and_security():\n--- /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_unified_governance.py\t2026-02-01 22:08:21.443222+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_unified_governance.py\t2026-02-01 23:22:55.241811+00:00\n@@ -127,19 +127,17 @@\n \n     def test_budget_violation_detection(self, tmp_path):\n         \"\"\"Test that budget violations are detected in unified evaluation.\"\"\"\n         # Create a budget config\n         budget_config = tmp_path / \"budget.yaml\"\n-        budget_config.write_text(\n-            \"\"\"\n+        budget_config.write_text(\"\"\"\n budgets:\n   default:\n     max_files: 1\n     max_lines_per_file: 10\n     max_total_lines: 20\n-\"\"\"\n-        )\n+\"\"\")\n \n         gov = UnifiedGovernance(str(tmp_path))\n \n         # Create operation that violates budget\n         operation = BudgetOperation(\n@@ -157,19 +155,17 @@\n         assert any(v.source == ViolationSource.BUDGET for v in decision.violations)\n \n     def test_budget_within_limits_allowed(self, tmp_path):\n         \"\"\"Test that operations within budget limits are allowed.\"\"\"\n         budget_config = tmp_path / \"budget.yaml\"\n-        budget_config.write_text(\n-            \"\"\"\n+        budget_config.write_text(\"\"\"\n budgets:\n   default:\n     max_files: 5\n     max_lines_per_file: 100\n     max_total_lines: 300\n-\"\"\"\n-        )\n+\"\"\")\n \n         gov = UnifiedGovernance(str(tmp_path))\n \n         operation = BudgetOperation(\n             changes=[\n--- /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/incremental_index.py\t2026-02-01 15:55:14.488503+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/incremental_index.py\t2026-02-01 23:22:56.061344+00:00\n@@ -88,12 +88,11 @@\n         self._init_database()\n \n     def _init_database(self) -> None:\n         \"\"\"Create database schema if not exists.\"\"\"\n         with self._get_connection() as conn:\n-            conn.executescript(\n-                \"\"\"\n+            conn.executescript(\"\"\"\n                 CREATE TABLE IF NOT EXISTS schema_version (\n                     version INTEGER PRIMARY KEY\n                 );\n                 \n                 CREATE TABLE IF NOT EXISTS file_analysis (\n@@ -113,12 +112,11 @@\n                     value TEXT\n                 );\n                 \n                 CREATE INDEX IF NOT EXISTS idx_content_hash ON file_analysis(content_hash);\n                 CREATE INDEX IF NOT EXISTS idx_timestamp ON file_analysis(analysis_timestamp);\n-            \"\"\"\n-            )\n+            \"\"\")\n \n             # Check/set schema version\n             cursor = conn.execute(\"SELECT version FROM schema_version LIMIT 1\")\n             row = cursor.fetchone()\n             if row is None:\n--- /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/incremental_indexer.py\t2026-02-01 15:55:14.494653+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/incremental_indexer.py\t2026-02-01 23:22:56.117118+00:00\n@@ -121,38 +121,32 @@\n             self._init_redis()\n \n     def _init_database(self) -> None:\n         \"\"\"Initialize SQLite cache database.\"\"\"\n         with sqlite3.connect(self.db_path) as conn:\n-            conn.execute(\n-                \"\"\"\n+            conn.execute(\"\"\"\n                 CREATE TABLE IF NOT EXISTS file_hashes (\n                     file_path TEXT PRIMARY KEY,\n                     file_hash TEXT NOT NULL,\n                     mtime REAL NOT NULL,\n                     file_size INTEGER NOT NULL,\n                     indexed_at REAL NOT NULL\n                 )\n-            \"\"\"\n-            )\n-            conn.execute(\n-                \"\"\"\n+            \"\"\")\n+            conn.execute(\"\"\"\n                 CREATE TABLE IF NOT EXISTS analyses (\n                     file_path TEXT PRIMARY KEY,\n                     file_hash TEXT NOT NULL,\n                     analysis_json TEXT NOT NULL,\n                     cached_at REAL NOT NULL,\n                     ttl_seconds INTEGER NOT NULL,\n                     FOREIGN KEY(file_path) REFERENCES file_hashes(file_path)\n                 )\n-            \"\"\"\n-            )\n-            conn.execute(\n-                \"\"\"\n+            \"\"\")\n+            conn.execute(\"\"\"\n                 CREATE INDEX IF NOT EXISTS idx_file_hash ON file_hashes(file_hash)\n-            \"\"\"\n-            )\n+            \"\"\")\n             conn.commit()\n \n     def _init_redis(self) -> None:\n         \"\"\"Initialize Redis connection (Enterprise).\"\"\"\n         try:\n--- /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/project_context.py\t2026-02-01 15:55:14.504041+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/project_context.py\t2026-02-01 23:22:56.531535+00:00\n@@ -127,27 +127,24 @@\n         db_path = self.cache_dir / \"project_cache.db\"\n         self._db_conn = sqlite3.connect(str(db_path))\n         cursor = self._db_conn.cursor()\n \n         # Create tables\n-        cursor.execute(\n-            \"\"\"\n+        cursor.execute(\"\"\"\n             CREATE TABLE IF NOT EXISTS metadata (\n                 project_root TEXT PRIMARY KEY,\n                 created_at REAL,\n                 updated_at REAL,\n                 file_count INTEGER,\n                 dir_count INTEGER,\n                 total_size INTEGER,\n                 hash TEXT,\n                 language_breakdown TEXT\n             )\n-        \"\"\"\n-        )\n-\n-        cursor.execute(\n-            \"\"\"\n+        \"\"\")\n+\n+        cursor.execute(\"\"\"\n             CREATE TABLE IF NOT EXISTS files (\n                 id INTEGER PRIMARY KEY,\n                 path TEXT UNIQUE,\n                 rel_path TEXT,\n                 size INTEGER,\n@@ -156,15 +153,13 @@\n                 is_symlink INTEGER,\n                 depth INTEGER,\n                 importance_score REAL,\n                 cached_at REAL\n             )\n-        \"\"\"\n-        )\n-\n-        cursor.execute(\n-            \"\"\"\n+        \"\"\")\n+\n+        cursor.execute(\"\"\"\n             CREATE TABLE IF NOT EXISTS directories (\n                 id INTEGER PRIMARY KEY,\n                 path TEXT UNIQUE,\n                 rel_path TEXT,\n                 is_symlink INTEGER,\n@@ -172,12 +167,11 @@\n                 file_count INTEGER,\n                 dir_type TEXT,\n                 type_confidence REAL,\n                 cached_at REAL\n             )\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         self._db_conn.commit()\n \n     def _detect_directory_type(self, rel_path: str) -> DirectoryType:\n         \"\"\"Detect the type of a directory based on its path and name.\"\"\"\n--- /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/config/init_config.py\t2026-02-01 15:55:14.512864+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/config/init_config.py\t2026-02-01 23:22:58.832319+00:00\n@@ -261,21 +261,19 @@\n     # ========================================================================\n     license_dir = config_dir / \"license\"\n     license_dir.mkdir(exist_ok=True)\n \n     license_readme = license_dir / \"README.md\"\n-    license_readme.write_text(\n-        \"\"\"# Code Scalpel License Directory\n+    license_readme.write_text(\"\"\"# Code Scalpel License Directory\n \n This directory stores license keys and cached license state.\n \n - `license.jwt`: Place your Pro/Enterprise license key here.\n - `license_state.json`: Automatically generated cache of license validation results.\n \n Do not commit `license.jwt` to version control if it contains sensitive information.\n-\"\"\"\n-    )\n+\"\"\")\n     files_created.append(\"license/README.md\")\n \n     # ========================================================================\n     # [20260116_FEATURE] v3.4.0 - Claude Code Hooks Configuration\n     # ========================================================================\n--- /mnt/k/backup/Develop/code-scalpel/tests/ARCHITECT_STRESS_TEST.py\t2026-02-01 15:55:14.541929+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/ARCHITECT_STRESS_TEST.py\t2026-02-01 23:23:03.554696+00:00\n@@ -146,12 +146,11 @@\n # FINAL VERDICT\n # ============================================================================\n print(\"\\n\" + \"=\" * 80)\n print(\"THE ARCHITECT'S VERDICT\")\n print(\"=\" * 80)\n-print(\n-    \"\"\"\n+print(\"\"\"\n 1. PDG Builder (pdg_tools/builder.py): \n    \u274c NO sanitization - CRASHES on merge conflicts\n    \u274c NO fallback - ast.parse() called directly (line 82)\n    \n 2. Surgical Extractor (surgery/surgical_extractor.py):\n@@ -178,7 +177,6 @@\n - Sanitization happens without user notification\n \n It IS \"fail-fast\" in some places (surgical_extractor) but NOT others (pdg_builder).\n \n The real-world verdict: **PARTIALLY ROBUST** but **INCONSISTENT**.\n-\"\"\"\n-)\n+\"\"\")\n--- /mnt/k/backup/Develop/code-scalpel/tests/capabilities/test_resolver_ci_environment.py\t2026-02-01 15:55:14.549952+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/capabilities/test_resolver_ci_environment.py\t2026-02-01 23:23:03.626882+00:00\n@@ -28,22 +28,20 @@\n         self, clear_capabilities_cache, tmp_path\n     ):\n         \"\"\"Resolver should use CODE_SCALPEL_LIMITS_FILE override.\"\"\"\n         # Create a minimal custom limits file\n         custom_limits = tmp_path / \"custom_limits.toml\"\n-        custom_limits.write_text(\n-            \"\"\"\n+        custom_limits.write_text(\"\"\"\n [community]\n get_file_context = { available = true, max_lines = 999 }\n \n [pro]\n get_file_context = { available = true, max_lines = 1999 }\n \n [enterprise]\n get_file_context = { available = true, max_lines = 9999 }\n-\"\"\"\n-        )\n+\"\"\")\n \n         os.environ[\"CODE_SCALPEL_LIMITS_FILE\"] = str(custom_limits)\n         reload_limits_cache()\n \n         try:\n@@ -57,43 +55,39 @@\n \n     def test_resolver_caching_with_override(self, clear_capabilities_cache, tmp_path):\n         \"\"\"Resolver cache should be cleared when override changes.\"\"\"\n         # Create first custom limits file\n         limits_v1 = tmp_path / \"limits_v1.toml\"\n-        limits_v1.write_text(\n-            \"\"\"\n+        limits_v1.write_text(\"\"\"\n [community]\n get_file_context = { available = true, max_lines = 100 }\n \n [pro]\n get_file_context = { available = true, max_lines = 100 }\n \n [enterprise]\n get_file_context = { available = true, max_lines = 100 }\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Load first version\n         os.environ[\"CODE_SCALPEL_LIMITS_FILE\"] = str(limits_v1)\n         reload_limits_cache()\n         cap_v1 = get_tool_capabilities(\"get_file_context\", \"community\")\n         assert cap_v1[\"limits\"][\"max_lines\"] == 100\n \n         # Change to second version\n         limits_v2 = tmp_path / \"limits_v2.toml\"\n-        limits_v2.write_text(\n-            \"\"\"\n+        limits_v2.write_text(\"\"\"\n [community]\n get_file_context = { available = true, max_lines = 200 }\n \n [pro]\n get_file_context = { available = true, max_lines = 200 }\n \n [enterprise]\n get_file_context = { available = true, max_lines = 200 }\n-\"\"\"\n-        )\n+\"\"\")\n \n         os.environ[\"CODE_SCALPEL_LIMITS_FILE\"] = str(limits_v2)\n         reload_limits_cache()\n         cap_v2 = get_tool_capabilities(\"get_file_context\", \"community\")\n         assert cap_v2[\"limits\"][\"max_lines\"] == 200\n@@ -136,22 +130,20 @@\n     \"\"\"Test environment variable precedence in resolver.\"\"\"\n \n     def test_limits_file_override_precedence(self, clear_capabilities_cache, tmp_path):\n         \"\"\"CODE_SCALPEL_LIMITS_FILE should take precedence.\"\"\"\n         custom_limits = tmp_path / \"override_limits.toml\"\n-        custom_limits.write_text(\n-            \"\"\"\n+        custom_limits.write_text(\"\"\"\n [community]\n get_file_context = { available = true, max_lines = 12345 }\n \n [pro]\n get_file_context = { available = true, max_lines = 12345 }\n \n [enterprise]\n get_file_context = { available = true, max_lines = 12345 }\n-\"\"\"\n-        )\n+\"\"\")\n \n         os.environ[\"CODE_SCALPEL_LIMITS_FILE\"] = str(custom_limits)\n         reload_limits_cache()\n \n         try:\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_framework_imports.py\t2026-02-01 15:55:14.578225+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_framework_imports.py\t2026-02-01 23:23:04.015124+00:00\n@@ -9,19 +9,17 @@\n     reason=\"[20260117_TEST] ImportType.FRAMEWORK not implemented - feature incomplete\"\n )\n def test_django_installed_apps_detection(tmp_path: Path) -> None:\n     settings_py = tmp_path / \"settings.py\"\n     settings_py.write_text(\n-        textwrap.dedent(\n-            \"\"\"\n+        textwrap.dedent(\"\"\"\n             INSTALLED_APPS = [\n                 \"django.contrib.admin\",\n                 \"django.contrib.auth\",\n                 \"myapp\",\n             ]\n-            \"\"\"\n-        ),\n+            \"\"\"),\n         encoding=\"utf-8\",\n     )\n \n     resolver = ImportResolver(tmp_path)\n     result = resolver.build()\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_framework_imports_flask.py\t2026-02-01 15:55:14.582742+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_framework_imports_flask.py\t2026-02-01 23:23:04.033303+00:00\n@@ -9,20 +9,18 @@\n     reason=\"[20260117_TEST] ImportType.FRAMEWORK not implemented - feature incomplete\"\n )\n def test_flask_blueprint_detection(tmp_path: Path) -> None:\n     app_py = tmp_path / \"app.py\"\n     app_py.write_text(\n-        textwrap.dedent(\n-            \"\"\"\n+        textwrap.dedent(\"\"\"\n             from flask import Flask, Blueprint\n \n             bp = Blueprint(\"bp\", __name__)\n \n             app = Flask(__name__)\n             app.register_blueprint(bp)\n-            \"\"\"\n-        ),\n+            \"\"\"),\n         encoding=\"utf-8\",\n     )\n \n     resolver = ImportResolver(tmp_path)\n     result = resolver.build()\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_dependency_parser.py\t2026-02-01 15:55:14.571211+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_dependency_parser.py\t2026-02-01 23:23:04.293751+00:00\n@@ -79,17 +79,15 @@\n     \"\"\"Tests for _parse_python_deps method.\"\"\"\n \n     def test_parse_requirements_txt(self):\n         \"\"\"Test parsing requirements.txt.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n requests==2.28.0\n flask>=2.0.0\n django<4.0\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             assert \"requests\" in names\n@@ -97,18 +95,16 @@\n             assert \"django\" in names\n \n     def test_parse_requirements_with_comments(self):\n         \"\"\"Test that comments are ignored in requirements.txt.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n # This is a comment\n requests==2.28.0\n # Another comment\n flask>=2.0.0\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             assert len(names) == 2\n@@ -116,75 +112,67 @@\n             assert \"flask\" in names\n \n     def test_parse_requirements_with_flags(self):\n         \"\"\"Test that flag lines are ignored (like -r other.txt).\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n -r base.txt\n --index-url https://pypi.org/simple\n requests==2.28.0\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             assert len(names) == 1\n             assert names[0] == \"requests\"\n \n     def test_parse_requirements_empty_lines(self):\n         \"\"\"Test that empty lines are handled.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n requests==2.28.0\n \n flask>=2.0.0\n \n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             assert len(names) == 2\n \n     def test_parse_pyproject_toml_pep621(self):\n         \"\"\"Test parsing PEP 621 format in pyproject.toml.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [project]\n name = \"myproject\"\n dependencies = [\n     \"requests>=2.28.0\",\n     \"flask>=2.0.0\",\n ]\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             assert \"requests\" in names\n             assert \"flask\" in names\n \n     def test_parse_pyproject_toml_poetry(self):\n         \"\"\"Test parsing Poetry format in pyproject.toml.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [tool.poetry]\n name = \"myproject\"\n \n [tool.poetry.dependencies]\n python = \"^3.9\"\n requests = \"^2.28.0\"\n flask = \"^2.0.0\"\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             assert \"requests\" in names\n@@ -193,22 +181,18 @@\n             assert \"python\" not in [n.lower() for n in names]\n \n     def test_parse_both_pyproject_and_requirements(self):\n         \"\"\"Test that both files are parsed and deduplicated.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [project]\n dependencies = [\"requests>=2.28.0\"]\n-\"\"\"\n-            )\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+\"\"\")\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n requests==2.28.0\n flask>=2.0.0\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             names = [d[\"name\"] for d in deps]\n             # Should be deduplicated - requests only once\n@@ -216,16 +200,14 @@\n             assert \"flask\" in names\n \n     def test_parse_malformed_pyproject(self):\n         \"\"\"Test handling of malformed pyproject.toml.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [project\n name = \"broken\"\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             # Should not raise, just return empty\n             deps = parser._parse_python_deps()\n             assert deps == []\n \n@@ -486,23 +468,21 @@\n             assert deps == []\n \n     def test_version_specifiers_comprehensive(self):\n         \"\"\"Test various version specifier formats.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n pkg1==1.0.0\n pkg2>=1.0\n pkg3<=2.0\n pkg4>1.0\n pkg5<2.0\n pkg6!=1.5.0\n pkg7~=1.4.2\n pkg8>=1.0,<2.0\n pkg9\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             deps = parser._parse_python_deps()\n \n             assert len(deps) == 9\n             # Verify all were parsed\n@@ -516,12 +496,11 @@\n \n     def test_realistic_python_project(self):\n         \"\"\"Test with a realistic Python project structure.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create a realistic pyproject.toml\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [build-system]\n requires = [\"setuptools>=61.0\"]\n build-backend = \"setuptools.build_meta\"\n \n [project]\n@@ -536,12 +515,11 @@\n [project.optional-dependencies]\n dev = [\n     \"pytest>=7.0.0\",\n     \"black>=23.0.0\",\n ]\n-\"\"\"\n-            )\n+\"\"\")\n             parser = DependencyParser(tmpdir)\n             result = parser.get_dependencies()\n \n             assert \"python\" in result\n             names = [d[\"name\"] for d in result[\"python\"]]\n@@ -551,17 +529,15 @@\n \n     def test_realistic_fullstack_project(self):\n         \"\"\"Test with a fullstack project (Python + Node).\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Python backend\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n fastapi>=0.100.0\n uvicorn>=0.23.0\n sqlalchemy>=2.0.0\n-\"\"\"\n-            )\n+\"\"\")\n             # Node frontend\n             pkg_json = {\n                 \"name\": \"frontend\",\n                 \"dependencies\": {\"react\": \"^18.0.0\", \"axios\": \"^1.4.0\"},\n                 \"devDependencies\": {\"typescript\": \"^5.0.0\", \"vite\": \"^4.0.0\"},\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_typescript_parser_stub.py\t2026-02-01 15:55:14.604405+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_typescript_parser_stub.py\t2026-02-01 23:23:04.505245+00:00\n@@ -5,12 +5,11 @@\n from code_scalpel.polyglot.typescript.analyzer import TypeScriptAnalyzer\n from code_scalpel.polyglot.typescript.parser import TypeScriptParser\n \n \n def _ts_sample_code() -> str:\n-    return textwrap.dedent(\n-        \"\"\"\n+    return textwrap.dedent(\"\"\"\n         import { Router, Request } from 'express';\n         import type { User } from './models';\n         \n         export async function fetchUser(id: string) {\n             if (id) {\n@@ -27,12 +26,11 @@\n         }\n         \n         export default function defaultHelper(name: string) {\n             return name;\n         }\n-        \"\"\"\n-    ).strip()\n+        \"\"\").strip()\n \n \n def test_parse_with_fallback_extracts_structures():\n     parser = TypeScriptParser(language=\"typescript\")\n     result = parser.parse(_ts_sample_code(), filename=\"example.ts\")\n@@ -66,20 +64,18 @@\n     assert \"File not found\" in missing.errors[0]\n \n \n def test_analyzer_metrics_and_security(tmp_path: Path):\n     analyzer = TypeScriptAnalyzer(language=\"javascript\")\n-    code = textwrap.dedent(\n-        \"\"\"\n+    code = textwrap.dedent(\"\"\"\n         export function risky(input) {\n             eval(input);\n             const el = document.getElementById('root');\n             el.innerHTML = input;\n             return el;\n         }\n-        \"\"\"\n-    ).strip()\n+        \"\"\").strip()\n \n     result = analyzer.analyze(code, filename=\"demo.js\")\n     assert result.success is True\n     assert result.language == \"javascript\"\n     assert result.num_functions == 1\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_project_crawler.py\t2026-02-01 15:55:14.590357+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_project_crawler.py\t2026-02-01 23:23:04.761154+00:00\n@@ -199,29 +199,26 @@\n     def temp_project(self):\n         \"\"\"Create a temporary project structure for testing.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create main module\n             main_file = Path(tmpdir) / \"main.py\"\n-            main_file.write_text(\n-                \"\"\"\n+            main_file.write_text(\"\"\"\n import os\n from utils import helper\n \n def main():\n     print(\"Hello\")\n     return helper()\n \n class App:\n     def run(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Create utils module\n             utils_file = Path(tmpdir) / \"utils.py\"\n-            utils_file.write_text(\n-                \"\"\"\n+            utils_file.write_text(\"\"\"\n def helper():\n     return 42\n \n def complex_helper(x, y, z):\n     if x:\n@@ -232,27 +229,24 @@\n                         try:\n                             pass\n                         except:\n                             pass\n     return None\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Create subdirectory with module\n             subdir = Path(tmpdir) / \"submodule\"\n             subdir.mkdir()\n             sub_file = subdir / \"__init__.py\"\n             sub_file.write_text(\"# Submodule init\")\n \n             sub_module = subdir / \"core.py\"\n-            sub_module.write_text(\n-                \"\"\"\n+            sub_module.write_text(\"\"\"\n class Core:\n     def process(self):\n         return True\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Create excluded directory\n             venv_dir = Path(tmpdir) / \"venv\"\n             venv_dir.mkdir()\n             venv_file = venv_dir / \"should_skip.py\"\n@@ -374,12 +368,11 @@\n     @pytest.fixture\n     def temp_project(self):\n         \"\"\"Create a temporary project for report testing.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             main_file = Path(tmpdir) / \"main.py\"\n-            main_file.write_text(\n-                \"\"\"\n+            main_file.write_text(\"\"\"\n def simple():\n     return 1\n \n def complex(x, y, z):\n     if x:\n@@ -388,12 +381,11 @@\n                 for i in range(10):\n                     while True:\n                         if i > 5:\n                             break\n     return None\n-\"\"\"\n-            )\n+\"\"\")\n             yield tmpdir\n \n     def test_generate_report(self, temp_project):\n         \"\"\"Test report generation.\"\"\"\n         crawler = ProjectCrawler(temp_project, complexity_threshold=5)\n@@ -469,20 +461,18 @@\n     @pytest.fixture\n     def temp_project(self):\n         \"\"\"Create a temporary project.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             main_file = Path(tmpdir) / \"main.py\"\n-            main_file.write_text(\n-                \"\"\"\n+            main_file.write_text(\"\"\"\n def hello():\n     return 42\n \n class Greeter:\n     def greet(self, name):\n         return f\"Hello, {name}\"\n-\"\"\"\n-            )\n+\"\"\")\n             yield tmpdir\n \n     def test_crawl_project_function(self, temp_project):\n         \"\"\"Test the convenience function.\"\"\"\n         result = crawl_project(temp_project)\n@@ -552,37 +542,33 @@\n \n     def test_nested_classes(self):\n         \"\"\"Test handling of nested classes.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             nested_file = Path(tmpdir) / \"nested.py\"\n-            nested_file.write_text(\n-                \"\"\"\n+            nested_file.write_text(\"\"\"\n class Outer:\n     class Inner:\n         def inner_method(self):\n             pass\n     \n     def outer_method(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             crawler = ProjectCrawler(tmpdir)\n             result = crawler.crawl()\n \n             assert result.total_classes >= 1  # At least Outer\n \n     def test_lambda_functions(self):\n         \"\"\"Test that lambdas don't cause issues.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             lambda_file = Path(tmpdir) / \"lambdas.py\"\n-            lambda_file.write_text(\n-                \"\"\"\n+            lambda_file.write_text(\"\"\"\n square = lambda x: x ** 2\n items = list(filter(lambda x: x > 0, [1, -2, 3]))\n-\"\"\"\n-            )\n+\"\"\")\n \n             crawler = ProjectCrawler(tmpdir)\n             result = crawler.crawl()\n \n             # Should complete without error\n--- /mnt/k/backup/Develop/code-scalpel/tests/cli/test_cli.py\t2026-02-01 15:55:14.560197+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/cli/test_cli.py\t2026-02-01 23:23:04.759331+00:00\n@@ -640,19 +640,17 @@\n         assert \"warning\" in combined.lower() or result.returncode == 0\n \n     def test_analyze_file_with_dead_code(self, tmp_path):\n         \"\"\"Test analyzing a file with dead code for detection.\"\"\"\n         test_file = tmp_path / \"dead_code.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def unused_function():\n     return \"never called\"\n \n def main():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = subprocess.run(\n             [sys.executable, \"-m\", \"code_scalpel.cli\", \"analyze\", str(test_file)],\n             capture_output=True,\n             text=True,\n@@ -933,12 +931,11 @@\n                 continue\n \n     def test_analyze_complex_code(self, tmp_path):\n         \"\"\"Test analyzing more complex code with all features.\"\"\"\n         test_file = tmp_path / \"complex.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import os\n \n class Calculator:\n     def __init__(self):\n         self.value = 0\n@@ -956,12 +953,11 @@\n \n def main():\n     calc = Calculator()\n     calc.add(5).add(10)\n     return calc.get_value()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = subprocess.run(\n             [sys.executable, \"-m\", \"code_scalpel.cli\", \"analyze\", str(test_file)],\n             capture_output=True,\n             text=True,\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/test_config_loader.py\t2026-02-01 15:55:14.610460+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/test_config_loader.py\t2026-02-01 23:23:04.916693+00:00\n@@ -33,20 +33,18 @@\n \n \n def test_load_limits_with_explicit_path(tmp_path):\n     \"\"\"Test loading from explicit path.\"\"\"\n     config_file = tmp_path / \"test_limits.toml\"\n-    config_file.write_text(\n-        \"\"\"\n+    config_file.write_text(\"\"\"\n [pro.extract_code]\n max_depth = 999\n cross_file_deps = true\n \n [community.security_scan]\n max_findings = 123\n-\"\"\"\n-    )\n+\"\"\")\n \n     limits = load_limits(config_file)\n \n     assert limits[\"pro\"][\"extract_code\"][\"max_depth\"] == 999\n     assert limits[\"pro\"][\"extract_code\"][\"cross_file_deps\"] is True\n@@ -55,16 +53,14 @@\n \n def test_get_tool_limits():\n     \"\"\"Test extracting limits for specific tool/tier.\"\"\"\n     with tempfile.TemporaryDirectory() as tmpdir:\n         config_file = Path(tmpdir) / \"limits.toml\"\n-        config_file.write_text(\n-            \"\"\"\n+        config_file.write_text(\"\"\"\n [pro.extract_code]\n max_depth = 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         limits_config = load_limits(config_file)\n         tool_limits = get_tool_limits(\"extract_code\", \"pro\", limits_config)\n \n         assert tool_limits[\"max_depth\"] == 42\n@@ -84,16 +80,14 @@\n \n def test_get_tool_capabilities_with_config_override(tmp_path, monkeypatch):\n     \"\"\"Test that get_tool_capabilities merges external config.\"\"\"\n     # Create a config with overrides\n     config_file = tmp_path / \"limits.toml\"\n-    config_file.write_text(\n-        \"\"\"\n+    config_file.write_text(\"\"\"\n [pro.extract_code]\n max_depth = 555\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Point loader to our test config\n     monkeypatch.setenv(\"CODE_SCALPEL_LIMITS_FILE\", str(config_file))\n \n     # Clear cache to force reload\n@@ -109,16 +103,14 @@\n \n \n def test_config_priority_env_var(tmp_path, monkeypatch):\n     \"\"\"Test that CODE_SCALPEL_LIMITS_FILE env var takes priority.\"\"\"\n     config_file = tmp_path / \"custom.toml\"\n-    config_file.write_text(\n-        \"\"\"\n+    config_file.write_text(\"\"\"\n [community.extract_code]\n max_depth = 777\n-\"\"\"\n-    )\n+\"\"\")\n \n     monkeypatch.setenv(\"CODE_SCALPEL_LIMITS_FILE\", str(config_file))\n     clear_cache()\n \n     limits = load_limits()\n@@ -173,16 +165,14 @@\n def test_null_values_in_config(tmp_path):\n     \"\"\"Test that null values (unlimited) are preserved.\"\"\"\n     config_file = tmp_path / \"limits.toml\"\n     # TOML uses 'inf' or omit the key for unlimited; null is not valid TOML\n     # Instead, test that we can handle the Python None from omitted values\n-    config_file.write_text(\n-        \"\"\"\n+    config_file.write_text(\"\"\"\n [enterprise.extract_code]\n cross_file_deps = true\n-\"\"\"\n-    )\n+\"\"\")\n \n     limits = load_limits(config_file)\n \n     # Verify the config loaded\n     assert \"enterprise\" in limits\n@@ -197,16 +187,14 @@\n \n \n def test_array_values_in_config(tmp_path):\n     \"\"\"Test that array limit values work.\"\"\"\n     config_file = tmp_path / \"limits.toml\"\n-    config_file.write_text(\n-        \"\"\"\n+    config_file.write_text(\"\"\"\n [pro.symbolic_execute]\n constraint_types = [\"int\", \"bool\", \"string\"]\n-\"\"\"\n-    )\n+\"\"\")\n \n     limits = load_limits(config_file)\n \n     assert limits[\"pro\"][\"symbolic_execute\"][\"constraint_types\"] == [\n         \"int\",\n@@ -219,16 +207,14 @@\n     \"\"\"Test that .local.toml takes precedence over .toml.\"\"\"\n     # This test simulates the search path by using env var\n     # In reality, _find_config_file() checks .local.toml first\n \n     local_config = tmp_path / \"limits.local.toml\"\n-    local_config.write_text(\n-        \"\"\"\n+    local_config.write_text(\"\"\"\n [pro.extract_code]\n max_depth = 999\n-\"\"\"\n-    )\n+\"\"\")\n \n     monkeypatch.setenv(\"CODE_SCALPEL_LIMITS_FILE\", str(local_config))\n     clear_cache()\n \n     limits = load_limits()\n@@ -260,21 +246,19 @@\n \n def test_full_integration_workflow(tmp_path, monkeypatch):\n     \"\"\"Test full workflow: deploy config, tune limits, tool uses them.\"\"\"\n     # Simulate deployment: ship limits.toml with package\n     deployed_config = tmp_path / \"limits.toml\"\n-    deployed_config.write_text(\n-        \"\"\"\n+    deployed_config.write_text(\"\"\"\n [pro.extract_code]\n max_depth = 5\n cross_file_deps = true\n max_extraction_size_mb = 20\n \n [community.security_scan]\n max_findings = 100\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Deployer customizes for their environment\n     monkeypatch.setenv(\"CODE_SCALPEL_LIMITS_FILE\", str(deployed_config))\n     clear_cache()\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/core/test_pro_tier_features.py\t2026-02-01 15:55:14.626498+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/test_pro_tier_features.py\t2026-02-01 23:23:05.163694+00:00\n@@ -34,12 +34,11 @@\n \n     def test_expand_wildcard_with_all(self, temp_project: Path):\n         \"\"\"Test expanding wildcard import with explicit __all__.\"\"\"\n         # Create module with __all__\n         utils_py = temp_project / \"utils.py\"\n-        utils_py.write_text(\n-            \"\"\"\n+        utils_py.write_text(\"\"\"\n __all__ = [\"helper_func\", \"HelperClass\", \"CONSTANT\"]\n \n def helper_func():\n     pass\n \n@@ -52,12 +51,11 @@\n class _PrivateClass:\n     pass\n \n CONSTANT = 42\n _PRIVATE_CONSTANT = 99\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         # Expand wildcard import\n@@ -73,24 +71,22 @@\n \n     def test_expand_wildcard_without_all(self, temp_project: Path):\n         \"\"\"Test expanding wildcard import without __all__ - returns public symbols.\"\"\"\n         # Create module without __all__\n         utils_py = temp_project / \"utils.py\"\n-        utils_py.write_text(\n-            \"\"\"\n+        utils_py.write_text(\"\"\"\n def helper_func():\n     pass\n \n def _private_func():\n     pass\n \n class HelperClass:\n     pass\n \n CONSTANT = 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         # Expand wildcard import - should get public symbols only\n@@ -102,20 +98,18 @@\n         assert \"_private_func\" not in symbols\n \n     def test_expand_wildcard_concatenated_all(self, temp_project: Path):\n         \"\"\"Test expanding __all__ with list concatenation.\"\"\"\n         utils_py = temp_project / \"utils.py\"\n-        utils_py.write_text(\n-            \"\"\"\n+        utils_py.write_text(\"\"\"\n __all__ = [\"func_a\", \"func_b\"] + [\"func_c\"]\n \n def func_a(): pass\n def func_b(): pass\n def func_c(): pass\n def func_d(): pass  # Not in __all__\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         symbols = resolver.expand_wildcard_import(\"utils\")\n@@ -130,17 +124,15 @@\n \n         helpers_py = temp_project / \"helpers.py\"\n         helpers_py.write_text(\"def assist(): pass\")\n \n         main_py = temp_project / \"main.py\"\n-        main_py.write_text(\n-            \"\"\"\n+        main_py.write_text(\"\"\"\n from utils import *\n from helpers import *\n import os\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         wildcards = resolver.get_wildcard_imports(\"main\")\n@@ -153,33 +145,27 @@\n \n     def test_expand_all_wildcards(self, temp_project: Path):\n         \"\"\"Test expanding all wildcard imports in a module.\"\"\"\n         # Create source modules\n         utils_py = temp_project / \"utils.py\"\n-        utils_py.write_text(\n-            \"\"\"\n+        utils_py.write_text(\"\"\"\n __all__ = [\"helper\"]\n def helper(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         helpers_py = temp_project / \"helpers.py\"\n-        helpers_py.write_text(\n-            \"\"\"\n+        helpers_py.write_text(\"\"\"\n __all__ = [\"assist\", \"support\"]\n def assist(): pass\n def support(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         main_py = temp_project / \"main.py\"\n-        main_py.write_text(\n-            \"\"\"\n+        main_py.write_text(\"\"\"\n from utils import *\n from helpers import *\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         expanded = resolver.expand_all_wildcards(\"main\")\n@@ -198,28 +184,24 @@\n         # Create package structure\n         pkg_dir = temp_project / \"mypackage\"\n         pkg_dir.mkdir()\n \n         # Internal module\n-        (pkg_dir / \"internal.py\").write_text(\n-            \"\"\"\n+        (pkg_dir / \"internal.py\").write_text(\"\"\"\n def helper_func():\n     pass\n \n class InternalClass:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Package __init__ re-exports symbols\n-        (pkg_dir / \"__init__.py\").write_text(\n-            \"\"\"\n+        (pkg_dir / \"__init__.py\").write_text(\"\"\"\n from mypackage.internal import helper_func, InternalClass\n \n __all__ = [\"helper_func\", \"InternalClass\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         reexports = resolver.detect_reexports(\"mypackage\")\n@@ -230,29 +212,23 @@\n         assert reexports[\"InternalClass\"] == \"mypackage.internal\"\n \n     def test_resolve_alias_chain_simple(self, temp_project: Path):\n         \"\"\"Test resolving a simple import alias chain.\"\"\"\n         # Create modules\n-        (temp_project / \"internal.py\").write_text(\n-            '''\n+        (temp_project / \"internal.py\").write_text('''\n def original_func():\n     \"\"\"The real implementation.\"\"\"\n     pass\n-'''\n-        )\n-\n-        (temp_project / \"wrapper.py\").write_text(\n-            \"\"\"\n+''')\n+\n+        (temp_project / \"wrapper.py\").write_text(\"\"\"\n from internal import original_func as wrapped_func\n-\"\"\"\n-        )\n-\n-        (temp_project / \"main.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"main.py\").write_text(\"\"\"\n from wrapper import wrapped_func as my_func\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         # Resolve the chain\n@@ -265,30 +241,24 @@\n     def test_resolve_alias_chain_with_reexport(self, temp_project: Path):\n         \"\"\"Test resolving alias chain through package re-export.\"\"\"\n         pkg_dir = temp_project / \"mypackage\"\n         pkg_dir.mkdir()\n \n-        (pkg_dir / \"core.py\").write_text(\n-            \"\"\"\n+        (pkg_dir / \"core.py\").write_text(\"\"\"\n def core_function():\n     pass\n-\"\"\"\n-        )\n-\n-        (pkg_dir / \"__init__.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (pkg_dir / \"__init__.py\").write_text(\"\"\"\n from mypackage.core import core_function\n \n __all__ = [\"core_function\"]\n-\"\"\"\n-        )\n-\n-        (temp_project / \"app.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"app.py\").write_text(\"\"\"\n from mypackage import core_function\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         orig_module, orig_name, chain = resolver.resolve_alias_chain(\n@@ -318,27 +288,23 @@\n         \"\"\"Test getting all re-exports across the project.\"\"\"\n         # Package A\n         pkg_a = temp_project / \"pkg_a\"\n         pkg_a.mkdir()\n         (pkg_a / \"impl.py\").write_text(\"def a_func(): pass\")\n-        (pkg_a / \"__init__.py\").write_text(\n-            \"\"\"\n+        (pkg_a / \"__init__.py\").write_text(\"\"\"\n from pkg_a.impl import a_func\n __all__ = [\"a_func\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Package B\n         pkg_b = temp_project / \"pkg_b\"\n         pkg_b.mkdir()\n         (pkg_b / \"impl.py\").write_text(\"class BClass: pass\")\n-        (pkg_b / \"__init__.py\").write_text(\n-            \"\"\"\n+        (pkg_b / \"__init__.py\").write_text(\"\"\"\n from pkg_b.impl import BClass\n __all__ = [\"BClass\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         all_reexports = resolver.get_all_reexports()\n@@ -349,20 +315,16 @@\n         assert \"BClass\" in all_reexports[\"pkg_b\"]\n \n     def test_circular_alias_detection(self, temp_project: Path):\n         \"\"\"Test detection of circular alias chains.\"\"\"\n         # Create circular imports (unusual but possible)\n-        (temp_project / \"mod_a.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"mod_a.py\").write_text(\"\"\"\n from mod_b import func_b as func_a\n-\"\"\"\n-        )\n-        (temp_project / \"mod_b.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (temp_project / \"mod_b.py\").write_text(\"\"\"\n from mod_a import func_a as func_b\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         # Should detect the cycle\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/test_import_resolver.py\t2026-02-01 15:55:14.618985+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/test_import_resolver.py\t2026-02-01 23:23:05.943791+00:00\n@@ -38,34 +38,30 @@\n \n @pytest.fixture\n def simple_project(temp_project):\n     \"\"\"Create a simple two-file project.\"\"\"\n     # main.py\n-    (temp_project / \"main.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"main.py\").write_text(\"\"\"\n import utils\n from utils import helper_func\n \n def main():\n     return helper_func()\n-\"\"\"\n-    )\n+\"\"\")\n \n     # utils.py\n-    (temp_project / \"utils.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"utils.py\").write_text(\"\"\"\n def helper_func():\n     return 42\n     \n def another_func():\n     return \"hello\"\n \n class HelperClass:\n     def method(self):\n         pass\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n@@ -74,78 +70,66 @@\n     # Create package structure\n     pkg_dir = temp_project / \"mypackage\"\n     pkg_dir.mkdir()\n \n     # mypackage/__init__.py\n-    (pkg_dir / \"__init__.py\").write_text(\n-        \"\"\"\n+    (pkg_dir / \"__init__.py\").write_text(\"\"\"\n from .core import process\n from .utils import helper\n \n __all__ = ['process', 'helper']\n-\"\"\"\n-    )\n+\"\"\")\n \n     # mypackage/core.py\n-    (pkg_dir / \"core.py\").write_text(\n-        \"\"\"\n+    (pkg_dir / \"core.py\").write_text(\"\"\"\n from .utils import helper, validate\n \n def process(data):\n     if validate(data):\n         return helper(data)\n     return None\n-\"\"\"\n-    )\n+\"\"\")\n \n     # mypackage/utils.py\n-    (pkg_dir / \"utils.py\").write_text(\n-        \"\"\"\n+    (pkg_dir / \"utils.py\").write_text(\"\"\"\n def helper(data):\n     return data.upper()\n     \n def validate(data):\n     return isinstance(data, str)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # main.py at root\n-    (temp_project / \"main.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"main.py\").write_text(\"\"\"\n from mypackage import process\n from mypackage.utils import helper\n \n def run():\n     return process(\"test\")\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def circular_project(temp_project):\n     \"\"\"Create a project with circular imports.\"\"\"\n     # a.py imports from b\n-    (temp_project / \"a.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"a.py\").write_text(\"\"\"\n from b import func_b\n \n def func_a():\n     return func_b() + 1\n-\"\"\"\n-    )\n+\"\"\")\n \n     # b.py imports from a\n-    (temp_project / \"b.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"b.py\").write_text(\"\"\"\n from a import func_a\n \n def func_b():\n     return 10\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n@@ -162,67 +146,57 @@\n     models = src / \"models\"\n     models.mkdir()\n     (models / \"__init__.py\").write_text(\n         \"from .user import User\\nfrom .product import Product\"\n     )\n-    (models / \"user.py\").write_text(\n-        \"\"\"\n+    (models / \"user.py\").write_text(\"\"\"\n class User:\n     def __init__(self, name):\n         self.name = name\n-\"\"\"\n-    )\n-    (models / \"product.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+    (models / \"product.py\").write_text(\"\"\"\n class Product:\n     def __init__(self, title):\n         self.title = title\n-\"\"\"\n-    )\n+\"\"\")\n \n     # src/services/\n     services = src / \"services\"\n     services.mkdir()\n     (services / \"__init__.py\").write_text(\"\")\n-    (services / \"user_service.py\").write_text(\n-        \"\"\"\n+    (services / \"user_service.py\").write_text(\"\"\"\n from ..models import User\n from ..utils.helpers import format_name\n \n class UserService:\n     def create_user(self, name):\n         formatted = format_name(name)\n         return User(formatted)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # src/utils/\n     utils = src / \"utils\"\n     utils.mkdir()\n     (utils / \"__init__.py\").write_text(\"\")\n-    (utils / \"helpers.py\").write_text(\n-        \"\"\"\n+    (utils / \"helpers.py\").write_text(\"\"\"\n def format_name(name):\n     return name.strip().title()\n     \n def validate_email(email):\n     return \"@\" in email\n-\"\"\"\n-    )\n+\"\"\")\n \n     # app.py at root\n-    (temp_project / \"app.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"app.py\").write_text(\"\"\"\n from src.models import User, Product\n from src.services.user_service import UserService\n \n def main():\n     service = UserService()\n     user = service.create_user(\"john\")\n     return user\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n # =============================================================================\n@@ -259,16 +233,14 @@\n         assert len(from_imports) >= 1\n         assert any(imp.name == \"helper_func\" for imp in from_imports)\n \n     def test_import_with_alias(self, temp_project):\n         \"\"\"Test parsing 'import module as alias' statements.\"\"\"\n-        (temp_project / \"test.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"test.py\").write_text(\"\"\"\n import numpy as np\n from os import path as p\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         test_imports = resolver.imports.get(\"test\", [])\n@@ -278,15 +250,13 @@\n         assert any(imp.alias == \"np\" for imp in aliased)\n         assert any(imp.alias == \"p\" for imp in aliased)\n \n     def test_multiple_imports_same_line(self, temp_project):\n         \"\"\"Test parsing 'from x import a, b, c' statements.\"\"\"\n-        (temp_project / \"test.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"test.py\").write_text(\"\"\"\n from os import path, getcwd, listdir\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         test_imports = resolver.imports.get(\"test\", [])\n@@ -297,15 +267,13 @@\n         assert names == {\"path\", \"getcwd\", \"listdir\"}\n \n     def test_wildcard_import(self, temp_project):\n         \"\"\"Test parsing 'from module import *' statements.\"\"\"\n         (temp_project / \"utils.py\").write_text(\"def func(): pass\")\n-        (temp_project / \"test.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"test.py\").write_text(\"\"\"\n from utils import *\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         test_imports = resolver.imports.get(\"test\", [])\n@@ -511,16 +479,14 @@\n         assert \"HelperClass.method\" in utils_symbols\n         assert utils_symbols[\"HelperClass.method\"].symbol_type == \"method\"\n \n     def test_extract_async_functions(self, temp_project):\n         \"\"\"Test extraction of async function definitions.\"\"\"\n-        (temp_project / \"async_mod.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"async_mod.py\").write_text(\"\"\"\n async def fetch_data():\n     return await some_async_call()\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         symbols = resolver.symbols.get(\"async_mod\", {})\n@@ -528,16 +494,14 @@\n         assert \"fetch_data\" in symbols\n         assert symbols[\"fetch_data\"].symbol_type == \"async_function\"\n \n     def test_extract_function_signature(self, temp_project):\n         \"\"\"Test extraction of function signatures.\"\"\"\n-        (temp_project / \"typed.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"typed.py\").write_text(\"\"\"\n def process(data: str, count: int = 5) -> bool:\n     return True\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         symbols = resolver.symbols.get(\"typed\", {})\n@@ -548,21 +512,19 @@\n         assert \"count: int\" in sig\n         assert \"-> bool\" in sig\n \n     def test_extract_docstrings(self, temp_project):\n         \"\"\"Test extraction of docstrings.\"\"\"\n-        (temp_project / \"documented.py\").write_text(\n-            '''\n+        (temp_project / \"documented.py\").write_text('''\n def documented_func():\n     \"\"\"This is a docstring.\"\"\"\n     pass\n \n class DocumentedClass:\n     \"\"\"Class docstring.\"\"\"\n     pass\n-'''\n-        )\n+''')\n \n         resolver = ImportResolver(temp_project)\n         resolver.build()\n \n         symbols = resolver.symbols.get(\"documented\", {})\n@@ -980,17 +942,15 @@\n         assert result.success\n         assert \"empty\" in resolver.module_to_file\n \n     def test_only_comments_file(self, temp_project):\n         \"\"\"Test handling of files with only comments.\"\"\"\n-        (temp_project / \"comments.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"comments.py\").write_text(\"\"\"\n # This is a comment\n # Another comment\n '''\" Docstring-like but not really. \"'''\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         result = resolver.build()\n \n         assert result.success\n@@ -1028,15 +988,13 @@\n         \"\"\"Test imports from the root package level.\"\"\"\n         pkg = temp_project / \"pkg\"\n         pkg.mkdir()\n \n         (pkg / \"__init__.py\").write_text(\"ROOT_CONST = 42\")\n-        (pkg / \"sub.py\").write_text(\n-            \"\"\"\n+        (pkg / \"sub.py\").write_text(\"\"\"\n from pkg import ROOT_CONST\n-\"\"\"\n-        )\n+\"\"\")\n \n         resolver = ImportResolver(temp_project)\n         result = resolver.build()\n \n         assert result.success\n--- /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_surgical_tools_coverage.py\t2026-02-01 15:55:14.598374+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_surgical_tools_coverage.py\t2026-02-01 23:23:06.028987+00:00\n@@ -197,17 +197,15 @@\n \n     def test_resolve_cross_file_for_class(self, tmp_path):\n         \"\"\"Test cross-file resolution for a class target.\"\"\"\n         # Create a simple file\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n class MyClass:\n     def method(self):\n         return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\n             \"MyClass\", target_type=\"class\"\n         )\n@@ -223,31 +221,27 @@\n         pkg_dir.mkdir()\n         (pkg_dir / \"__init__.py\").write_text(\"\")\n \n         # Create models.py with a class\n         models_file = pkg_dir / \"models.py\"\n-        models_file.write_text(\n-            \"\"\"\n+        models_file.write_text(\"\"\"\n class TaxRate:\n     RATE = 0.1\n     \n     @staticmethod\n     def get():\n         return TaxRate.RATE\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create main.py that imports from models\n         main_file = pkg_dir / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from .models import TaxRate\n \n def calculate_tax(amount):\n     return TaxRate.get() * amount\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"calculate_tax\")\n \n         assert result.success is True\n@@ -257,29 +251,25 @@\n \n     def test_resolve_cross_file_with_from_import(self, tmp_path):\n         \"\"\"Test resolving from X import Y style imports.\"\"\"\n         # Create helper.py\n         helper_file = tmp_path / \"helper.py\"\n-        helper_file.write_text(\n-            \"\"\"\n+        helper_file.write_text(\"\"\"\n def helper_function():\n     return 42\n \n CONFIG = {\"key\": \"value\"}\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create main.py\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import helper_function, CONFIG\n \n def use_helper():\n     return helper_function() + len(CONFIG)\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_helper\")\n \n         assert result.success is True\n@@ -289,44 +279,38 @@\n \n     def test_resolve_cross_file_with_absolute_import(self, tmp_path):\n         \"\"\"Test resolving import X style imports.\"\"\"\n         # Create utils.py\n         utils_file = tmp_path / \"utils.py\"\n-        utils_file.write_text(\n-            \"\"\"\n+        utils_file.write_text(\"\"\"\n def utility():\n     return \"utility\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create main.py\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n import utils\n \n def use_utils():\n     return utils.utility()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_utils\")\n \n         assert result.success is True\n \n     def test_resolve_cross_file_unresolved_module(self, tmp_path):\n         \"\"\"Test that unresolved imports are tracked.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from nonexistent_module import Something\n \n def use_something():\n     return Something()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_something\")\n \n         assert result.success is True\n@@ -338,28 +322,24 @@\n         # Create chain: main -> level1 -> level2\n         level2_file = tmp_path / \"level2.py\"\n         level2_file.write_text(\"def deep(): return 'deep'\")\n \n         level1_file = tmp_path / \"level1.py\"\n-        level1_file.write_text(\n-            \"\"\"\n+        level1_file.write_text(\"\"\"\n from level2 import deep\n \n def middle():\n     return deep()\n-\"\"\"\n-        )\n+\"\"\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from level1 import middle\n \n def top():\n     return middle()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n \n         # With depth 0, should not resolve anything\n         result0 = extractor.resolve_cross_file_dependencies(\"top\", max_depth=0)\n@@ -373,18 +353,16 @@\n         \"\"\"Test resolving aliased imports.\"\"\"\n         helper_file = tmp_path / \"helper.py\"\n         helper_file.write_text(\"def original(): return 1\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import original as aliased\n \n def use_aliased():\n     return aliased()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_aliased\")\n \n         assert result.success is True\n@@ -393,36 +371,32 @@\n         \"\"\"Test that star imports are skipped.\"\"\"\n         helper_file = tmp_path / \"helper.py\"\n         helper_file.write_text(\"def func(): pass\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import *\n \n def use_func():\n     return func()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_func\")\n \n         assert result.success is True\n         # Star imports are skipped, so func won't be resolved via star import\n \n     def test_resolve_cross_file_handles_file_read_error(self, tmp_path):\n         \"\"\"Test handling when external file can't be read.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import func\n \n def use_func():\n     return func()\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create helper.py then make it unreadable\n         helper_file = tmp_path / \"helper.py\"\n         helper_file.write_text(\"def func(): pass\")\n \n@@ -451,18 +425,16 @@\n         \"\"\"Test resolving global variables from external files.\"\"\"\n         config_file = tmp_path / \"config.py\"\n         config_file.write_text(\"SETTINGS = {'debug': True}\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from config import SETTINGS\n \n def get_setting():\n     return SETTINGS['debug']\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"get_setting\")\n \n         assert result.success is True\n@@ -475,19 +447,17 @@\n     \"\"\"\n \n     def test_build_import_map_from_import(self, tmp_path):\n         \"\"\"Test mapping from X import Y style.\"\"\"\n         file_path = tmp_path / \"test.py\"\n-        file_path.write_text(\n-            \"\"\"\n+        file_path.write_text(\"\"\"\n from models import User, Item\n from utils import helper as h\n \n def func():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(file_path))\n         extractor._ensure_parsed()\n         import_map = extractor._build_import_map()\n \n@@ -496,20 +466,18 @@\n         assert \"h\" in import_map  # Aliased import\n \n     def test_build_import_map_regular_import(self, tmp_path):\n         \"\"\"Test mapping import X style.\"\"\"\n         file_path = tmp_path / \"test.py\"\n-        file_path.write_text(\n-            \"\"\"\n+        file_path.write_text(\"\"\"\n import os\n import json as j\n import collections.abc\n \n def func():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(file_path))\n         extractor._ensure_parsed()\n         import_map = extractor._build_import_map()\n \n@@ -528,15 +496,13 @@\n         \"\"\"Test resolving 'from . import X' style.\"\"\"\n         pkg_dir = tmp_path / \"pkg\"\n         pkg_dir.mkdir()\n         (pkg_dir / \"__init__.py\").write_text(\"\")\n         (pkg_dir / \"sibling.py\").write_text(\"def sibling(): pass\")\n-        (pkg_dir / \"main.py\").write_text(\n-            \"\"\"\n+        (pkg_dir / \"main.py\").write_text(\"\"\"\n from . import sibling\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(pkg_dir / \"main.py\"))\n         extractor._ensure_parsed()\n \n         # Resolve the sibling module\n@@ -550,15 +516,13 @@\n         sub_dir = pkg_dir / \"sub\"\n         sub_dir.mkdir(parents=True)\n         (pkg_dir / \"__init__.py\").write_text(\"\")\n         (sub_dir / \"__init__.py\").write_text(\"\")\n         (pkg_dir / \"parent.py\").write_text(\"def parent(): pass\")\n-        (sub_dir / \"child.py\").write_text(\n-            \"\"\"\n+        (sub_dir / \"child.py\").write_text(\"\"\"\n from .. import parent\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(sub_dir / \"child.py\"))\n         extractor._ensure_parsed()\n \n         # Resolve parent module (level=2 means go up one directory)\n@@ -1192,18 +1156,16 @@\n         helper_file = tmp_path / \"helper.py\"\n         helper_file.write_text(\"def other_func(): pass\")\n \n         # Create main.py that imports a non-existent symbol\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import nonexistent_func\n \n def use_it():\n     return nonexistent_func()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_it\")\n \n         assert result.success is True\n@@ -1232,18 +1194,16 @@\n         # Create utils.py in package\n         (pkg_dir / \"utils.py\").write_text(\"def utility(): pass\")\n \n         # Create main.py in subdir\n         main_file = sub_dir / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from package.utils import utility\n \n def use_util():\n     return utility()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         extractor._ensure_parsed()\n \n         # Try to resolve package.utils from subdir\n@@ -1349,29 +1309,23 @@\n \n     def test_cross_file_depth_exceeded(self, tmp_path):\n         \"\"\"Test that max_depth is respected in cross-file resolution.\"\"\"\n         # Create deep chain\n         (tmp_path / \"level3.py\").write_text(\"def l3(): return 3\")\n-        (tmp_path / \"level2.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level2.py\").write_text(\"\"\"\n from level3 import l3\n def l2(): return l3()\n-\"\"\"\n-        )\n-        (tmp_path / \"level1.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (tmp_path / \"level1.py\").write_text(\"\"\"\n from level2 import l2\n def l1(): return l2()\n-\"\"\"\n-        )\n+\"\"\")\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from level1 import l1\n def main(): return l1()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n \n         # With max_depth=0, should not resolve any dependencies\n         result = extractor.resolve_cross_file_dependencies(\"main\", max_depth=0)\n@@ -1390,18 +1344,16 @@\n         pkg_dir.mkdir()\n         (pkg_dir / \"__init__.py\").write_text(\"\")\n         (pkg_dir / \"sibling.py\").write_text(\"def sib(): pass\")\n \n         main_file = pkg_dir / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from . import sibling\n \n def use_sib():\n     return sibling.sib()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         extractor._ensure_parsed()\n \n         # This should handle the case where module_name is empty for relative imports\n@@ -1470,42 +1422,34 @@\n     \"\"\"\n \n     def test_cross_file_recursive_depth_limit(self, tmp_path):\n         \"\"\"Test recursive resolution stops at depth limit.\"\"\"\n         # Create files that reference each other\n-        (tmp_path / \"a.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"a.py\").write_text(\"\"\"\n from b import b_func\n \n def a_func():\n     return b_func()\n-\"\"\"\n-        )\n-        (tmp_path / \"b.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (tmp_path / \"b.py\").write_text(\"\"\"\n from c import c_func\n \n def b_func():\n     return c_func()\n-\"\"\"\n-        )\n-        (tmp_path / \"c.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (tmp_path / \"c.py\").write_text(\"\"\"\n def c_func():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from a import a_func\n \n def main():\n     return a_func()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n \n         # With max_depth=1, should resolve a_func but not b_func or c_func\n         result = extractor.resolve_cross_file_dependencies(\"main\", max_depth=1)\n@@ -1524,18 +1468,16 @@\n         helper_file = tmp_path / \"helper.py\"\n         # An empty file - the import will resolve but symbol won't be found\n         helper_file.write_text(\"# Empty module\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import some_thing\n \n def use_thing():\n     return some_thing()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_thing\")\n \n         assert result.success is True\n@@ -1564,18 +1506,16 @@\n         # Create utils at pkg level\n         (pkg / \"utils.py\").write_text(\"def helper(): pass\")\n \n         # Create main.py at subsub level\n         main_file = subsub / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n import pkg.utils\n \n def use_util():\n     return pkg.utils.helper()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         extractor._ensure_parsed()\n \n         # Try to resolve pkg.utils from deep in the tree\n@@ -1696,29 +1636,25 @@\n \n     def test_cross_file_import_module_with_nonexistent_symbol(self, tmp_path):\n         \"\"\"Test importing a symbol that doesn't exist in the module.\"\"\"\n         # Create external module with some content\n         ext_file = tmp_path / \"external.py\"\n-        ext_file.write_text(\n-            \"\"\"\n+        ext_file.write_text(\"\"\"\n # This module has functions but not the one being imported\n def actual_func():\n     return 1\n \n ACTUAL_VAR = 2\n-\"\"\"\n-        )\n+\"\"\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from external import nonexistent_symbol\n \n def use_nonexistent():\n     return nonexistent_symbol()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         result = extractor.resolve_cross_file_dependencies(\"use_nonexistent\")\n \n         assert result.success is True\n@@ -1736,18 +1672,16 @@\n         \"\"\"Test that depth 0 causes immediate return.\"\"\"\n         ext_file = tmp_path / \"external.py\"\n         ext_file.write_text(\"def external_func(): return 1\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from external import external_func\n \n def main():\n     return external_func()\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n \n         # max_depth=0 should not resolve any external dependencies\n         result = extractor.resolve_cross_file_dependencies(\"main\", max_depth=0)\n@@ -1775,18 +1709,16 @@\n         deep.mkdir(parents=True)\n         (pkg / \"subpkg\" / \"__init__.py\").write_text(\"\")\n         (deep / \"__init__.py\").write_text(\"\")\n \n         main_file = deep / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n import pkg\n \n def use_pkg():\n     return pkg.PKG_INIT\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(main_file))\n         extractor._ensure_parsed()\n \n         # Try to resolve 'pkg' from deep/main.py\n--- /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_oracle_pipeline.py\t2026-02-01 15:55:14.656852+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_oracle_pipeline.py\t2026-02-01 23:23:06.266046+00:00\n@@ -146,22 +146,20 @@\n     def test_pipeline_generates_spec(self):\n         \"\"\"Test that pipeline can generate a spec without errors.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create a test Python file\n             test_file = Path(tmpdir) / \"auth.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def login(username, password):\n     '''Authenticate user.'''\n     # TODO: Hash password\n     return True\n \n class User:\n     def __init__(self, name):\n         self.name = name\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Generate spec with small limits\n             pipeline = OraclePipeline(\n                 repo_root=tmpdir,\n                 max_files=10,\n--- /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_integration.py\t2026-02-01 15:55:14.646096+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_integration.py\t2026-02-01 23:23:06.369693+00:00\n@@ -17,12 +17,11 @@\n         src_dir = tmp_path / \"src\"\n         src_dir.mkdir()\n \n         # Create auth module with function and class\n         auth_file = src_dir / \"auth.py\"\n-        auth_file.write_text(\n-            '''\"\"\"Authentication module.\"\"\"\n+        auth_file.write_text('''\"\"\"Authentication module.\"\"\"\n \n def authenticate(username: str, password: str) -> bool:\n     \"\"\"Validate user credentials.\"\"\"\n     import database\n     db = database.get_connection()\n@@ -39,17 +38,15 @@\n         \"\"\"Login user.\"\"\"\n         return authenticate(username, \"\")\n \n import json\n from typing import Dict\n-'''\n-        )\n+''')\n \n         # Create database module\n         db_file = src_dir / \"database.py\"\n-        db_file.write_text(\n-            '''\"\"\"Database module.\"\"\"\n+        db_file.write_text('''\"\"\"Database module.\"\"\"\n \n def get_connection():\n     \"\"\"Get database connection.\"\"\"\n     import json\n     return DatabaseConnection()\n@@ -58,12 +55,11 @@\n     \"\"\"Database connection.\"\"\"\n     \n     def verify_user(self, username: str, password: str) -> bool:\n         \"\"\"Verify user credentials.\"\"\"\n         return True\n-'''\n-        )\n+''')\n \n         # Step 1: Scan project\n         scanner = ProjectScanner(\n             root_dir=str(src_dir), max_files=10, max_depth=2, extract_symbols=True\n         )\n@@ -108,31 +104,27 @@\n         utils_dir = src_dir / \"utils\"\n         utils_dir.mkdir()\n \n         # Create a view file\n         view_file = views_dir / \"dashboard.py\"\n-        view_file.write_text(\n-            '''\"\"\"Dashboard view.\"\"\"\n+        view_file.write_text('''\"\"\"Dashboard view.\"\"\"\n \n def render_dashboard():\n     \"\"\"Render dashboard.\"\"\"\n     from src.utils.helpers import format_data\n     data = format_data()\n     return {\"data\": data}\n-'''\n-        )\n+''')\n \n         # Create utilities file\n         utils_file = utils_dir / \"helpers.py\"\n-        utils_file.write_text(\n-            '''\"\"\"Utility helpers.\"\"\"\n+        utils_file.write_text('''\"\"\"Utility helpers.\"\"\"\n \n def format_data():\n     \"\"\"Format data.\"\"\"\n     return {}\n-'''\n-        )\n+''')\n \n         # Scan project\n         scanner = ProjectScanner(\n             root_dir=str(src_dir), max_files=10, max_depth=3, extract_symbols=True\n         )\n@@ -181,31 +173,27 @@\n         src_dir = tmp_path / \"src\"\n         src_dir.mkdir()\n \n         # File A imports B\n         file_a = src_dir / \"module_a.py\"\n-        file_a.write_text(\n-            '''\"\"\"Module A.\"\"\"\n+        file_a.write_text('''\"\"\"Module A.\"\"\"\n \n def func_a():\n     \"\"\"Function in A.\"\"\"\n     from module_b import func_b\n     return func_b()\n-'''\n-        )\n+''')\n \n         # File B imports A\n         file_b = src_dir / \"module_b.py\"\n-        file_b.write_text(\n-            '''\"\"\"Module B.\"\"\"\n+        file_b.write_text('''\"\"\"Module B.\"\"\"\n \n def func_b():\n     \"\"\"Function in B.\"\"\"\n     from module_a import func_a\n     return func_a()\n-'''\n-        )\n+''')\n \n         # Scan\n         scanner = ProjectScanner(\n             root_dir=str(src_dir), max_files=10, max_depth=2, extract_symbols=True\n         )\n@@ -235,29 +223,25 @@\n         src_dir = tmp_path / \"src\"\n         src_dir.mkdir()\n \n         # Create a valid file\n         valid_file = src_dir / \"valid.py\"\n-        valid_file.write_text(\n-            '''\"\"\"Valid module.\"\"\"\n+        valid_file.write_text('''\"\"\"Valid module.\"\"\"\n \n def valid_function():\n     \"\"\"Valid function.\"\"\"\n     return True\n-'''\n-        )\n+''')\n \n         # Create an invalid file (syntax error)\n         invalid_file = src_dir / \"invalid.py\"\n-        invalid_file.write_text(\n-            '''\"\"\"Invalid module.\"\"\"\n+        invalid_file.write_text('''\"\"\"Invalid module.\"\"\"\n \n def invalid_function(\n     # Missing closing parenthesis\n     return True\n-'''\n-        )\n+''')\n \n         # Scan should handle errors gracefully\n         scanner = ProjectScanner(\n             root_dir=str(src_dir), max_files=10, max_depth=2, extract_symbols=True\n         )\n@@ -285,12 +269,11 @@\n         src_dir = tmp_path / \"src\"\n         src_dir.mkdir()\n \n         # Create a file with rich symbol information\n         rich_file = src_dir / \"models.py\"\n-        rich_file.write_text(\n-            '''\"\"\"Data models.\"\"\"\n+        rich_file.write_text('''\"\"\"Data models.\"\"\"\n \n from typing import Optional, List\n from dataclasses import dataclass\n \n @dataclass\n@@ -326,12 +309,11 @@\n         self.items.append(item)\n \n def create_user(name: str, email: Optional[str] = None) -> User:\n     \"\"\"Create a new user.\"\"\"\n     return User(id=1, name=name, email=email)\n-'''\n-        )\n+''')\n \n         # Scan with symbol extraction\n         scanner = ProjectScanner(\n             root_dir=str(src_dir), max_files=10, max_depth=2, extract_symbols=True\n         )\n--- /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_symbol_enrichment.py\t2026-02-01 15:55:14.679202+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_symbol_enrichment.py\t2026-02-01 23:23:06.412389+00:00\n@@ -18,12 +18,11 @@\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             # Create a test file with function and class\n             test_file = tmpdir_path / \"test_module.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def process_data(data: list) -> dict:\n     '''Process data and return results.'''\n     return {'count': len(data)}\n \n class DataProcessor:\n@@ -33,12 +32,11 @@\n         self.name = name\n     \n     def process(self, items):\n         '''Process items.'''\n         return items\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Scan with symbol extraction enabled\n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n@@ -88,20 +86,18 @@\n         \"\"\"Test that class methods are extracted and linked.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             test_file = tmpdir_path / \"classes.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n class Calculator:\n     def add(self, a: int, b: int) -> int:\n         return a + b\n     \n     def subtract(self, a: int, b: int) -> int:\n         return a - b\n-\"\"\"\n-            )\n+\"\"\")\n \n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n                 max_depth=2,\n@@ -147,23 +143,21 @@\n         \"\"\"Test that AST extraction and symbol enrichment work together.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             test_file = tmpdir_path / \"mixed.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n import json\n from typing import Dict\n \n def helper():\n     pass\n \n class Manager:\n     def task(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n                 max_depth=2,\n@@ -180,12 +174,11 @@\n         \"\"\"Test that function signatures are correctly extracted.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             test_file = tmpdir_path / \"signatures.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def simple():\n     '''Simple function.'''\n     pass\n \n def with_args(a: int, b: str) -> bool:\n@@ -194,12 +187,11 @@\n \n @decorator\n def decorated():\n     '''Decorated function.'''\n     pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n                 max_depth=2,\n@@ -243,17 +235,15 @@\n         \"\"\"Test that enriched nodes have proper metadata structure.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             test_file = tmpdir_path / \"metadata.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def example(x, y) -> int:\n     '''Example function.'''\n     return x + y\n-\"\"\"\n-            )\n+\"\"\")\n \n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n                 max_depth=2,\n--- /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/surgery/surgical_extractor.py\t2026-02-01 15:55:14.535908+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/surgery/surgical_extractor.py\t2026-02-01 23:23:06.583107+00:00\n@@ -2368,15 +2368,13 @@\n \n         # Generate OpenAPI spec\n         docstring = func_result.docstring or f\"Execute {function_name} function\"\n         param_specs = []\n         for param in params:\n-            param_specs.append(\n-                f\"\"\"          {param}:\n+            param_specs.append(f\"\"\"          {param}:\n             type: {param_types[param]}\n-            description: Parameter {param}\"\"\"\n-            )\n+            description: Parameter {param}\"\"\")\n \n         param_spec_str = (\n             \"\\n\".join(param_specs) if param_specs else \"          # No parameters\"\n         )\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/integration/test_v151_integration.py\t2026-02-01 15:55:14.635552+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/integration/test_v151_integration.py\t2026-02-01 23:23:06.735017+00:00\n@@ -17,27 +17,24 @@\n     @pytest.fixture\n     def flask_project(self, tmp_path):\n         \"\"\"Create a realistic Flask project structure.\"\"\"\n         # app.py - main application entry point\n         app_file = tmp_path / \"app.py\"\n-        app_file.write_text(\n-            \"\"\"\n+        app_file.write_text(\"\"\"\n from flask import Flask\n from routes import register_routes\n \n app = Flask(__name__)\n register_routes(app)\n \n if __name__ == \"__main__\":\n     app.run(debug=True)\n-\"\"\"\n-        )\n+\"\"\")\n \n         # routes.py - route definitions\n         routes_file = tmp_path / \"routes.py\"\n-        routes_file.write_text(\n-            \"\"\"\n+        routes_file.write_text(\"\"\"\n from flask import request, jsonify\n from services import user_service\n from db import database\n \n def register_routes(app):\n@@ -49,35 +46,31 @@\n     \n     @app.route(\"/users/<int:user_id>\")\n     def get_user(user_id):\n         user = database.get_user(user_id)\n         return jsonify(user)\n-\"\"\"\n-        )\n+\"\"\")\n \n         # services/user_service.py\n         services_dir = tmp_path / \"services\"\n         services_dir.mkdir()\n         (services_dir / \"__init__.py\").write_text(\"\")\n-        (services_dir / \"user_service.py\").write_text(\n-            '''\n+        (services_dir / \"user_service.py\").write_text('''\n from db import database\n \n def search_users(query):\n     \"\"\"Search for users - potentially vulnerable.\"\"\"\n     return database.execute_query(f\"SELECT * FROM users WHERE name LIKE '%{query}%'\")\n \n def get_user_by_id(user_id):\n     \"\"\"Get user by ID - safe parameterized query.\"\"\"\n     return database.get_user(user_id)\n-'''\n-        )\n+''')\n \n         # db.py - database module\n         db_file = tmp_path / \"db.py\"\n-        db_file.write_text(\n-            '''\n+        db_file.write_text('''\n import sqlite3\n \n class Database:\n     def __init__(self):\n         self.conn = sqlite3.connect(\":memory:\")\n@@ -93,12 +86,11 @@\n         cursor = self.conn.cursor()\n         cursor.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,))\n         return cursor.fetchone()\n \n database = Database()\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_import_resolver_analyzes_flask_project(self, flask_project):\n         \"\"\"Test that ImportResolver can analyze a Flask project.\"\"\"\n@@ -194,19 +186,16 @@\n             if i > 0:\n                 imports.append(f\"from module_{i-1} import func_{i-1}\")\n             if i > 1:\n                 imports.append(f\"from module_{i-2} import func_{i-2}\")\n \n-            code = (\n-                \"\\n\".join(imports)\n-                + f\"\"\"\n+            code = \"\\n\".join(imports) + f\"\"\"\n \n def func_{i}(x):\n     '''Function in module {i}.'''\n     result = x * {i+1}\n \"\"\"\n-            )\n             # Add calls to imported functions\n             if i > 0:\n                 code += f\"    result += func_{i-1}(x)\\n\"\n             code += \"    return result\\n\"\n \n@@ -247,32 +236,28 @@\n     @pytest.fixture\n     def circular_project(self, tmp_path):\n         \"\"\"Create a project with circular imports.\"\"\"\n         # a.py imports from b.py\n         a_file = tmp_path / \"a.py\"\n-        a_file.write_text(\n-            \"\"\"\n+        a_file.write_text(\"\"\"\n from b import func_b\n \n def func_a():\n     return func_b() + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         # b.py imports from a.py (circular!)\n         b_file = tmp_path / \"b.py\"\n-        b_file.write_text(\n-            \"\"\"\n+        b_file.write_text(\"\"\"\n from a import func_a\n \n def func_b():\n     return 42  # Would call func_a() but that would recurse\n \n def other_func():\n     return func_a()\n-\"\"\"\n-        )\n+\"\"\")\n \n         return tmp_path\n \n     def test_import_resolver_detects_circular(self, circular_project):\n         \"\"\"Test that ImportResolver detects circular imports.\"\"\"\n@@ -309,28 +294,24 @@\n \n     @pytest.fixture\n     def simple_project(self, tmp_path):\n         \"\"\"Create a simple two-file project.\"\"\"\n         utils_file = tmp_path / \"utils.py\"\n-        utils_file.write_text(\n-            '''\n+        utils_file.write_text('''\n def helper(x):\n     \"\"\"A helper function.\"\"\"\n     return x + 1\n-'''\n-        )\n+''')\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            '''\n+        main_file.write_text('''\n from utils import helper\n \n def process(x):\n     \"\"\"Process data using helper.\"\"\"\n     return helper(x) * 2\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_get_cross_file_dependencies_consistency(self, simple_project):\n         \"\"\"Test that get_cross_file_dependencies returns consistent results.\"\"\"\n@@ -381,66 +362,54 @@\n \n     @pytest.fixture\n     def deep_dependency_project(self, tmp_path):\n         \"\"\"Create a project with deep dependency chain for testing confidence decay.\"\"\"\n         # level_0.py - entry point\n-        (tmp_path / \"level_0.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level_0.py\").write_text(\"\"\"\n from level_1 import func_1\n \n def entry_point():\n     return func_1()\n-\"\"\"\n-        )\n+\"\"\")\n \n         # level_1.py\n-        (tmp_path / \"level_1.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level_1.py\").write_text(\"\"\"\n from level_2 import func_2\n \n def func_1():\n     return func_2() + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         # level_2.py\n-        (tmp_path / \"level_2.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level_2.py\").write_text(\"\"\"\n from level_3 import func_3\n \n def func_2():\n     return func_3() + 2\n-\"\"\"\n-        )\n+\"\"\")\n \n         # level_3.py\n-        (tmp_path / \"level_3.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level_3.py\").write_text(\"\"\"\n from level_4 import func_4\n \n def func_3():\n     return func_4() + 3\n-\"\"\"\n-        )\n+\"\"\")\n \n         # level_4.py\n-        (tmp_path / \"level_4.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level_4.py\").write_text(\"\"\"\n from level_5 import func_5\n \n def func_4():\n     return func_5() + 4\n-\"\"\"\n-        )\n+\"\"\")\n \n         # level_5.py (leaf node)\n-        (tmp_path / \"level_5.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"level_5.py\").write_text(\"\"\"\n def func_5():\n     return 5\n-\"\"\"\n-        )\n+\"\"\")\n \n         return tmp_path\n \n     def test_calculate_confidence_formula(self):\n         \"\"\"Test that confidence decay formula is correct.\"\"\"\n@@ -889,22 +858,20 @@\n     import asyncio\n \n     from code_scalpel.mcp.server import get_graph_neighborhood\n \n     # Create a simple test project\n-    (tmp_path / \"main.py\").write_text(\n-        \"\"\"\n+    (tmp_path / \"main.py\").write_text(\"\"\"\n def entry_point():\n     helper()\n     \n def helper():\n     util()\n     \n def util():\n     pass\n-\"\"\"\n-    )\n+\"\"\")\n \n     async def run_test():\n         # Use the actual project - it has a call graph\n         result = await get_graph_neighborhood(\n             center_node_id=\"python::tmp_cov::function::main\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_scanner.py\t2026-02-01 15:55:14.670426+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_scanner.py\t2026-02-01 23:23:06.830549+00:00\n@@ -21,20 +21,18 @@\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             # Create a simple Python file\n             py_file = tmpdir_path / \"test_module.py\"\n-            py_file.write_text(\n-                \"\"\"\n+            py_file.write_text(\"\"\"\n def hello():\n     pass\n \n class MyClass:\n     def method(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Scan with low limits\n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n@@ -177,17 +175,15 @@\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             # Create a file with a class\n             test_file = tmpdir_path / \"test.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n class MyClass:\n     def method(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Scan\n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n@@ -205,17 +201,15 @@\n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             # Create a file with a class\n             test_file = tmpdir_path / \"test.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n class MyClass:\n     def method(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Scan\n             scanner = ProjectScanner(\n                 root_dir=tmpdir_path,\n                 max_files=10,\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_mcp_resources.py\t2026-02-01 15:55:14.719655+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_mcp_resources.py\t2026-02-01 23:23:07.136412+00:00\n@@ -45,19 +45,17 @@\n \n     async def test_returns_valid_json(self):\n         \"\"\"Verify resource returns valid JSON.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create a simple Python file\n-            Path(tmpdir, \"main.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"main.py\").write_text(\"\"\"\n def caller():\n     helper()\n \n def helper():\n     print(\"helping\")\n-\"\"\"\n-            )\n+\"\"\")\n             with patch.object(server_module, \"PROJECT_ROOT\", Path(tmpdir)):\n                 server_module._PROJECT_ROOT_HOLDER[0] = Path(tmpdir)\n                 result = await get_project_call_graph()\n \n                 # Should be valid JSON\n@@ -65,23 +63,21 @@\n                 assert isinstance(data, dict)\n \n     async def test_call_graph_structure(self):\n         \"\"\"Verify call graph has correct structure.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"example.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"example.py\").write_text(\"\"\"\n def main():\n     process()\n     validate()\n \n def process():\n     print(\"processing\")\n \n def validate():\n     pass\n-\"\"\"\n-            )\n+\"\"\")\n             with patch.object(server_module, \"PROJECT_ROOT\", Path(tmpdir)):\n                 server_module._PROJECT_ROOT_HOLDER[0] = Path(tmpdir)\n                 result = await get_project_call_graph()\n                 data = json.loads(result)\n \n@@ -123,16 +119,14 @@\n                 assert isinstance(data, dict)\n \n     async def test_parses_requirements_txt(self):\n         \"\"\"Verify requirements.txt is parsed.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"requirements.txt\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"requirements.txt\").write_text(\"\"\"\n requests>=2.28.0\n flask>=2.0.0\n-\"\"\"\n-            )\n+\"\"\")\n             with patch.object(server_module, \"PROJECT_ROOT\", Path(tmpdir)):\n                 server_module._PROJECT_ROOT_HOLDER[0] = Path(tmpdir)\n                 result = await get_project_dependencies()\n                 data = json.loads(result)\n \n@@ -142,19 +136,17 @@\n                 assert \"flask\" in names\n \n     async def test_parses_pyproject_toml(self):\n         \"\"\"Verify pyproject.toml is parsed.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [project]\n dependencies = [\n     \"pydantic>=2.0.0\",\n     \"click>=8.0.0\",\n ]\n-\"\"\"\n-            )\n+\"\"\")\n             with patch.object(server_module, \"PROJECT_ROOT\", Path(tmpdir)):\n                 server_module._PROJECT_ROOT_HOLDER[0] = Path(tmpdir)\n                 result = await get_project_dependencies()\n                 data = json.loads(result)\n \n@@ -392,43 +384,35 @@\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create src directory\n             src = Path(tmpdir, \"src\")\n             src.mkdir()\n             Path(src, \"__init__.py\").touch()\n-            Path(src, \"core.py\").write_text(\n-                \"\"\"\n+            Path(src, \"core.py\").write_text(\"\"\"\n from .utils import helper\n \n def main():\n     helper()\n-\"\"\"\n-            )\n-            Path(src, \"utils.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            Path(src, \"utils.py\").write_text(\"\"\"\n def helper():\n     pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Create tests directory\n             tests = Path(tmpdir, \"tests\")\n             tests.mkdir()\n-            Path(tests, \"test_core.py\").write_text(\n-                \"\"\"\n+            Path(tests, \"test_core.py\").write_text(\"\"\"\n def test_main():\n     pass\n-\"\"\"\n-            )\n+\"\"\")\n \n             # Create config files\n-            Path(tmpdir, \"pyproject.toml\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"pyproject.toml\").write_text(\"\"\"\n [project]\n name = \"test-project\"\n dependencies = [\"click>=8.0\"]\n-\"\"\"\n-            )\n+\"\"\")\n \n             with patch.object(server_module, \"PROJECT_ROOT\", Path(tmpdir)):\n                 server_module._PROJECT_ROOT_HOLDER[0] = Path(tmpdir)\n                 # All resources should work\n                 call_graph = json.loads(await get_project_call_graph())\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_resource_templates.py\t2026-02-01 15:55:14.735470+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_resource_templates.py\t2026-02-01 23:23:07.292976+00:00\n@@ -150,17 +150,15 @@\n             server.ALLOWED_ROOTS = [Path(tmpdir)]  # Reset to temp dir\n \n             try:\n                 # Create test file\n                 test_file = Path(tmpdir) / \"utils.py\"\n-                test_file.write_text(\n-                    '''\n+                test_file.write_text('''\n def calculate_tax(amount):\n     \"\"\"Calculate tax.\"\"\"\n     return amount * 0.1\n-'''\n-                )\n+''')\n \n                 # Test resource access\n                 result_json = await get_code_resource(\n                     \"python\", \"utils\", \"calculate_tax\"\n                 )\n@@ -196,17 +194,15 @@\n             try:\n                 # Create test file\n                 components_dir = Path(tmpdir) / \"components\"\n                 components_dir.mkdir()\n                 test_file = components_dir / \"Button.tsx\"\n-                test_file.write_text(\n-                    \"\"\"\n+                test_file.write_text(\"\"\"\n export function Button({ label }: { label: string }) {\n   return <button>{label}</button>;\n }\n-\"\"\"\n-                )\n+\"\"\")\n \n                 # Test resource access\n                 result_json = await get_code_resource(\n                     \"typescript\", \"components/Button\", \"Button\"\n                 )\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_stage5_manual_tool_validation.py\t2026-02-01 15:55:14.760822+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_stage5_manual_tool_validation.py\t2026-02-01 23:23:07.494979+00:00\n@@ -50,44 +50,38 @@\n     project.mkdir()\n \n     # Python file with function\n     # [20251228_TEST] Include an actual sink call (cursor.execute) so\n     # security_scan reliably reports a finding.\n-    (project / \"utils.py\").write_text(\n-        '''\n+    (project / \"utils.py\").write_text('''\n def add(a, b):\n     \"\"\"Add two numbers.\"\"\"\n     return a + b\n \n def vulnerable(user_input, cursor):\n     \"\"\"Vulnerable to SQL injection.\"\"\"\n     query = f\"SELECT * FROM users WHERE id = {user_input}\"\n     cursor.execute(query)\n     return query\n-'''\n-    )\n+''')\n \n     # requirements.txt for dependency scanning\n     (project / \"requirements.txt\").write_text(\"requests==2.31.0\\n\")\n \n     # TypeScript file for type evaporation testing\n-    (project / \"frontend.ts\").write_text(\n-        \"\"\"\n+    (project / \"frontend.ts\").write_text(\"\"\"\n type Role = 'admin' | 'user';\n const role = (document.getElementById('role') as HTMLInputElement).value as Role;\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Backend Python for type evaporation\n-    (project / \"backend.py\").write_text(\n-        \"\"\"\n+    (project / \"backend.py\").write_text(\"\"\"\n from flask import request\n \n def get_role():\n     return request.json['role']\n-\"\"\"\n-    )\n+\"\"\")\n \n     return project\n \n \n async def test_01_analyze_code_community(test_project):\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_type_evaporation_scan_checklist_gaps.py\t2026-02-01 21:50:07.346469+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_type_evaporation_scan_checklist_gaps.py\t2026-02-01 23:23:07.881419+00:00\n@@ -477,20 +477,18 @@\n     import time\n \n     # Create 500 virtual files with complex patterns\n     frontend_segments = []\n     for i in range(500):\n-        frontend_segments.append(\n-            f\"\"\"// FILE: complex{i}.ts\n+        frontend_segments.append(f\"\"\"// FILE: complex{i}.ts\n interface Data{i} {{ id: string; value: number; }}\n async function process{i}() {{\n   const r = await fetch('/api/data{i}');\n   const data: Data{i} = await r.json();\n   return {{ id: data.id, calculated: data.value * 2 }};\n }}\n-\"\"\"\n-        )\n+\"\"\")\n     frontend_code = \"\\n\".join(frontend_segments)\n \n     backend_code = \"\"\"\n from fastapi import FastAPI\n from pydantic import BaseModel\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_oracle_middleware.py\t2026-02-01 15:55:14.728947+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_oracle_middleware.py\t2026-02-01 23:23:08.088819+00:00\n@@ -64,22 +64,20 @@\n         assert any(\"process_data\" in str(r.get(\"symbol\", \"\")) for r in result)\n \n     def test_suggest_with_file_code(self, tmp_path: Path):\n         \"\"\"Should generate suggestions from file content.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def calculate_sum(a, b):\n     return a + b\n \n def calculate_product(x, y):\n     return x * y\n \n def calculate_diff(p, q):\n     return p - q\n-\"\"\"\n-        )\n+\"\"\")\n \n         context = {\n             \"file_path\": str(test_file),\n             \"symbol_name\": \"calculate_sum_total\",  # Typo\n         }\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_mcp.py\t2026-02-01 21:50:07.839277+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_mcp.py\t2026-02-01 23:23:08.139266+00:00\n@@ -1350,12 +1350,11 @@\n     @pytest.fixture\n     def multi_file_project(self, tmp_path):\n         \"\"\"Create a multi-file project for cross-file tests.\"\"\"\n         # models.py\n         models_py = tmp_path / \"models.py\"\n-        models_py.write_text(\n-            '''\"\"\"Models module.\"\"\"\n+        models_py.write_text('''\"\"\"Models module.\"\"\"\n \n class TaxRate:\n     \"\"\"Tax rate configuration.\"\"\"\n \n     def __init__(self, rate: float):\n@@ -1366,17 +1365,15 @@\n \n \n def get_default_rate() -> float:\n     \"\"\"Get the default tax rate.\"\"\"\n     return 0.1\n-'''\n-        )\n+''')\n \n         # utils.py\n         utils_py = tmp_path / \"utils.py\"\n-        utils_py.write_text(\n-            '''\"\"\"Utilities module.\"\"\"\n+        utils_py.write_text('''\"\"\"Utilities module.\"\"\"\n \n from models import TaxRate, get_default_rate\n \n \n def calculate_tax(amount: float) -> float:\n@@ -1386,12 +1383,11 @@\n \n \n def simple_function():\n     \"\"\"No external dependencies.\"\"\"\n     return 42\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     async def test_cross_file_deps_resolves_class(\n         self, multi_file_project, monkeypatch\n@@ -1565,12 +1561,11 @@\n         \"\"\"Test basic file context extraction.\"\"\"\n         from code_scalpel.mcp.server import get_file_context\n \n         # Create a test file\n         test_file = tmp_path / \"test_module.py\"\n-        test_file.write_text(\n-            '''\n+        test_file.write_text('''\n \"\"\"A test module.\"\"\"\n \n import os\n from pathlib import Path\n \n@@ -1581,12 +1576,11 @@\n class MyClass:\n     \"\"\"A test class.\"\"\"\n     \n     def method(self):\n         return \"hello\"\n-'''\n-        )\n+''')\n \n         result = await get_file_context(str(test_file))\n \n         assert result.success is True\n         assert result.language == \"python\"\n@@ -1606,16 +1600,14 @@\n     async def test_get_file_context_security_issues(self, tmp_path):\n         \"\"\"Test file context detects security issues.\"\"\"\n         from code_scalpel.mcp.server import get_file_context\n \n         test_file = tmp_path / \"vulnerable.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def dangerous_eval(user_input):\n     return eval(user_input)  # Security issue!\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_file_context(str(test_file))\n \n         assert result.success is True\n         assert result.has_security_issues is True\n@@ -1646,24 +1638,22 @@\n     async def test_get_file_context_exports(self, tmp_path):\n         \"\"\"Test detection of __all__ exports.\"\"\"\n         from code_scalpel.mcp.server import get_file_context\n \n         test_file = tmp_path / \"exports.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n __all__ = [\"public_func\", \"PublicClass\"]\n \n def public_func():\n     pass\n \n def _private_func():\n     pass\n \n class PublicClass:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_file_context(str(test_file))\n \n         assert result.success is True\n         assert \"public_func\" in result.exports\n@@ -1677,38 +1667,32 @@\n         \"\"\"Test finding all references to a function.\"\"\"\n         from code_scalpel.mcp.server import get_symbol_references\n \n         # Create multiple files that reference a function\n         utils_file = tmp_path / \"utils.py\"\n-        utils_file.write_text(\n-            '''\n+        utils_file.write_text('''\n def helper_function():\n     \"\"\"The helper function definition.\"\"\"\n     return 42\n-'''\n-        )\n+''')\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from utils import helper_function\n \n def main():\n     result = helper_function()\n     return result\n-\"\"\"\n-        )\n+\"\"\")\n \n         test_file = tmp_path / \"test_utils.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n from utils import helper_function\n \n def test_helper():\n     assert helper_function() == 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_symbol_references(\"helper_function\", str(tmp_path))\n \n         assert result.success is True\n         assert result.symbol_name == \"helper_function\"\n@@ -1718,27 +1702,23 @@\n     async def test_find_class_references(self, tmp_path):\n         \"\"\"Test finding all references to a class.\"\"\"\n         from code_scalpel.mcp.server import get_symbol_references\n \n         models_file = tmp_path / \"models.py\"\n-        models_file.write_text(\n-            \"\"\"\n+        models_file.write_text(\"\"\"\n class User:\n     def __init__(self, name):\n         self.name = name\n-\"\"\"\n-        )\n+\"\"\")\n \n         service_file = tmp_path / \"service.py\"\n-        service_file.write_text(\n-            \"\"\"\n+        service_file.write_text(\"\"\"\n from models import User\n \n def create_user(name):\n     return User(name)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_symbol_references(\"User\", str(tmp_path))\n \n         assert result.success is True\n         assert result.total_references >= 2  # Definition + 1 usage\n@@ -1781,18 +1761,16 @@\n     async def test_reference_context_included(self, tmp_path):\n         \"\"\"Test that context snippets are included in references.\"\"\"\n         from code_scalpel.mcp.server import get_symbol_references\n \n         test_file = tmp_path / \"code.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def target_function():\n     return \"result\"\n \n result = target_function()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_symbol_references(\"target_function\", str(tmp_path))\n \n         assert result.success is True\n         # All references should have context\n@@ -1815,29 +1793,25 @@\n         \"\"\"Test extracting a function with dependencies from another file.\"\"\"\n         from code_scalpel.mcp.server import get_cross_file_dependencies\n \n         # Create utils.py with a helper function\n         utils_file = tmp_path / \"utils.py\"\n-        utils_file.write_text(\n-            \"\"\"\n+        utils_file.write_text(\"\"\"\n def format_string(s):\n     \\\"\\\"\\\"Format a string.\\\"\\\"\\\"\n     return s.strip().upper()\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create main.py that uses the helper\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from utils import format_string\n \n def process_data(data):\n     \\\"\\\"\\\"Process data using utility function.\\\"\\\"\\\"\n     return format_string(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_cross_file_dependencies(\n             target_file=\"main.py\",\n             target_symbol=\"process_data\",\n             project_root=str(tmp_path),\n@@ -1855,26 +1829,22 @@\n     async def test_combined_code_generation(self, tmp_path):\n         \"\"\"Test that combined code is generated correctly.\"\"\"\n         from code_scalpel.mcp.server import get_cross_file_dependencies\n \n         helper_file = tmp_path / \"helper.py\"\n-        helper_file.write_text(\n-            \"\"\"\n+        helper_file.write_text(\"\"\"\n def helper():\n     return \"help\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n from helper import helper\n \n def main():\n     return helper()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_cross_file_dependencies(\n             target_file=\"main.py\",\n             target_symbol=\"main\",\n             project_root=str(tmp_path),\n@@ -1889,16 +1859,14 @@\n     async def test_without_code_inclusion(self, tmp_path):\n         \"\"\"Test extraction without including full code.\"\"\"\n         from code_scalpel.mcp.server import get_cross_file_dependencies\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def target_func():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_cross_file_dependencies(\n             target_file=\"main.py\",\n             target_symbol=\"target_func\",\n             project_root=str(tmp_path),\n@@ -1915,26 +1883,22 @@\n         \"\"\"Test that Mermaid diagram is generated.\"\"\"\n         from code_scalpel.mcp.server import get_cross_file_dependencies\n \n         # Create files with imports\n         a_file = tmp_path / \"a.py\"\n-        a_file.write_text(\n-            \"\"\"\n+        a_file.write_text(\"\"\"\n def func_a():\n     return 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         b_file = tmp_path / \"b.py\"\n-        b_file.write_text(\n-            \"\"\"\n+        b_file.write_text(\"\"\"\n from a import func_a\n \n def func_b():\n     return func_a() + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_cross_file_dependencies(\n             target_file=\"b.py\",\n             target_symbol=\"func_b\",\n             project_root=str(tmp_path),\n@@ -1984,28 +1948,24 @@\n         \"\"\"Test detection of circular imports.\"\"\"\n         from code_scalpel.mcp.server import get_cross_file_dependencies\n \n         # Create circular import situation\n         a_file = tmp_path / \"a.py\"\n-        a_file.write_text(\n-            \"\"\"\n+        a_file.write_text(\"\"\"\n from b import func_b\n \n def func_a():\n     return func_b()\n-\"\"\"\n-        )\n+\"\"\")\n \n         b_file = tmp_path / \"b.py\"\n-        b_file.write_text(\n-            \"\"\"\n+        b_file.write_text(\"\"\"\n from a import func_a\n \n def func_b():\n     return func_a()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_cross_file_dependencies(\n             target_file=\"a.py\",\n             target_symbol=\"func_a\",\n             project_root=str(tmp_path),\n@@ -2019,36 +1979,30 @@\n         \"\"\"Test that max_depth limits dependency resolution.\"\"\"\n         from code_scalpel.mcp.server import get_cross_file_dependencies\n \n         # Create a chain of dependencies\n         c_file = tmp_path / \"c.py\"\n-        c_file.write_text(\n-            \"\"\"\n+        c_file.write_text(\"\"\"\n def func_c():\n     return \"c\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         b_file = tmp_path / \"b.py\"\n-        b_file.write_text(\n-            \"\"\"\n+        b_file.write_text(\"\"\"\n from c import func_c\n \n def func_b():\n     return func_c()\n-\"\"\"\n-        )\n+\"\"\")\n \n         a_file = tmp_path / \"a.py\"\n-        a_file.write_text(\n-            \"\"\"\n+        a_file.write_text(\"\"\"\n from b import func_b\n \n def func_a():\n     return func_b()\n-\"\"\"\n-        )\n+\"\"\")\n \n         # With max_depth=1, should only get immediate dependencies\n         result = await get_cross_file_dependencies(\n             target_file=\"a.py\",\n             target_symbol=\"func_a\",\n@@ -2070,16 +2024,14 @@\n     async def test_no_vulnerabilities(self, tmp_path):\n         \"\"\"Test scanning code with no vulnerabilities.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         safe_file = tmp_path / \"safe.py\"\n-        safe_file.write_text(\n-            \"\"\"\n+        safe_file.write_text(\"\"\"\n def safe_function(x):\n     return x * 2\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(project_root=str(tmp_path))\n \n         assert result.success is True\n         assert result.has_vulnerabilities is False\n@@ -2090,34 +2042,30 @@\n         \"\"\"Test detecting SQL injection across files.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         # Create routes.py with user input\n         routes_file = tmp_path / \"routes.py\"\n-        routes_file.write_text(\n-            \"\"\"\n+        routes_file.write_text(\"\"\"\n from flask import request\n from db import execute_query\n \n def search():\n     query = request.args.get('q')\n     return execute_query(query)\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create db.py with SQL execution\n         db_file = tmp_path / \"db.py\"\n-        db_file.write_text(\n-            \"\"\"\n+        db_file.write_text(\"\"\"\n import sqlite3\n \n def execute_query(query):\n     conn = sqlite3.connect('db.sqlite')\n     cursor = conn.cursor()\n     cursor.execute(f\"SELECT * FROM users WHERE name = '{query}'\")\n     return cursor.fetchall()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(project_root=str(tmp_path))\n \n         assert result.success is True\n         assert result.files_analyzed >= 2\n@@ -2125,44 +2073,38 @@\n     async def test_taint_flow_detection(self, tmp_path):\n         \"\"\"Test that taint flows are detected across files.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         input_file = tmp_path / \"input.py\"\n-        input_file.write_text(\n-            \"\"\"\n+        input_file.write_text(\"\"\"\n def get_user_input():\n     return input(\"Enter data: \")\n-\"\"\"\n-        )\n+\"\"\")\n \n         process_file = tmp_path / \"process.py\"\n-        process_file.write_text(\n-            \"\"\"\n+        process_file.write_text(\"\"\"\n from input import get_user_input\n import os\n \n def process():\n     data = get_user_input()\n     os.system(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(project_root=str(tmp_path))\n \n         assert result.success is True\n \n     async def test_mermaid_diagram_for_security(self, tmp_path):\n         \"\"\"Test that security scan generates Mermaid diagram.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def test_func():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(tmp_path), include_diagram=True\n         )\n \n@@ -2182,19 +2124,17 @@\n     async def test_entry_points_filtering(self, tmp_path):\n         \"\"\"Test that entry_points parameter filters analysis.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def main():\n     return \"main\"\n \n def other():\n     return \"other\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(tmp_path),\n             entry_points=[\"main.py:main\"],\n         )\n@@ -2204,16 +2144,14 @@\n     async def test_max_depth_for_security(self, tmp_path):\n         \"\"\"Test that max_depth limits security analysis.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def test():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(tmp_path),\n             max_depth=2,\n         )\n@@ -2224,16 +2162,14 @@\n         \"\"\"Test that risk level is calculated correctly.\"\"\"\n         from code_scalpel.mcp.server import cross_file_security_scan\n \n         # Create safe code\n         safe_file = tmp_path / \"safe.py\"\n-        safe_file.write_text(\n-            \"\"\"\n+        safe_file.write_text(\"\"\"\n def safe_func():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(project_root=str(tmp_path))\n \n         assert result.success is True\n         assert result.risk_level in [\"low\", \"medium\", \"high\", \"critical\"]\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_type_evaporation_scan_tiers.py\t2026-02-01 16:25:16.907494+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_type_evaporation_scan_tiers.py\t2026-02-01 23:23:08.350980+00:00\n@@ -421,13 +421,11 @@\n   const data = await resp.json();\n   return data;\n }\n \n // add some scale\n-\"\"\" + \"\\n\".join(\n-        [\"// filler line\" for _ in range(300)]\n-    )\n+\"\"\" + \"\\n\".join([\"// filler line\" for _ in range(300)])\n \n     backend_code = \"\"\"\n from fastapi import FastAPI, Request\n app = FastAPI()\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_cross_file_security_scan_regression.py\t2026-02-01 15:55:14.799777+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_cross_file_security_scan_regression.py\t2026-02-01 23:23:08.377907+00:00\n@@ -18,12 +18,11 @@\n def test_cross_file_sql_injection_flow_detected(tmp_path: Path):\n     pkg = tmp_path / \"crossfile_hard\"\n     pkg.mkdir()\n     (pkg / \"__init__.py\").write_text(\"# test package\\n\")\n \n-    (pkg / \"routes.py\").write_text(\n-        \"\"\"\\\n+    (pkg / \"routes.py\").write_text(\"\"\"\\\n from flask import Flask, request\n from .services import search_users, search_users_safe\n \n app = Flask(__name__)\n \n@@ -34,51 +33,44 @@\n \n @app.get('/search-safe')\n def search_route_safe() -> str:\n     q = request.args.get('q', '')\n     return search_users_safe(q)\n-\"\"\"\n-    )\n+\"\"\")\n \n-    (pkg / \"sanitizers.py\").write_text(\n-        \"\"\"\\\n+    (pkg / \"sanitizers.py\").write_text(\"\"\"\\\n def sanitize_decoy(value: str) -> str:\n     return value\n \n def sanitize_allowlist_alpha(value: str) -> str:\n     return ''.join(ch for ch in value if ch.isalnum() or ch in {'_', '-'})\n-\"\"\"\n-    )\n+\"\"\")\n \n-    (pkg / \"services.py\").write_text(\n-        \"\"\"\\\n+    (pkg / \"services.py\").write_text(\"\"\"\\\n from . import sanitizers as s\n from .db import run_query as rq\n \n def search_users(raw_query: str) -> str:\n     query = s.sanitize_decoy(raw_query)\n     return rq(query)\n \n def search_users_safe(raw_query: str) -> str:\n     query = s.sanitize_allowlist_alpha(raw_query)\n     return rq(query)\n-\"\"\"\n-    )\n+\"\"\")\n \n-    (pkg / \"db.py\").write_text(\n-        \"\"\"\\\n+    (pkg / \"db.py\").write_text(\"\"\"\\\n import sqlite3\n \n def run_query(user_supplied: str) -> str:\n     sql = f\"SELECT * FROM users WHERE name = '{user_supplied}'\"\n     conn = sqlite3.connect(':memory:')\n     cur = conn.cursor()\n     cur.execute(sql)\n     conn.close()\n     return sql\n-\"\"\"\n-    )\n+\"\"\")\n \n     tracker = CrossFileTaintTracker(tmp_path)\n     result = tracker.analyze(max_depth=8, timeout_seconds=10.0, max_modules=100)\n \n     assert result.success is True\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_adversarial.py\t2026-02-01 15:55:14.786507+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_adversarial.py\t2026-02-01 23:23:08.587467+00:00\n@@ -287,17 +287,15 @@\n     async def test_security_scan_large_codebase(self):\n         \"\"\"Security scan on large codebase should complete.\"\"\"\n         # Generate code with many potential vulnerabilities\n         vulnerable_funcs = []\n         for i in range(50):\n-            vulnerable_funcs.append(\n-                f\"\"\"\n+            vulnerable_funcs.append(f\"\"\"\n def vulnerable_{i}(user_input):\n     query = f\"SELECT * FROM table WHERE id={{user_input}}\"\n     cursor.execute(query)\n-\"\"\"\n-            )  # noqa: S608 -- intentional vulnerability in test data\n+\"\"\")  # noqa: S608 -- intentional vulnerability in test data\n         code = \"\\n\".join(vulnerable_funcs)\n \n         result = await security_scan(code=code)\n         assert result.success\n         assert result.vulnerability_count > 0\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_type_narrowing_extra.py\t2026-02-01 15:55:14.827030+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_type_narrowing_extra.py\t2026-02-01 23:23:09.090982+00:00\n@@ -10,20 +10,18 @@\n \n # [20251216_TEST] Cover regex fallback and taint helpers\n \n \n def test_regex_fallback_tracks_negated_predicates_and_truthy_guards() -> None:\n-    code = dedent(\n-        \"\"\"\n+    code = dedent(\"\"\"\n         if (!isValid(value)) {\n           doThing(value);\n         }\n         if (typeof value === 'number') {\n           return value + 1;\n         }\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     narrowing = TypeNarrowing()\n     result = narrowing.analyze(code)\n \n     # First guard is negated predicate; narrowing should not apply in else branch\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_adversarial_security.py\t2026-02-01 15:55:14.792757+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_adversarial_security.py\t2026-02-01 23:23:09.109482+00:00\n@@ -36,45 +36,39 @@\n     @pytest.mark.asyncio\n     async def test_taint_through_import_chain(self, temp_project):\n         \"\"\"Taint should be tracked through import chain: A -> B -> C.\"\"\"\n         # File A: Source of taint\n         file_a = temp_project / \"source.py\"\n-        file_a.write_text(\n-            \"\"\"\n+        file_a.write_text(\"\"\"\n from flask import request\n \n def get_user_input():\n     return request.args.get(\"user_id\")  # TAINT SOURCE\n-\"\"\"\n-        )\n+\"\"\")\n \n         # File B: Intermediate processing\n         file_b = temp_project / \"processor.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from source import get_user_input\n \n def process_input():\n     data = get_user_input()  # Receives taint\n     return data.strip()  # Still tainted after transform\n-\"\"\"\n-        )\n+\"\"\")\n \n         # File C: Sink\n         file_c = temp_project / \"executor.py\"\n-        file_c.write_text(\n-            \"\"\"\n+        file_c.write_text(\"\"\"\n from processor import process_input\n import sqlite3\n \n def execute_query():\n     user_id = process_input()  # Tainted\n     conn = sqlite3.connect(\"db.sqlite\")\n     cursor = conn.cursor()\n     cursor.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # SINK!\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"executor.py\"]\n         )\n \n@@ -84,35 +78,31 @@\n \n     @pytest.mark.asyncio\n     async def test_taint_through_async_chain(self, temp_project):\n         \"\"\"Taint should be tracked through async/await chain.\"\"\"\n         file_a = temp_project / \"async_source.py\"\n-        file_a.write_text(\n-            \"\"\"\n+        file_a.write_text(\"\"\"\n async def fetch_user_data(user_id: str) -> dict:\n     # user_id is tainted (from user input)\n     return {\"id\": user_id, \"name\": \"Unknown\"}\n \n async def process_user(user_id: str):\n     data = await fetch_user_data(user_id)  # Taint propagates\n     return data[\"id\"]  # Still tainted\n-\"\"\"\n-        )\n+\"\"\")\n \n         file_b = temp_project / \"async_sink.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from async_source import process_user\n import asyncio\n \n async def dangerous_async(request_id: str):\n     user = await process_user(request_id)\n     # Taint should reach here\n     query = f\"DELETE FROM users WHERE id = {user}\"\n     return query\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"async_sink.py\"]\n         )\n \n@@ -120,36 +110,32 @@\n \n     @pytest.mark.asyncio\n     async def test_taint_through_callback(self, temp_project):\n         \"\"\"Taint should be tracked through callback pattern.\"\"\"\n         file_a = temp_project / \"callback_source.py\"\n-        file_a.write_text(\n-            \"\"\"\n+        file_a.write_text(\"\"\"\n def with_callback(data, callback):\n     result = callback(data)\n     return result\n \n def identity(x):\n     return x\n-\"\"\"\n-        )\n+\"\"\")\n \n         file_b = temp_project / \"callback_sink.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from callback_source import with_callback\n from flask import request\n import os\n \n def dangerous_callback(cmd):\n     os.system(cmd)  # SINK\n \n def handle_request():\n     user_cmd = request.args.get(\"cmd\")  # SOURCE\n     with_callback(user_cmd, dangerous_callback)  # Taint flows through callback\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"callback_sink.py\"]\n         )\n \n@@ -158,26 +144,23 @@\n \n     @pytest.mark.asyncio\n     async def test_taint_through_decorator(self, temp_project):\n         \"\"\"Taint should be tracked through decorator wrapper.\"\"\"\n         file_a = temp_project / \"decorators.py\"\n-        file_a.write_text(\n-            \"\"\"\n+        file_a.write_text(\"\"\"\n from functools import wraps\n \n def log_input(func):\n     @wraps(func)\n     def wrapper(data, *args, **kwargs):\n         print(f\"Input: {data}\")  # Taint passes through\n         return func(data, *args, **kwargs)\n     return wrapper\n-\"\"\"\n-        )\n+\"\"\")\n \n         file_b = temp_project / \"decorated_sink.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from decorators import log_input\n from flask import request\n import subprocess\n \n @log_input\n@@ -185,12 +168,11 @@\n     subprocess.run(command, shell=True)  # SINK\n \n def handler():\n     cmd = request.form.get(\"command\")  # SOURCE\n     execute(cmd)  # Taint flows through decorator\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"decorated_sink.py\"]\n         )\n \n@@ -198,27 +180,24 @@\n \n     @pytest.mark.asyncio\n     async def test_taint_sanitizer_clears(self, temp_project):\n         \"\"\"Sanitizer should clear taint.\"\"\"\n         file_a = temp_project / \"sanitizers.py\"\n-        file_a.write_text(\n-            r'''\n+        file_a.write_text(r'''\n import re\n \n def sanitize_id(user_id: str) -> int:\n     \"\"\"Converts to int - clears taint.\"\"\"\n     return int(user_id)  # SANITIZER\n \n def sanitize_input(data: str) -> str:\n     \"\"\"Escapes special chars - clears taint.\"\"\"\n     return re.sub(r'[^\\w]', '', data)  # SANITIZER\n-'''\n-        )\n+''')\n \n         file_b = temp_project / \"safe_sink.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from sanitizers import sanitize_id\n from flask import request\n import sqlite3\n \n def safe_query():\n@@ -227,12 +206,11 @@\n     \n     conn = sqlite3.connect(\"db.sqlite\")\n     cursor = conn.cursor()\n     # This should be SAFE because sanitize_id converted to int\n     cursor.execute(f\"SELECT * FROM users WHERE id = {safe_id}\")\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"safe_sink.py\"]\n         )\n \n@@ -242,38 +220,34 @@\n \n     @pytest.mark.asyncio\n     async def test_taint_through_context_manager(self, temp_project):\n         \"\"\"Taint should be tracked through context manager.\"\"\"\n         file_a = temp_project / \"context_manager.py\"\n-        file_a.write_text(\n-            \"\"\"\n+        file_a.write_text(\"\"\"\n class DataProcessor:\n     def __init__(self, data):\n         self.data = data  # May be tainted\n     \n     def __enter__(self):\n         return self.data  # Taint propagates\n     \n     def __exit__(self, *args):\n         pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         file_b = temp_project / \"context_sink.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from context_manager import DataProcessor\n from flask import request\n import os\n \n def process_request():\n     user_input = request.args.get(\"cmd\")  # SOURCE\n     \n     with DataProcessor(user_input) as data:\n         os.system(data)  # SINK - taint came through __enter__\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"context_sink.py\"]\n         )\n \n@@ -281,24 +255,21 @@\n \n     @pytest.mark.asyncio\n     async def test_taint_through_class_inheritance(self, temp_project):\n         \"\"\"Taint should be tracked through class inheritance.\"\"\"\n         file_a = temp_project / \"base_handler.py\"\n-        file_a.write_text(\n-            \"\"\"\n+        file_a.write_text(\"\"\"\n class BaseHandler:\n     def __init__(self, data):\n         self.data = data\n     \n     def get_data(self):\n         return self.data  # Returns potentially tainted data\n-\"\"\"\n-        )\n+\"\"\")\n \n         file_b = temp_project / \"derived_handler.py\"\n-        file_b.write_text(\n-            \"\"\"\n+        file_b.write_text(\"\"\"\n from base_handler import BaseHandler\n from flask import request\n import subprocess\n \n class CommandHandler(BaseHandler):\n@@ -308,12 +279,11 @@\n \n def handle():\n     user_cmd = request.args.get(\"cmd\")  # SOURCE\n     handler = CommandHandler(user_cmd)\n     handler.execute()  # Taint flows through inheritance\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"derived_handler.py\"]\n         )\n \n@@ -328,25 +298,22 @@\n             'JdbcTemplate.batchUpdate(f\"delete from users where name = {name}\")',\n         ],\n     )\n     async def test_spring_jpa_cross_file_sink_detected(self, temp_project, sink_call):\n         controller = temp_project / \"controller.py\"\n-        controller.write_text(\n-            \"\"\"\n+        controller.write_text(\"\"\"\n from flask import request\n from repo import run_query\n \n \n def handler():\n     name = request.args.get(\"name\")  # SOURCE\n     return run_query(name)\n-\"\"\"\n-        )\n+\"\"\")\n \n         repo = temp_project / \"repo.py\"\n-        repo.write_text(\n-            f\"\"\"\n+        repo.write_text(f\"\"\"\n class EntityManager:\n     def createNamedQuery(self, query):\n         return query\n \n \n@@ -360,12 +327,11 @@\n \n \n def run_query(name):\n     # [20251215_TEST] Taint should reach Spring/JPA sink\n     return {sink_call}\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await cross_file_security_scan(\n             project_root=str(temp_project), entry_points=[\"controller.py\"]\n         )\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_refactor_simulator.py\t2026-02-01 15:55:14.805868+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_refactor_simulator.py\t2026-02-01 23:23:09.299558+00:00\n@@ -789,17 +789,15 @@\n         from code_scalpel.generators import RefactorSimulator\n \n         # Create a temp project with a test file\n         with tempfile.TemporaryDirectory() as tmpdir:\n             test_file = Path(tmpdir) / \"test_utils.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def test_calculate_tax():\n     from utils import calculate_tax\n     assert calculate_tax(100) == 10\n-\"\"\"\n-            )\n+\"\"\")\n \n             original = \"def calculate_tax(amount): return amount * 0.1\"\n             new_code = \"def different_func(): pass\"\n \n             simulator = RefactorSimulator()\n--- /mnt/k/backup/Develop/code-scalpel/tests/mcp_tool_verification/test_mcp_tools_live.py\t2026-02-01 22:58:27.834964+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/mcp_tool_verification/test_mcp_tools_live.py\t2026-02-01 23:23:09.465484+00:00\n@@ -727,43 +727,37 @@\n         from code_scalpel.ast_tools.call_graph import CallGraphBuilder\n         from code_scalpel.project_crawler import ProjectCrawler\n \n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create a mini project structure\n-            (Path(tmpdir) / \"main.py\").write_text(\n-                '''\n+            (Path(tmpdir) / \"main.py\").write_text('''\n def main():\n     \"\"\"Main entry point.\"\"\"\n     from utils import helper\n     return helper()\n \n if __name__ == \"__main__\":\n     main()\n-'''\n-            )\n-            (Path(tmpdir) / \"utils.py\").write_text(\n-                '''\n+''')\n+            (Path(tmpdir) / \"utils.py\").write_text('''\n def helper():\n     \"\"\"Helper function.\"\"\"\n     return 42\n \n def unused_func():\n     \"\"\"This function is never called.\"\"\"\n     pass\n-'''\n-            )\n-            (Path(tmpdir) / \"models.py\").write_text(\n-                '''\n+''')\n+            (Path(tmpdir) / \"models.py\").write_text('''\n class User:\n     \"\"\"User model.\"\"\"\n     def __init__(self, name: str):\n         self.name = name\n     \n     def greet(self) -> str:\n         return f\"Hello, {self.name}\"\n-'''\n-            )\n+''')\n \n             # Test project crawling (underlying functionality of get_project_map)\n             crawler = ProjectCrawler(tmpdir)\n             result = crawler.crawl()\n \n@@ -815,26 +809,22 @@\n         \"\"\"Test get_project_map detects circular imports.\"\"\"\n         from code_scalpel.ast_tools.call_graph import CallGraphBuilder\n \n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create circular import structure\n-            (Path(tmpdir) / \"module_a.py\").write_text(\n-                \"\"\"\n+            (Path(tmpdir) / \"module_a.py\").write_text(\"\"\"\n from module_b import func_b\n \n def func_a():\n     return func_b()\n-\"\"\"\n-            )\n-            (Path(tmpdir) / \"module_b.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            (Path(tmpdir) / \"module_b.py\").write_text(\"\"\"\n from module_a import func_a\n \n def func_b():\n     return func_a()\n-\"\"\"\n-            )\n+\"\"\")\n \n             builder = CallGraphBuilder(Path(tmpdir))\n             circular_imports = builder.detect_circular_imports()\n \n             # Should detect the circular import\n@@ -846,27 +836,23 @@\n         \"\"\"Test get_cross_file_dependencies resolves imports across files.\"\"\"\n         from code_scalpel.surgical_extractor import SurgicalExtractor\n \n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create inter-dependent files\n-            (Path(tmpdir) / \"models.py\").write_text(\n-                '''\n+            (Path(tmpdir) / \"models.py\").write_text('''\n class TaxRate:\n     \"\"\"Tax rate configuration.\"\"\"\n     STANDARD = 0.2\n     REDUCED = 0.05\n-'''\n-            )\n-            (Path(tmpdir) / \"calculator.py\").write_text(\n-                '''\n+''')\n+            (Path(tmpdir) / \"calculator.py\").write_text('''\n from models import TaxRate\n \n def calculate_tax(amount: float) -> float:\n     \"\"\"Calculate tax using standard rate.\"\"\"\n     return amount * TaxRate.STANDARD\n-'''\n-            )\n+''')\n \n             # Extract with cross-file dependencies\n             extractor = SurgicalExtractor.from_file(str(Path(tmpdir) / \"calculator.py\"))\n             result = extractor.resolve_cross_file_dependencies(\n                 target_name=\"calculate_tax\", target_type=\"function\", max_depth=2\n@@ -901,34 +887,28 @@\n         \"\"\"Test get_cross_file_dependencies generates Mermaid diagrams.\"\"\"\n         # Mermaid diagram generation is tested via call graph\n         from code_scalpel.ast_tools.call_graph import CallGraphBuilder\n \n         with tempfile.TemporaryDirectory() as tmpdir:\n-            (Path(tmpdir) / \"app.py\").write_text(\n-                \"\"\"\n+            (Path(tmpdir) / \"app.py\").write_text(\"\"\"\n from db import get_user\n from cache import check_cache\n \n def handle_request(user_id):\n     cached = check_cache(user_id)\n     if cached:\n         return cached\n     return get_user(user_id)\n-\"\"\"\n-            )\n-            (Path(tmpdir) / \"db.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            (Path(tmpdir) / \"db.py\").write_text(\"\"\"\n def get_user(user_id):\n     return {\"id\": user_id}\n-\"\"\"\n-            )\n-            (Path(tmpdir) / \"cache.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            (Path(tmpdir) / \"cache.py\").write_text(\"\"\"\n def check_cache(key):\n     return None\n-\"\"\"\n-            )\n+\"\"\")\n \n             builder = CallGraphBuilder(Path(tmpdir))\n             result = builder.build_with_details(entry_point=\"handle_request\", depth=5)\n \n             # Mermaid diagram should be generated\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_simulate_refactor_edge_cases_comprehensive.py\t2026-02-01 15:55:14.820522+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_simulate_refactor_edge_cases_comprehensive.py\t2026-02-01 23:23:09.503911+00:00\n@@ -555,13 +555,11 @@\n     pass\n \n def func_2():\n     pass\n \n-\"\"\" + \"\\n\".join(\n-            [f\"def func_{i}(): pass\" for i in range(3, 50)]\n-        )\n+\"\"\" + \"\\n\".join([f\"def func_{i}(): pass\" for i in range(3, 50)])\n \n         async def run_large_async():\n             simulator = RefactorSimulator()\n             result = simulator.simulate(\n                 original_code=large_code,\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_vulnerability_scanner.py\t2026-02-01 15:55:14.841155+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_vulnerability_scanner.py\t2026-02-01 23:23:09.497310+00:00\n@@ -94,12 +94,11 @@\n     \"\"\"Tests for pom.xml parsing.\"\"\"\n \n     def test_parse_basic_pom(self, tmp_path: Path):\n         \"\"\"Test parsing basic pom.xml.\"\"\"\n         pom_xml = tmp_path / \"pom.xml\"\n-        pom_xml.write_text(\n-            \"\"\"<?xml version=\"1.0\"?>\n+        pom_xml.write_text(\"\"\"<?xml version=\"1.0\"?>\n <project>\n     <dependencies>\n         <dependency>\n             <groupId>org.springframework</groupId>\n             <artifactId>spring-core</artifactId>\n@@ -111,12 +110,11 @@\n             <version>4.13.2</version>\n             <scope>test</scope>\n         </dependency>\n     </dependencies>\n </project>\n-\"\"\"\n-        )\n+\"\"\")\n \n         deps = DependencyParser.parse_pom_xml(pom_xml)\n \n         assert len(deps) == 2\n         assert any(\n@@ -126,46 +124,42 @@\n         assert any(d.name == \"junit:junit\" and d.is_dev for d in deps)\n \n     def test_parse_pom_with_namespace(self, tmp_path: Path):\n         \"\"\"Test parsing pom.xml with Maven namespace.\"\"\"\n         pom_xml = tmp_path / \"pom.xml\"\n-        pom_xml.write_text(\n-            \"\"\"<?xml version=\"1.0\"?>\n+        pom_xml.write_text(\"\"\"<?xml version=\"1.0\"?>\n <project xmlns=\"http://maven.apache.org/POM/4.0.0\">\n     <dependencies>\n         <dependency>\n             <groupId>com.google.guava</groupId>\n             <artifactId>guava</artifactId>\n             <version>31.1-jre</version>\n         </dependency>\n     </dependencies>\n </project>\n-\"\"\"\n-        )\n+\"\"\")\n \n         deps = DependencyParser.parse_pom_xml(pom_xml)\n \n         assert len(deps) == 1\n         assert deps[0].name == \"com.google.guava:guava\"\n         assert deps[0].version == \"31.1-jre\"\n \n     def test_skip_property_versions(self, tmp_path: Path):\n         \"\"\"Test that property reference versions are skipped.\"\"\"\n         pom_xml = tmp_path / \"pom.xml\"\n-        pom_xml.write_text(\n-            \"\"\"<?xml version=\"1.0\"?>\n+        pom_xml.write_text(\"\"\"<?xml version=\"1.0\"?>\n <project>\n     <dependencies>\n         <dependency>\n             <groupId>org.test</groupId>\n             <artifactId>test</artifactId>\n             <version>${project.version}</version>\n         </dependency>\n     </dependencies>\n </project>\n-\"\"\"\n-        )\n+\"\"\")\n \n         deps = DependencyParser.parse_pom_xml(pom_xml)\n         assert len(deps) == 0\n \n \n@@ -173,23 +167,21 @@\n     \"\"\"Tests for build.gradle parsing.\"\"\"\n \n     def test_parse_string_notation(self, tmp_path: Path):\n         \"\"\"Test parsing Gradle string notation dependencies.\"\"\"\n         build_gradle = tmp_path / \"build.gradle\"\n-        build_gradle.write_text(\n-            \"\"\"\n+        build_gradle.write_text(\"\"\"\n plugins {\n     id 'java'\n }\n \n dependencies {\n     implementation 'org.springframework:spring-core:5.3.20'\n     testImplementation 'junit:junit:4.13.2'\n     api \"com.google.guava:guava:31.1-jre\"\n }\n-\"\"\"\n-        )\n+\"\"\")\n \n         deps = DependencyParser.parse_build_gradle(build_gradle)\n \n         assert len(deps) == 3\n         assert any(d.name == \"org.springframework:spring-core\" for d in deps)\n@@ -200,37 +192,33 @@\n     \"\"\"Tests for requirements.txt parsing.\"\"\"\n \n     def test_parse_basic_requirements(self, tmp_path: Path):\n         \"\"\"Test parsing basic requirements.txt.\"\"\"\n         requirements = tmp_path / \"requirements.txt\"\n-        requirements.write_text(\n-            \"\"\"\n+        requirements.write_text(\"\"\"\n # This is a comment\n requests==2.28.0\n flask>=2.0.0\n django~=4.0\n numpy<2.0\n-\"\"\"\n-        )\n+\"\"\")\n \n         deps = DependencyParser.parse_requirements_txt(requirements)\n \n         assert len(deps) == 4\n         assert any(d.name == \"requests\" and d.version == \"2.28.0\" for d in deps)\n         assert any(d.name == \"flask\" and d.version == \"2.0.0\" for d in deps)\n \n     def test_skip_comments_and_flags(self, tmp_path: Path):\n         \"\"\"Test that comments and pip flags are skipped.\"\"\"\n         requirements = tmp_path / \"requirements.txt\"\n-        requirements.write_text(\n-            \"\"\"\n+        requirements.write_text(\"\"\"\n # Comment\n -r other-requirements.txt\n --index-url https://pypi.org/simple\n requests==2.28.0\n-\"\"\"\n-        )\n+\"\"\")\n \n         deps = DependencyParser.parse_requirements_txt(requirements)\n \n         assert len(deps) == 1\n         assert deps[0].name == \"requests\"\n@@ -352,23 +340,21 @@\n         )\n \n         # Create pom.xml in subdirectory\n         subdir = tmp_path / \"backend\"\n         subdir.mkdir()\n-        (subdir / \"pom.xml\").write_text(\n-            \"\"\"<?xml version=\"1.0\"?>\n+        (subdir / \"pom.xml\").write_text(\"\"\"<?xml version=\"1.0\"?>\n <project>\n     <dependencies>\n         <dependency>\n             <groupId>org.apache.logging.log4j</groupId>\n             <artifactId>log4j-core</artifactId>\n             <version>2.14.0</version>\n         </dependency>\n     </dependencies>\n </project>\n-\"\"\"\n-        )\n+\"\"\")\n \n         mock_query_batch.return_value = {}  # No vulns for simplicity\n \n         scanner = VulnerabilityScanner()\n         result = scanner.scan_directory(tmp_path)\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_unified_sink_detector.py\t2026-02-01 15:55:14.832552+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_unified_sink_detector.py\t2026-02-01 23:23:09.641906+00:00\n@@ -103,17 +103,15 @@\n     \"\"\"Test SQL injection detection across languages.\"\"\"\n \n     def test_python_sql_injection_100_percent_confidence(self):\n         \"\"\"Python cursor.execute should be detected with 1.0 confidence.\"\"\"\n         detector = UnifiedSinkDetector()\n-        code = textwrap.dedent(\n-            \"\"\"\n+        code = textwrap.dedent(\"\"\"\n             import sqlite3\n             user_input = input()\n             cursor.execute(\"SELECT * FROM users WHERE id=\" + user_input)\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         sinks = detector.detect_sinks(code, \"python\", min_confidence=0.8)\n \n         assert len(sinks) > 0\n         sql_sinks = [s for s in sinks if s.sink_type == SecuritySink.SQL_QUERY]\n@@ -122,16 +120,14 @@\n         assert sql_sinks[0].pattern == \"cursor.execute\"\n \n     def test_python_sqlalchemy_execute_detected(self):\n         \"\"\"SQLAlchemy session.execute should be detected.\"\"\"\n         detector = UnifiedSinkDetector()\n-        code = textwrap.dedent(\n-            \"\"\"\n+        code = textwrap.dedent(\"\"\"\n             from sqlalchemy import create_engine\n             session.execute(\"SELECT * FROM users\")\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         sinks = detector.detect_sinks(code, \"python\", min_confidence=0.8)\n \n         assert len(sinks) > 0\n         sql_sinks = [s for s in sinks if s.pattern == \"session.execute\"]\n@@ -139,16 +135,14 @@\n         assert sql_sinks[0].confidence >= 0.95\n \n     def test_typescript_sql_injection_detected(self):\n         \"\"\"TypeScript connection.query should be detected.\"\"\"\n         detector = UnifiedSinkDetector()\n-        code = textwrap.dedent(\n-            \"\"\"\n+        code = textwrap.dedent(\"\"\"\n             const query = \"SELECT * FROM users WHERE id=\" + userId;\n             connection.query(query);\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         sinks = detector.detect_sinks(code, \"typescript\", min_confidence=0.8)\n \n         assert len(sinks) > 0\n         sql_sinks = [s for s in sinks if s.pattern == \"connection.query\"]\n@@ -320,33 +314,29 @@\n     \"\"\"Test confidence threshold filtering.\"\"\"\n \n     def test_high_confidence_filter(self):\n         \"\"\"Filtering at 1.0 should only return perfect matches.\"\"\"\n         detector = UnifiedSinkDetector()\n-        code = textwrap.dedent(\n-            \"\"\"\n+        code = textwrap.dedent(\"\"\"\n             cursor.execute(query)\n             open(filename)\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         sinks = detector.detect_sinks(code, \"python\", min_confidence=1.0)\n \n         # cursor.execute has 1.0 confidence, open has lower\n         assert len(sinks) >= 1\n         assert all(s.confidence == 1.0 for s in sinks)\n \n     def test_medium_confidence_filter(self):\n         \"\"\"Filtering at 0.8 should include most sinks.\"\"\"\n         detector = UnifiedSinkDetector()\n-        code = textwrap.dedent(\n-            \"\"\"\n+        code = textwrap.dedent(\"\"\"\n             cursor.execute(query)\n             open(filename)\n             session.execute(query)\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         sinks = detector.detect_sinks(code, \"python\", min_confidence=0.8)\n \n         # Should get cursor.execute (1.0) and session.execute (0.95)\n         assert len(sinks) >= 2\n@@ -527,22 +517,20 @@\n     \"\"\"Test false positive rate on clean code.\"\"\"\n \n     def test_clean_python_code_no_false_positives(self):\n         \"\"\"Clean Python code should not trigger false positives.\"\"\"\n         detector = UnifiedSinkDetector()\n-        code = textwrap.dedent(\n-            \"\"\"\n+        code = textwrap.dedent(\"\"\"\n             def calculate_total(items):\n                 total = 0\n                 for item in items:\n                     total += item.price\n                 return total\n             \n             def format_name(first, last):\n                 return f\"{first} {last}\"\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         sinks = detector.detect_sinks(code, \"python\", min_confidence=0.8)\n \n         # Should have no sinks in this clean code\n         assert len(sinks) == 0\n--- /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_security_analysis.py\t2026-02-01 15:55:14.814420+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_security_analysis.py\t2026-02-01 23:23:09.730074+00:00\n@@ -645,16 +645,14 @@\n         from code_scalpel.security.analyzers.taint_tracker import (\n             load_sanitizers_from_config,\n         )\n \n         config_file = tmp_path / \"pyproject.toml\"\n-        config_file.write_text(\n-            \"\"\"\n+        config_file.write_text(\"\"\"\n [tool.code-scalpel.sanitizers]\n \"my_utils.clean_sql\" = [\"SQL_QUERY\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         try:\n             count = load_sanitizers_from_config(str(config_file))\n             assert count == 1\n             assert \"my_utils.clean_sql\" in SANITIZER_REGISTRY\n@@ -670,16 +668,14 @@\n         from code_scalpel.security.analyzers.taint_tracker import (\n             load_sanitizers_from_config,\n         )\n \n         config_file = tmp_path / \"pyproject.toml\"\n-        config_file.write_text(\n-            \"\"\"\n+        config_file.write_text(\"\"\"\n [tool.code-scalpel.sanitizers]\n \"my_utils.super_clean\" = [\"ALL\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         try:\n             count = load_sanitizers_from_config(str(config_file))\n             assert count == 1\n             assert \"my_utils.super_clean\" in SANITIZER_REGISTRY\n@@ -694,18 +690,16 @@\n         from code_scalpel.security.analyzers.taint_tracker import (\n             load_sanitizers_from_config,\n         )\n \n         config_file = tmp_path / \"pyproject.toml\"\n-        config_file.write_text(\n-            \"\"\"\n+        config_file.write_text(\"\"\"\n [tool.code-scalpel.sanitizers]\n \"utils.clean_sql\" = [\"SQL_QUERY\"]\n \"utils.clean_html\" = [\"HTML_OUTPUT\"]\n \"utils.clean_all\" = [\"ALL\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         try:\n             count = load_sanitizers_from_config(str(config_file))\n             assert count == 3\n             assert \"utils.clean_sql\" in SANITIZER_REGISTRY\n@@ -721,16 +715,14 @@\n         from code_scalpel.security.analyzers.taint_tracker import (\n             load_sanitizers_from_config,\n         )\n \n         config_file = tmp_path / \"pyproject.toml\"\n-        config_file.write_text(\n-            \"\"\"\n+        config_file.write_text(\"\"\"\n [tool.code-scalpel.sanitizers]\n \"utils.paranoid_clean\" = [\"SQL_QUERY\", \"HTML_OUTPUT\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         try:\n             count = load_sanitizers_from_config(str(config_file))\n             assert count == 1\n             sanitizer = SANITIZER_REGISTRY[\"utils.paranoid_clean\"]\n@@ -745,16 +737,14 @@\n         from code_scalpel.security.analyzers.taint_tracker import (\n             load_sanitizers_from_config,\n         )\n \n         config_file = tmp_path / \"pyproject.toml\"\n-        config_file.write_text(\n-            \"\"\"\n+        config_file.write_text(\"\"\"\n [tool.code-scalpel.sanitizers]\n \"utils.mixed\" = [\"SQL_QUERY\", \"INVALID_SINK\"]\n-\"\"\"\n-        )\n+\"\"\")\n \n         try:\n             count = load_sanitizers_from_config(str(config_file))\n             assert count == 1\n             sanitizer = SANITIZER_REGISTRY[\"utils.mixed\"]\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_compliance_detection.py\t2026-02-01 15:55:14.853756+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_compliance_detection.py\t2026-02-01 23:23:09.926310+00:00\n@@ -31,12 +31,11 @@\n     async def test_detects_enterprise_compliance_findings(\n         self, tmp_path, enterprise_license\n     ):\n         \"\"\"HIPAA/SOC2/GDPR/PCI rules should appear in compliance_reports.\"\"\"\n         test_file = tmp_path / \"compliance_targets.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import logging\n import requests\n \n logger = logging.getLogger(__name__)\n \n@@ -44,12 +43,11 @@\n def get_records(request):\n     logger.info(\"patient_id=%s\", request.args[\"id\"])  # HIPAA001\n     email = request.json[\"email\"]  # GDPR001\n     requests.post(\"http://payments.example.com/checkout\", data={\"card\": \"4111111111111111\"})  # PCI003\n     return email\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(\n             paths=[str(test_file)],\n             compliance_standards=[\"hipaa\", \"soc2\", \"gdpr\", \"pci_dss\"],\n         )\n@@ -76,22 +74,20 @@\n \n     @pytest.mark.asyncio\n     async def test_generate_pdf_report_and_score(self, tmp_path, enterprise_license):\n         \"\"\"Enterprise generate_report should set pdf_report and compliance_score.\"\"\"\n         test_file = tmp_path / \"compliance_pdf.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import logging\n \n logger = logging.getLogger(__name__)\n \n @app.post(\"/payments\")\n def process(card):\n     logger.info(\"card number: %s\", card)  # PCI001\n     return card\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(\n             paths=[str(test_file)],\n             compliance_standards=[\"pci_dss\"],\n             generate_report=True,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_license_validation.py\t2026-02-01 15:55:14.863035+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_license_validation.py\t2026-02-01 23:23:10.077031+00:00\n@@ -134,18 +134,16 @@\n \n         monkeypatch.setenv(\"CODE_SCALPEL_LICENSE_PATH\", str(malformed_license))\n         monkeypatch.setenv(\"CODE_SCALPEL_DISABLE_LICENSE_DISCOVERY\", \"1\")\n \n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     pass\n except:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Should not raise exception, should fall back to Community tier\n         result = await code_policy_check(paths=[str(test_file)])\n \n         assert result.success, \"Tool should succeed even with malformed license\"\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_mcp_integration.py\t2026-02-01 15:55:14.868122+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_mcp_integration.py\t2026-02-01 23:23:10.091457+00:00\n@@ -121,18 +121,16 @@\n \n     @pytest.mark.asyncio\n     async def test_result_violations_format(self, tmp_path):\n         \"\"\"Violations should be properly formatted list of dicts.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     pass\n except:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         assert isinstance(result.violations, list), \"Violations should be list\"\n \n@@ -178,16 +176,14 @@\n \n     @pytest.mark.asyncio\n     async def test_tool_does_not_crash_on_syntax_errors(self, tmp_path):\n         \"\"\"Tool should handle files with syntax errors gracefully.\"\"\"\n         test_file = tmp_path / \"syntax_error.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def broken(\n     # Missing closing parenthesis\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Should not raise exception\n         result = await code_policy_check(paths=[str(test_file)])\n \n         # Should return result (may report error in summary)\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_tier_enforcement.py\t2026-02-01 15:55:14.893641+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_tier_enforcement.py\t2026-02-01 23:23:10.193206+00:00\n@@ -77,18 +77,16 @@\n \n     @pytest.mark.asyncio\n     async def test_community_enforces_50_rule_limit(self, tmp_path, community_license):\n         \"\"\"Community tier should enforce 50 rule limit.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     pass\n except:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         # Verify tier is Community\n         assert result.tier == \"community\", f\"Expected community tier, got {result.tier}\"\n@@ -122,18 +120,16 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_enforces_200_rule_limit(self, tmp_path, pro_license):\n         \"\"\"Pro tier should enforce 200 rule limit.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     pass\n except:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         # Verify tier is Pro\n         assert result.tier == \"pro\", f\"Expected pro tier, got {result.tier}\"\n@@ -173,18 +169,16 @@\n \n     @pytest.mark.asyncio\n     async def test_enterprise_has_unlimited_rules(self, tmp_path, enterprise_license):\n         \"\"\"Enterprise tier should have no rule limit.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     pass\n except:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         # Verify tier is Enterprise\n         assert (\n@@ -203,16 +197,14 @@\n \n     @pytest.mark.asyncio\n     async def test_community_no_best_practices(self, tmp_path, community_license):\n         \"\"\"Community tier should not include best_practices_violations.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def func(x):\n     return x + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         assert result.tier == \"community\"\n         # Community tier: best_practices_violations should be empty or None\n@@ -222,16 +214,14 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_has_best_practices(self, tmp_path, pro_license):\n         \"\"\"Pro tier should include best_practices_violations.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def func(x):\n     return x + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         assert result.tier == \"pro\"\n         # Pro tier: best_practices_violations should be available (may be empty list)\n@@ -243,16 +233,14 @@\n     async def test_enterprise_has_compliance_reports(\n         self, tmp_path, enterprise_license\n     ):\n         \"\"\"Enterprise tier should include compliance_reports.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def func(x):\n     return x + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         assert result.tier == \"enterprise\"\n         # Enterprise tier: compliance_reports should be available\n@@ -265,15 +253,13 @@\n         self, tmp_path, community_license\n     ):\n         \"\"\"Community tier should not expose custom rule results.\"\"\"\n         # [20260105_TEST] Strengthen feature gating expectations.\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n value = 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)], rules=[\"CUSTOM001\"])\n \n         assert result.tier == \"community\"\n         assert not getattr(\n@@ -282,16 +268,14 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_blocks_compliance_outputs(self, tmp_path, pro_license):\n         \"\"\"Pro tier should not return compliance artifacts even if requested.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def handler(request):\n     return request.json.get(\"email\")\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(\n             paths=[str(test_file)],\n             compliance_standards=[\"hipaa\"],\n             generate_report=True,\n@@ -309,16 +293,14 @@\n     async def test_enterprise_includes_audit_trail_and_score(\n         self, tmp_path, enterprise_license\n     ):\n         \"\"\"Enterprise tier should populate compliance score and audit trail.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def log_patient(patient_id):\n     print(f\"patient_id={patient_id}\")\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(\n             paths=[str(test_file)],\n             compliance_standards=[\"hipaa\"],\n             generate_report=True,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_edge_cases.py\t2026-02-01 15:55:14.909177+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_edge_cases.py\t2026-02-01 23:23:10.488791+00:00\n@@ -60,19 +60,17 @@\n         # Should handle gracefully without crash\n         assert result.modules_analyzed == 0\n \n     def test_single_file_project(self, temp_project):\n         \"\"\"[20260103_TEST] Single-file project without imports.\"\"\"\n-        (temp_project / \"main.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"main.py\").write_text(\"\"\"\n def add(a, b):\n     return a + b\n \n def multiply(x, y):\n     return x * y\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n@@ -112,25 +110,21 @@\n         # Should not crash despite multiple errors\n         assert result is not None\n \n     def test_import_error_recovery(self, temp_project):\n         \"\"\"[20260103_TEST] Handles import errors and continues analysis.\"\"\"\n-        (temp_project / \"a.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"a.py\").write_text(\"\"\"\n from nonexistent_module import something\n \n def process():\n     return something()\n-\"\"\"\n-        )\n-\n-        (temp_project / \"b.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"b.py\").write_text(\"\"\"\n def safe_operation():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         # Should continue despite import error\n@@ -145,12 +139,11 @@\n class TestSafeCode:\n     \"\"\"Tests for projects with no vulnerabilities.\"\"\"\n \n     def test_no_dangerous_code(self, temp_project):\n         \"\"\"[20260103_TEST] Safe project reports no vulnerabilities.\"\"\"\n-        (temp_project / \"utils.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"utils.py\").write_text(\"\"\"\n def add(a, b):\n     return a + b\n \n def multiply(x, y):\n     return x * y\n@@ -158,44 +151,39 @@\n def calculate(values):\n     total = 0\n     for v in values:\n         total = add(total, v)\n     return total\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n         assert len(result.vulnerabilities) == 0\n \n     def test_parametrized_queries_safe(self, temp_project):\n         \"\"\"[20260103_TEST] Parametrized queries are not flagged as vulnerable.\"\"\"\n-        (temp_project / \"db.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def get_user_safe(user_id):\n     conn = sqlite3.connect('test.db')\n     cursor = conn.cursor()\n     # Safe: parameterized query\n     cursor.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,))\n     return cursor.fetchone()\n-\"\"\"\n-        )\n-\n-        (temp_project / \"routes.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"routes.py\").write_text(\"\"\"\n from flask import request\n from db import get_user_safe\n \n def handler():\n     user_id = request.args.get('id')\n     return get_user_safe(user_id)\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n@@ -211,30 +199,26 @@\n class TestMermaidGeneration:\n     \"\"\"Tests for Mermaid diagram generation.\"\"\"\n \n     def test_generate_mermaid_diagram(self, temp_project):\n         \"\"\"[20260103_TEST] Mermaid diagram generation works.\"\"\"\n-        (temp_project / \"routes.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"routes.py\").write_text(\"\"\"\n from flask import request\n from db import execute_query\n \n def get_user():\n     user_id = request.args.get('id')\n     return execute_query(user_id)\n-\"\"\"\n-        )\n-\n-        (temp_project / \"db.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def execute_query(user_id):\n     cursor = sqlite3.cursor()\n     cursor.execute(f\"SELECT * FROM users WHERE id = {user_id}\")\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         tracker.analyze()\n \n         mermaid = tracker.get_taint_graph_mermaid()\n@@ -279,34 +263,30 @@\n \n     def test_short_timeout_respected(self, temp_project):\n         \"\"\"[20260103_TEST] Short timeout prevents excessive analysis.\"\"\"\n         # Create a project with many files to ensure timeout matters\n         for i in range(20):\n-            (temp_project / f\"module_{i}.py\").write_text(\n-                f\"\"\"\n+            (temp_project / f\"module_{i}.py\").write_text(f\"\"\"\n def function_{i}(data):\n     import os\n     os.system(data)\n-\"\"\"\n-            )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         # Use very short timeout\n         result = tracker.analyze(timeout_seconds=0.1)\n \n         # Should complete within timeout (possibly without analyzing all)\n         assert result is not None\n \n     def test_no_timeout_parameter(self, temp_project):\n         \"\"\"[20260103_TEST] Analysis works with default timeout.\"\"\"\n-        (temp_project / \"test.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"test.py\").write_text(\"\"\"\n import os\n def process(data):\n     os.system(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         # Call without timeout parameter\n         result = tracker.analyze()\n \n@@ -322,40 +302,34 @@\n     \"\"\"Tests for complex dependency scenarios.\"\"\"\n \n     def test_deep_module_chain(self, temp_project):\n         \"\"\"[20260103_TEST] Handles deep module call chains.\"\"\"\n         # Create a 10-level call chain\n-        (temp_project / \"level0.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"level0.py\").write_text(\"\"\"\n from flask import request\n from level1 import func1\n \n def handler():\n     data = request.args.get('input')\n     return func1(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         for i in range(1, 9):\n             next_level = i + 1\n-            (temp_project / f\"level{i}.py\").write_text(\n-                f\"\"\"\n+            (temp_project / f\"level{i}.py\").write_text(f\"\"\"\n from level{next_level} import func{next_level}\n \n def func{i}(data):\n     return func{next_level}(data)\n-\"\"\"\n-            )\n-\n-        (temp_project / \"level9.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"level9.py\").write_text(\"\"\"\n import os\n \n def func9(data):\n     os.system(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze(max_depth=20)\n \n         assert result is not None\n@@ -383,67 +357,59 @@\n         )\n \n         (temp_project / \"root.py\").write_text(root_content)\n \n         for i in range(15):\n-            (temp_project / f\"module_{i}.py\").write_text(\n-                f\"\"\"\n+            (temp_project / f\"module_{i}.py\").write_text(f\"\"\"\n def func_{i}(data):\n     return data.upper()\n-\"\"\"\n-            )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n         assert result.modules_analyzed >= 10\n \n     def test_circular_import_graph(self, temp_project):\n         \"\"\"[20260103_TEST] Handles circular import patterns.\"\"\"\n         # Create circular: a -> b -> c -> a\n-        (temp_project / \"a.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"a.py\").write_text(\"\"\"\n try:\n     from b import func_b\n except ImportError:\n     func_b = None\n \n def func_a(data):\n     if func_b:\n         return func_b(data)\n     return data\n-\"\"\"\n-        )\n-\n-        (temp_project / \"b.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"b.py\").write_text(\"\"\"\n try:\n     from c import func_c\n except ImportError:\n     func_c = None\n \n def func_b(data):\n     if func_c:\n         return func_c(data)\n     return data\n-\"\"\"\n-        )\n-\n-        (temp_project / \"c.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"c.py\").write_text(\"\"\"\n try:\n     from a import func_a\n except ImportError:\n     func_a = None\n \n def func_c(data):\n     if func_a:\n         return func_a(data)\n     return data\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         # Should not deadlock\n@@ -458,21 +424,19 @@\n class TestSpecialCases:\n     \"\"\"Tests for special characters and edge case formats.\"\"\"\n \n     def test_unicode_identifiers(self, temp_project):\n         \"\"\"[20260103_TEST] Handles unicode in identifiers.\"\"\"\n-        (temp_project / \"unicode_test.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"unicode_test.py\").write_text(\"\"\"\n # -*- coding: utf-8 -*-\n \n def \u03c3\u03b7\u03bc\u03b1(\u03b4\u03b5\u03b4\u03bf\u03bc\u03ad\u03bd\u03b1):\n     return \u03b4\u03b5\u03b4\u03bf\u03bc\u03ad\u03bd\u03b1.upper()\n \n def hello():\n     return \u03c3\u03b7\u03bc\u03b1(\"test\")\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         # Should handle unicode gracefully\n@@ -513,16 +477,14 @@\n \n     def test_many_small_modules(self, temp_project):\n         \"\"\"[20260103_TEST] Handles projects with many modules.\"\"\"\n         # Create 50 small modules\n         for i in range(50):\n-            (temp_project / f\"mod_{i:03d}.py\").write_text(\n-                f\"\"\"\n+            (temp_project / f\"mod_{i:03d}.py\").write_text(f\"\"\"\n def process_{i}(data):\n     return data\n-\"\"\"\n-            )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze(max_modules=100)\n \n         assert result.success\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_rule_detection.py\t2026-02-01 15:55:14.880553+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_rule_detection.py\t2026-02-01 23:23:10.520430+00:00\n@@ -65,35 +65,31 @@\n \n     @pytest.mark.asyncio\n     async def test_detects_py001_bare_except(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY001: Bare except clause detection.\"\"\"\n         test_file = tmp_path / \"test_bare_except.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     risky_operation()\n except:  # PY001 violation\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY001\"]\n         assert len(violations) > 0, \"Should detect PY001: Bare except clause\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py002_mutable_default(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY002: Mutable default argument detection.\"\"\"\n         test_file = tmp_path / \"test_mutable_default.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def add_item(item, items=[]):  # PY002 violation\n     items.append(item)\n     return items\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY002\"]\n         assert len(violations) > 0, \"Should detect PY002: Mutable default argument\"\n@@ -101,139 +97,123 @@\n     @pytest.mark.asyncio\n     async def test_detects_py003_global_statement(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY003: Global statement detection.\"\"\"\n         # [20260105_TEST] Expand Community coverage for remaining PY rules.\n         test_file = tmp_path / \"test_global.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n value = 0\n \n def increment():\n     global value  # PY003 violation\n     value += 1\n     return value\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY003\"]\n         assert violations, \"Should detect PY003: Global statement\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py004_star_import(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY004: Star import detection.\"\"\"\n         test_file = tmp_path / \"test_star_import.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n from math import *  # PY004 violation\n \n def area(r):\n     return pi * r * r\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY004\"]\n         assert violations, \"Should detect PY004: Star import\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py005_assert_usage(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY005: Assert statement detection.\"\"\"\n         test_file = tmp_path / \"test_assert.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def check_flag(flag):\n     assert flag  # PY005 violation\n     return bool(flag)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY005\"]\n         assert violations, \"Should detect PY005: Assert statement\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py006_exec_usage(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY006: exec() usage detection.\"\"\"\n         test_file = tmp_path / \"test_exec.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n payload = \"print('hello')\"\n exec(payload)  # PY006 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY006\"]\n         assert violations, \"Should detect PY006: exec() usage\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py007_eval_usage(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY007: eval() usage detection.\"\"\"\n         test_file = tmp_path / \"test_eval.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n user_input = input(\"Enter expression: \")\n result = eval(user_input)  # PY007 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY007\"]\n         assert len(violations) > 0, \"Should detect PY007: eval() usage\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py008_type_comparison(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY008: type() comparison detection.\"\"\"\n         test_file = tmp_path / \"test_type_compare.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def is_int(value):\n     if type(value) == int:  # PY008 violation\n         return True\n     return False\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY008\"]\n         assert violations, \"Should detect PY008: type() comparison\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py009_empty_except_block(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY009: Empty except block detection.\"\"\"\n         test_file = tmp_path / \"test_empty_except.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def handler():\n     try:\n         risky()\n     except Exception:  # PY009 violation\n         pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY009\"]\n         assert violations, \"Should detect PY009: Empty except block\"\n \n     @pytest.mark.asyncio\n     async def test_detects_py010_input_for_password(self, tmp_path, clear_license_env):\n         \"\"\"Verify PY010: input() used for passwords detection.\"\"\"\n         test_file = tmp_path / \"test_password_input.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n password = input(\"Enter password: \")  # PY010 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"PY010\"]\n         assert violations, \"Should detect PY010: input() for passwords\"\n@@ -244,47 +224,41 @@\n \n     @pytest.mark.asyncio\n     async def test_detects_sec001_hardcoded_password(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC001: Hardcoded password detection.\"\"\"\n         test_file = tmp_path / \"test_hardcoded_password.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n PASSWORD = \"super_secret_123\"  # SEC001 violation\n API_KEY = \"sk-1234567890abcdef\"  # SEC001 violation\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC001\"]\n         assert len(violations) > 0, \"Should detect SEC001: Hardcoded password\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec002_sql_concatenation(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC002: SQL string concatenation detection.\"\"\"\n         test_file = tmp_path / \"test_sql_concat.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def get_user(username):\n     cursor.execute(\"SELECT * FROM users WHERE name = '\" + username + \"'\")  # SEC002 violation\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC002\"]\n         assert violations, \"Should detect SEC002: SQL string concatenation\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec003_os_system_usage(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC003: os.system() usage detection.\"\"\"\n         test_file = tmp_path / \"test_os_system.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import os\n filename = user_input\n os.system(f\"cat {filename}\")  # SEC003 violation\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC003\"]\n         assert len(violations) > 0, \"Should detect SEC003: os.system() usage\"\n \n@@ -292,120 +266,106 @@\n     async def test_detects_sec004_subprocess_shell_true(\n         self, tmp_path, set_pro_license\n     ):\n         \"\"\"Verify SEC004: subprocess with shell=True detection.\"\"\"\n         test_file = tmp_path / \"test_subprocess_shell.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import subprocess\n \n def run_command(cmd):\n     subprocess.run(cmd, shell=True)  # SEC004 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC004\"]\n         assert violations, \"Should detect SEC004: subprocess shell=True\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec005_pickle_usage(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC005: pickle usage detection.\"\"\"\n         test_file = tmp_path / \"test_pickle_usage.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import pickle\n \n def load(data):\n     return pickle.loads(data)  # SEC005 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC005\"]\n         assert violations, \"Should detect SEC005: pickle.loads usage\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec006_yaml_unsafe_load(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC006: yaml.load without Loader detection.\"\"\"\n         test_file = tmp_path / \"test_yaml_load.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import yaml\n \n def read_config(stream):\n     return yaml.load(stream)  # SEC006 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC006\"]\n         assert violations, \"Should detect SEC006: yaml.load without Loader\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec007_hardcoded_ip(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC007: Hardcoded IP address detection.\"\"\"\n         test_file = tmp_path / \"test_hardcoded_ip.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n SERVER_IP = \"192.168.0.10\"  # SEC007 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC007\"]\n         assert violations, \"Should detect SEC007: Hardcoded IP\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec008_insecure_ssl(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC008: Insecure SSL verification disabled detection.\"\"\"\n         test_file = tmp_path / \"test_insecure_ssl.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n requests.get(\"https://example.com\", verify=False)  # SEC008 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC008\"]\n         assert violations, \"Should detect SEC008: SSL verify disabled\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec009_debug_mode(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC009: Debug mode detection.\"\"\"\n         test_file = tmp_path / \"test_debug_mode.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n DEBUG = True  # SEC009 violation\n \n def run_app(app):\n     app.run(debug=True)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC009\"]\n         assert violations, \"Should detect SEC009: Debug mode enabled\"\n \n     @pytest.mark.asyncio\n     async def test_detects_sec010_weak_hash(self, tmp_path, set_pro_license):\n         \"\"\"Verify SEC010: Weak hash detection.\"\"\"\n         test_file = tmp_path / \"test_weak_hash.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import hashlib\n \n def digest(data):\n     return hashlib.md5(data).hexdigest()  # SEC010 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"SEC010\"]\n         assert violations, \"Should detect SEC010: MD5 usage\"\n@@ -416,92 +376,82 @@\n \n     @pytest.mark.asyncio\n     async def test_detects_async001_missing_await(self, tmp_path, set_pro_license):\n         \"\"\"Verify ASYNC001: Missing await detection.\"\"\"\n         test_file = tmp_path / \"test_missing_await.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n class Client:\n     async def fetch(self):\n         return \"data\"\n \n \n async def process_data(client: Client):\n     client.fetch()  # ASYNC001 violation - missing await on coroutine call\n     return \"ok\"\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"ASYNC001\"]\n         assert violations, \"Should detect ASYNC001: Missing await\"\n \n     @pytest.mark.asyncio\n     async def test_detects_async002_blocking_call(self, tmp_path, set_pro_license):\n         \"\"\"Verify ASYNC002: Blocking call in async function detection.\"\"\"\n         test_file = tmp_path / \"test_blocking_call.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import time\n \n async def process_request():\n     time.sleep(5)  # ASYNC002 violation - should use asyncio.sleep()\n     return \"done\"\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"ASYNC002\"]\n         assert len(violations) > 0, \"Should detect ASYNC002: Blocking call in async\"\n \n     @pytest.mark.asyncio\n     async def test_detects_async003_nested_asyncio_run(self, tmp_path, set_pro_license):\n         \"\"\"Verify ASYNC003: Nested asyncio.run detection.\"\"\"\n         test_file = tmp_path / \"test_nested_asyncio_run.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import asyncio\n \n async def runner():\n     return asyncio.run(asyncio.sleep(0))  # ASYNC003 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"ASYNC003\"]\n         assert violations, \"Should detect ASYNC003: Nested asyncio.run\"\n \n     @pytest.mark.asyncio\n     async def test_detects_async004_unhandled_task(self, tmp_path, set_pro_license):\n         \"\"\"Verify ASYNC004: Unhandled task detection.\"\"\"\n         test_file = tmp_path / \"test_unhandled_task.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import asyncio\n \n async def orchestrate():\n     asyncio.create_task(asyncio.sleep(1))  # ASYNC004 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"ASYNC004\"]\n         assert violations, \"Should detect ASYNC004: Unhandled task\"\n \n     @pytest.mark.asyncio\n     async def test_detects_async005_async_gen_cleanup(self, tmp_path, set_pro_license):\n         \"\"\"Verify ASYNC005: Async generator cleanup detection.\"\"\"\n         test_file = tmp_path / \"test_async_gen_cleanup.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n async def consume(gen):\n     async for item in gen:  # ASYNC005 violation (async generator without aclose())\n         print(item)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"ASYNC005\"]\n         assert violations, \"Should detect ASYNC005: Async generator cleanup\"\n@@ -512,94 +462,82 @@\n \n     @pytest.mark.asyncio\n     async def test_detects_bp001_missing_type_hints(self, tmp_path, set_pro_license):\n         \"\"\"Verify BP001: Missing type hints detection.\"\"\"\n         test_file = tmp_path / \"test_type_hints.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def calculate_total(price, quantity):  # BP001 violation - no type hints\n     return price * quantity\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"BP001\"]\n         assert len(violations) > 0, \"Should detect BP001: Missing type hints\"\n \n     @pytest.mark.asyncio\n     async def test_detects_bp002_missing_docstring(self, tmp_path, set_pro_license):\n         \"\"\"Verify BP002: Missing docstring detection.\"\"\"\n         test_file = tmp_path / \"test_docstring.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def important_function(x, y):  # BP002 violation - no docstring\n     return x + y\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"BP002\"]\n         assert len(violations) > 0, \"Should detect BP002: Missing docstring\"\n \n     @pytest.mark.asyncio\n     async def test_detects_bp003_too_many_arguments(self, tmp_path, set_pro_license):\n         \"\"\"Verify BP003: Too many arguments detection.\"\"\"\n         test_file = tmp_path / \"test_many_args.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def complex_function(a, b, c, d, e, f, g, h):  # BP003 violation - 8 args\n     return a + b + c + d + e + f + g + h\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"BP003\"]\n         assert len(violations) > 0, \"Should detect BP003: Too many arguments\"\n \n     @pytest.mark.asyncio\n     async def test_detects_bp004_function_too_long(self, tmp_path, set_pro_license):\n         \"\"\"Verify BP004: Function too long detection (>50 lines).\"\"\"\n         lines = \"\\n\".join([\"    return i\" for i in range(60)])\n         test_file = tmp_path / \"test_function_length.py\"\n-        test_file.write_text(\n-            f\"\"\"\n+        test_file.write_text(f\"\"\"\n def oversized():\n {lines}\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"BP004\"]\n         assert violations, \"Should detect BP004: Function too long\"\n \n     @pytest.mark.asyncio\n     async def test_detects_bp006_file_without_context(self, tmp_path, set_pro_license):\n         \"\"\"Verify BP006: File opened without context manager detection.\"\"\"\n         test_file = tmp_path / \"test_file_no_context.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n def read_data():\n     f = open(\"data.txt\")  # BP006 violation\n     return f.read()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"BP006\"]\n         assert violations, \"Should detect BP006: open without context manager\"\n \n     @pytest.mark.asyncio\n     async def test_detects_bp007_magic_number(self, tmp_path, set_pro_license):\n         \"\"\"Verify BP007: Magic number detection.\"\"\"\n         test_file = tmp_path / \"test_magic_number.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n RETRY_LIMIT = 1234  # BP007 violation\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = [v for v in result.violations if v.get(\"rule_id\") == \"BP007\"]\n         assert violations, \"Should detect BP007: Magic number\"\n@@ -610,23 +548,21 @@\n \n     @pytest.mark.asyncio\n     async def test_rule_ids_follow_format(self, tmp_path, clear_license_env):\n         \"\"\"Verify all rule IDs follow the pattern: CATEGORY###.\"\"\"\n         test_file = tmp_path / \"test_mixed_violations.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     risky_operation()\n except:\n     pass\n \n PASSWORD = \"secret\"\n \n def func(items=[]):\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = result.violations\n \n         for violation in violations:\n@@ -652,18 +588,16 @@\n     async def test_violations_include_required_fields(\n         self, tmp_path, clear_license_env\n     ):\n         \"\"\"Verify all violations include required fields.\"\"\"\n         test_file = tmp_path / \"test_required_fields.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n try:\n     risky_operation()\n except:\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         result = await code_policy_check(paths=[str(test_file)])\n \n         violations = result.violations\n         assert len(violations) > 0, \"Should have at least one violation\"\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_mcp_interface.py\t2026-02-01 15:55:14.917526+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_mcp_interface.py\t2026-02-01 23:23:10.552404+00:00\n@@ -303,31 +303,27 @@\n \n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             # Create vulnerable project\n-            (tmpdir_path / \"routes.py\").write_text(\n-                \"\"\"\n+            (tmpdir_path / \"routes.py\").write_text(\"\"\"\n from flask import request\n from db import query\n \n def handler():\n     user_id = request.args.get('id')\n     return query(user_id)\n-\"\"\"\n-            )\n-\n-            (tmpdir_path / \"db.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+\n+            (tmpdir_path / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def query(user_id):\n     sql = f\"SELECT * FROM users WHERE id = {user_id}\"\n     cursor = sqlite3.cursor()\n     cursor.execute(sql)\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = await cross_file_security_scan(\n                 project_root=tmpdir,\n                 entry_points=[\"routes.py\"],\n                 max_depth=10,\n@@ -346,28 +342,24 @@\n \n         with tempfile.TemporaryDirectory() as tmpdir:\n             tmpdir_path = Path(tmpdir)\n \n             # Create safe project\n-            (tmpdir_path / \"utils.py\").write_text(\n-                \"\"\"\n+            (tmpdir_path / \"utils.py\").write_text(\"\"\"\n def add(a, b):\n     return a + b\n \n def multiply(x, y):\n     return x * y\n-\"\"\"\n-            )\n-\n-            (tmpdir_path / \"main.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+\n+            (tmpdir_path / \"main.py\").write_text(\"\"\"\n from utils import add, multiply\n \n def calculate(x, y):\n     return add(x, multiply(x, y))\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = await cross_file_security_scan(\n                 project_root=tmpdir,\n                 entry_points=[\"main.py\"],\n                 max_depth=5,\n@@ -493,55 +485,47 @@\n             # Recreate Ninja Warrior crossfile-hard fixture\n             pkg = tmpdir_path / \"crossfile_hard\"\n             pkg.mkdir()\n             (pkg / \"__init__.py\").write_text(\"# test package\\n\")\n \n-            (pkg / \"routes.py\").write_text(\n-                \"\"\"\\\n+            (pkg / \"routes.py\").write_text(\"\"\"\\\n from flask import Flask, request\n from .services import search_users\n \n app = Flask(__name__)\n \n @app.get('/search')\n def search_route() -> str:\n     q = request.args.get('q', '')\n     return search_users(q)\n-\"\"\"\n-            )\n-\n-            (pkg / \"services.py\").write_text(\n-                \"\"\"\\\n+\"\"\")\n+\n+            (pkg / \"services.py\").write_text(\"\"\"\\\n from . import sanitizers as s\n from .db import run_query as rq\n \n def search_users(raw_query: str) -> str:\n     query = s.sanitize_decoy(raw_query)\n     return rq(query)\n-\"\"\"\n-            )\n-\n-            (pkg / \"sanitizers.py\").write_text(\n-                \"\"\"\\\n+\"\"\")\n+\n+            (pkg / \"sanitizers.py\").write_text(\"\"\"\\\n def sanitize_decoy(value: str) -> str:\n     return value\n-\"\"\"\n-            )\n-\n-            (pkg / \"db.py\").write_text(\n-                \"\"\"\\\n+\"\"\")\n+\n+            (pkg / \"db.py\").write_text(\"\"\"\\\n import sqlite3\n \n def run_query(user_supplied: str) -> str:\n     sql = f\"SELECT * FROM users WHERE name = '{user_supplied}'\"\n     conn = sqlite3.connect(':memory:')\n     cur = conn.cursor()\n     cur.execute(sql)\n     conn.close()\n     return sql\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = await cross_file_security_scan(\n                 project_root=tmpdir,\n                 entry_points=[\"crossfile_hard/routes.py\"],\n                 max_depth=10,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/mcp_metadata/test_mcp_license_metadata.py\t2026-02-01 15:55:14.963605+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/mcp_metadata/test_mcp_license_metadata.py\t2026-02-01 23:23:11.088996+00:00\n@@ -87,19 +87,17 @@\n     @pytest.mark.asyncio\n     async def test_mcp_response_includes_tier_field(self, use_community_tier, tmp_path):\n         \"\"\"MCP response should include 'tier' field in metadata or response.\"\"\"\n         # Create a simple test project\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n-def foo():\n-    return bar()\n-\n-def bar():\n-    return \"result\"\n-\"\"\"\n-        )\n+        test_file.write_text(\"\"\"\n+def foo():\n+    return bar()\n+\n+def bar():\n+    return \"result\"\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::test::function::foo\",\n             k=1,\n             max_nodes=20,\n@@ -114,19 +112,17 @@\n \n     @pytest.mark.asyncio\n     async def test_community_tier_metadata_correct(self, use_community_tier, tmp_path):\n         \"\"\"Community tier MCP response should indicate 'community' tier.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n-def foo():\n-    return bar()\n-\n-def bar():\n-    return \"result\"\n-\"\"\"\n-        )\n+        test_file.write_text(\"\"\"\n+def foo():\n+    return bar()\n+\n+def bar():\n+    return \"result\"\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::test::function::foo\",\n             k=1,\n             max_nodes=20,\n@@ -138,19 +134,17 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_tier_metadata_correct(self, use_pro_tier, tmp_path):\n         \"\"\"Pro tier MCP response should indicate 'pro' tier.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n-def foo():\n-    return bar()\n-\n-def bar():\n-    return \"result\"\n-\"\"\"\n-        )\n+        test_file.write_text(\"\"\"\n+def foo():\n+    return bar()\n+\n+def bar():\n+    return \"result\"\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::test::function::foo\",\n             k=3,\n             max_nodes=100,\n@@ -164,19 +158,17 @@\n     async def test_enterprise_tier_metadata_correct(\n         self, use_enterprise_tier, tmp_path\n     ):\n         \"\"\"Enterprise tier MCP response should indicate 'enterprise' tier.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n-def foo():\n-    return bar()\n-\n-def bar():\n-    return \"result\"\n-\"\"\"\n-        )\n+        test_file.write_text(\"\"\"\n+def foo():\n+    return bar()\n+\n+def bar():\n+    return \"result\"\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::test::function::foo\",\n             k=10,\n             max_nodes=500,\n@@ -236,16 +228,14 @@\n \n     @pytest.mark.asyncio\n     async def test_valid_license_no_expiration_warning(self, use_pro_tier, tmp_path):\n         \"\"\"Valid, non-expiring license should not generate warnings.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n-def foo():\n-    return \"result\"\n-\"\"\"\n-        )\n+        test_file.write_text(\"\"\"\n+def foo():\n+    return \"result\"\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::test::function::foo\",\n             k=2,\n             max_nodes=50,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_file_context/test_enterprise_tier.py\t2026-02-01 15:55:14.940297+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_file_context/test_enterprise_tier.py\t2026-02-01 23:23:11.112020+00:00\n@@ -36,20 +36,18 @@\n         code_dir = project_dir / \".code-scalpel\"\n         code_dir.mkdir()\n \n         # Create metadata file\n         metadata_file = code_dir / \"metadata.yaml\"\n-        metadata_file.write_text(\n-            \"\"\"\n+        metadata_file.write_text(\"\"\"\n owner: security-team\n classification: sensitive\n data_types:\n   - pii\n   - financial\n team: platform-engineering\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         # Create test Python file\n         test_file = project_dir / \"test.py\"\n         test_file.write_text(\"def hello(): pass\")\n \n@@ -169,17 +167,15 @@\n         \"\"\"Enterprise tier should parse CODEOWNERS files.\"\"\"\n         project_dir = Path(tmpdir)\n \n         # Create CODEOWNERS file\n         codeowners_file = project_dir / \"CODEOWNERS\"\n-        codeowners_file.write_text(\n-            \"\"\"\n+        codeowners_file.write_text(\"\"\"\n *.py @python-team\n src/ @core-team\n tests/ @qa-team\n-        \"\"\"\n-        )\n+        \"\"\")\n \n         test_file = project_dir / \"test.py\"\n         test_file.write_text(\"def hello(): pass\")\n \n         from code_scalpel.mcp.helpers.context_helpers import _get_file_context_sync\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_core_functionality.py\t2026-02-01 15:55:14.903616+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_core_functionality.py\t2026-02-01 23:23:11.210561+00:00\n@@ -45,199 +45,170 @@\n \n @pytest.fixture\n def simple_vuln_project(temp_project):\n     \"\"\"Create a project with a simple SQL injection vulnerability.\"\"\"\n     # routes.py - web routes that handle user input\n-    (temp_project / \"routes.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"routes.py\").write_text(\"\"\"\n from flask import request\n from db import execute_query\n \n def get_user():\n     user_id = request.args.get('id')\n     return execute_query(user_id)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # db.py - database operations\n-    (temp_project / \"db.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def execute_query(user_id):\n     conn = sqlite3.connect('test.db')\n     cursor = conn.cursor()\n     cursor.execute(f\"SELECT * FROM users WHERE id = {user_id}\")\n     return cursor.fetchone()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def command_injection_project(temp_project):\n     \"\"\"Create a project with command injection vulnerability.\"\"\"\n-    (temp_project / \"api.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"api.py\").write_text(\"\"\"\n from flask import request\n from utils import run_command\n \n def process():\n     filename = request.args.get('file')\n     return run_command(filename)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"utils.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"utils.py\").write_text(\"\"\"\n import os\n \n def run_command(filename):\n     os.system(f\"cat {filename}\")\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def multi_hop_project(temp_project):\n     \"\"\"Create a project with multi-hop taint flow.\"\"\"\n-    (temp_project / \"app.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"app.py\").write_text(\"\"\"\n from flask import request\n from services import process_data\n \n def handler():\n     data = request.args.get('data')\n     return process_data(data)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"services.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"services.py\").write_text(\"\"\"\n from utils import transform\n \n def process_data(data):\n     transformed = transform(data)\n     return transformed\n-\"\"\"\n-    )\n-\n-    (temp_project / \"utils.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"utils.py\").write_text(\"\"\"\n import os\n \n def transform(data):\n     # This is dangerous - command injection\n     os.system(f\"echo {data}\")\n     return data.upper()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def path_traversal_project(temp_project):\n     \"\"\"Create a project with path traversal vulnerability.\"\"\"\n-    (temp_project / \"views.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"views.py\").write_text(\"\"\"\n from flask import request\n from files import read_file\n \n def download():\n     path = request.args.get('path')\n     return read_file(path)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"files.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"files.py\").write_text(\"\"\"\n def read_file(path):\n     with open(path, 'r') as f:\n         return f.read()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def circular_import_project(temp_project):\n     \"\"\"Create a project with circular imports to test handling.\"\"\"\n     # a.py imports from b.py\n-    (temp_project / \"a.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"a.py\").write_text(\"\"\"\n from flask import request\n from b import process_b\n \n def handler():\n     data = request.args.get('input')\n     return process_b(data)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # b.py imports from c.py AND imports a.py (circular)\n-    (temp_project / \"b.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"b.py\").write_text(\"\"\"\n from c import dangerous_operation\n import a\n \n def process_b(data):\n     return dangerous_operation(data)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # c.py contains the sink\n-    (temp_project / \"c.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"c.py\").write_text(\"\"\"\n import os\n \n def dangerous_operation(cmd):\n     os.system(cmd)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def dynamic_import_project(temp_project):\n     \"\"\"Create a project using dynamic imports (importlib).\"\"\"\n-    (temp_project / \"loader.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"loader.py\").write_text(\"\"\"\n import importlib\n from flask import request\n \n def dynamic_handler():\n     module_name = request.args.get('module')\n     module = importlib.import_module(module_name)\n     return module.process()\n-\"\"\"\n-    )\n-\n-    (temp_project / \"plugins.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"plugins.py\").write_text(\"\"\"\n import os\n \n def process():\n     # Vulnerable operation\n     os.system(\"ls -la\")\n     return \"done\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def conditional_import_project(temp_project):\n     \"\"\"Create a project with conditional imports.\"\"\"\n-    (temp_project / \"main.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"main.py\").write_text(\"\"\"\n from flask import request\n \n USE_SAFE = request.args.get('safe') == 'true'\n \n if USE_SAFE:\n@@ -249,28 +220,23 @@\n     data = request.args.get('data')\n     if USE_SAFE:\n         return safe_operation(data)\n     else:\n         return unsafe_operation(data)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"safe_ops.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"safe_ops.py\").write_text(\"\"\"\n def safe_operation(data):\n     return data.upper()\n-\"\"\"\n-    )\n-\n-    (temp_project / \"unsafe_ops.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"unsafe_ops.py\").write_text(\"\"\"\n import os\n \n def unsafe_operation(data):\n     os.system(data)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n@@ -278,101 +244,85 @@\n     \"\"\"Create a package with relative imports.\"\"\"\n     pkg = temp_project / \"myapp\"\n     pkg.mkdir()\n     (pkg / \"__init__.py\").write_text(\"\")\n \n-    (pkg / \"routes.py\").write_text(\n-        \"\"\"\n+    (pkg / \"routes.py\").write_text(\"\"\"\n from flask import request\n from .handlers import process_request\n \n def index():\n     data = request.args.get('query')\n     return process_request(data)\n-\"\"\"\n-    )\n-\n-    (pkg / \"handlers.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (pkg / \"handlers.py\").write_text(\"\"\"\n from .db import execute_sql\n \n def process_request(query):\n     return execute_sql(query)\n-\"\"\"\n-    )\n-\n-    (pkg / \"db.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (pkg / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def execute_sql(query):\n     cursor = sqlite3.cursor()\n     cursor.execute(f\"SELECT * FROM data WHERE q = '{query}'\")\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def aliased_import_project(temp_project):\n     \"\"\"Create a project with aliased imports (import X as Y).\"\"\"\n-    (temp_project / \"operations.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"operations.py\").write_text(\"\"\"\n import subprocess\n \n def run(cmd):\n     subprocess.run(cmd, shell=True)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"handler.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"handler.py\").write_text(\"\"\"\n from flask import request\n import operations as ops\n \n def process():\n     cmd = request.args.get('cmd')\n     return ops.run(cmd)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def reexport_project(temp_project):\n     \"\"\"Create a project with re-exports (from X import Y, then re-export).\"\"\"\n-    (temp_project / \"base.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"base.py\").write_text(\"\"\"\n import os\n \n def system_call(cmd):\n     os.system(cmd)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"api.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"api.py\").write_text(\"\"\"\n # Re-export from base\n from base import system_call\n \n # Make it available as a public API\n __all__ = ['system_call']\n-\"\"\"\n-    )\n-\n-    (temp_project / \"handler.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"handler.py\").write_text(\"\"\"\n from flask import request\n from api import system_call\n \n def process():\n     cmd = request.args.get('cmd')\n     return system_call(cmd)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n # =============================================================================\n@@ -702,41 +652,35 @@\n     \"\"\"Integration tests with realistic application scenarios.\"\"\"\n \n     def test_flask_app_analysis(self, temp_project):\n         \"\"\"Test analysis of Flask-like application structure.\"\"\"\n         # Create a mini Flask app structure\n-        (temp_project / \"app.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"app.py\").write_text(\"\"\"\n from flask import Flask, request\n from views import handle_request\n \n app = Flask(__name__)\n \n @app.route('/api')\n def api():\n     return handle_request()\n-\"\"\"\n-        )\n-\n-        (temp_project / \"views.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"views.py\").write_text(\"\"\"\n from flask import request\n from models import get_data\n \n def handle_request():\n     query = request.args.get('q')\n     return get_data(query)\n-\"\"\"\n-        )\n-\n-        (temp_project / \"models.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"models.py\").write_text(\"\"\"\n def get_data(query):\n     # Potentially dangerous if query is not sanitized\n     return f\"Results for: {query}\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n@@ -747,38 +691,32 @@\n         # Create complex import structure\n         pkg = temp_project / \"pkg\"\n         pkg.mkdir()\n         (pkg / \"__init__.py\").write_text(\"\")\n \n-        (pkg / \"base.py\").write_text(\n-            \"\"\"\n+        (pkg / \"base.py\").write_text(\"\"\"\n import os\n \n def exec_cmd(cmd):\n     os.system(cmd)\n-\"\"\"\n-        )\n-\n-        (pkg / \"service.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (pkg / \"service.py\").write_text(\"\"\"\n from .base import exec_cmd\n \n def process(data):\n     exec_cmd(f\"echo {data}\")\n-\"\"\"\n-        )\n-\n-        (temp_project / \"main.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"main.py\").write_text(\"\"\"\n from flask import request\n from pkg.service import process\n \n def handler():\n     data = request.args.get('input')\n     process(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/test_mermaid_validation.py\t2026-02-01 15:55:14.968888+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/test_mermaid_validation.py\t2026-02-01 23:23:11.707463+00:00\n@@ -404,12 +404,11 @@\n class TestMermaidTierExpectations:\n     \"\"\"Exact Mermaid outputs per tier for regression checks.\"\"\"\n \n     @staticmethod\n     def _expected_community_mermaid() -> str:\n-        return dedent(\n-            \"\"\"\n+        return dedent(\"\"\"\n             graph TD\n                 python_main_function_center[\"center\"]:::center\n                 python_module_a_function_func_A[\"func_A\"]:::depth1\n                 python_module_b_function_func_B[\"func_B\"]:::depth1\n                 python_module_c_function_func_C[\"func_C\"]:::depth1\n@@ -419,17 +418,15 @@\n                 python_main_function_center --> python_module_c_function_func_C\n                 python_main_function_center --> python_module_d_function_func_D\n                 classDef center fill:#f9f,stroke:#333,stroke-width:3px\n                 classDef depth1 fill:#bbf,stroke:#333,stroke-width:2px\n                 classDef depth2plus fill:#ddd,stroke:#333,stroke-width:1px\n-            \"\"\"\n-        ).strip()\n+            \"\"\").strip()\n \n     @staticmethod\n     def _expected_full_mermaid() -> str:\n-        return dedent(\n-            \"\"\"\n+        return dedent(\"\"\"\n             graph TD\n                 python_main_function_center[\"center\"]:::center\n                 python_module_a_function_func_A[\"func_A\"]:::depth1\n                 python_module_b_function_func_B[\"func_B\"]:::depth1\n                 python_module_c_function_func_C[\"func_C\"]:::depth1\n@@ -449,12 +446,11 @@\n                 python_module_c_function_func_C --> python_module_c1_function_func_C1\n                 python_module_d_function_func_D --> python_module_d1_function_func_D1\n                 classDef center fill:#f9f,stroke:#333,stroke-width:3px\n                 classDef depth1 fill:#bbf,stroke:#333,stroke-width:2px\n                 classDef depth2plus fill:#ddd,stroke:#333,stroke-width:1px\n-            \"\"\"\n-        ).strip()\n+            \"\"\").strip()\n \n     def test_community_mermaid_expected(self, sample_call_graph):\n         \"\"\"Community tier (k=1) should render depth-1 neighborhood only.\"\"\"\n         result = sample_call_graph.get_neighborhood(\n             \"python::main::function::center\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_symbol_references/test_output_metadata.py\t2026-02-01 15:55:14.996059+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_symbol_references/test_output_metadata.py\t2026-02-01 23:23:11.864996+00:00\n@@ -14,19 +14,16 @@\n ):\n     \"\"\"[20260111_TEST] Community tier should populate output metadata with limits.\"\"\"\n     import code_scalpel.mcp.tools.context as server\n \n     project = make_project(\n-        {\n-            f\"src/file_{i}.py\": \"\"\"\n+        {f\"src/file_{i}.py\": \"\"\"\n from shared.target import target\n \n def use():\n     return target()\n-\"\"\"\n-            for i in range(5)\n-        }\n+\"\"\" for i in range(5)}\n         | {\n             \"shared/target.py\": \"\"\"\n def target():\n     return 1\n \"\"\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_extractor_additional.py\t2026-02-01 15:55:15.028949+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_extractor_additional.py\t2026-02-01 23:23:11.909163+00:00\n@@ -6,26 +6,22 @@\n \n \n def test_extract_with_dependencies(tmp_path):\n     project = tmp_path\n     (project / \"__init__.py\").write_text(\"\\n\")\n-    (project / \"b.py\").write_text(\n-        \"\"\"\n+    (project / \"b.py\").write_text(\"\"\"\n CONST = 7\n \n def helper():\n     return CONST\n-\"\"\"\n-    )\n-    (project / \"a.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+    (project / \"a.py\").write_text(\"\"\"\n from b import helper\n \n def foo():\n     return helper()\n-\"\"\"\n-    )\n+\"\"\")\n \n     extractor = CrossFileExtractor(str(project))\n     result = extractor.extract(\"a.py\", \"foo\", depth=1)\n     assert result.success\n     assert result.target is not None\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_symbol_references/test_licensing_and_limits.py\t2026-02-01 15:55:14.989541+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_symbol_references/test_licensing_and_limits.py\t2026-02-01 23:23:11.935065+00:00\n@@ -13,19 +13,16 @@\n         tier = \"enterprise\"\n         error_message = \"revoked license\"\n         is_expired = False\n \n     project = make_project(\n-        {\n-            f\"src/file_{i}.py\": \"\"\"\n+        {f\"src/file_{i}.py\": \"\"\"\n from shared.target import target\n \n def use():\n     return target()\n-\"\"\"\n-            for i in range(6)\n-        }\n+\"\"\" for i in range(6)}\n         | {\n             \"shared/target.py\": \"\"\"\n def target():\n     return 1\n \"\"\",\n@@ -65,19 +62,16 @@\n         tier = \"pro\"\n         error_message = \"license expired\"\n         is_expired = True\n \n     project = make_project(\n-        {\n-            f\"src/file_{i}.py\": \"\"\"\n+        {f\"src/file_{i}.py\": \"\"\"\n from shared.target import target\n \n def use():\n     return target()\n-\"\"\"\n-            for i in range(3)\n-        }\n+\"\"\" for i in range(3)}\n         | {\n             \"shared/target.py\": \"\"\"\n def target():\n     return 1\n \"\"\",\n@@ -114,19 +108,16 @@\n         tier = \"pro\"\n         error_message = \"invalid signature\"\n         is_expired = False\n \n     project = make_project(\n-        {\n-            f\"src/file_{i}.py\": \"\"\"\n+        {f\"src/file_{i}.py\": \"\"\"\n from shared.target import target\n \n def use():\n     return target()\n-\"\"\"\n-            for i in range(3)\n-        }\n+\"\"\" for i in range(3)}\n         | {\n             \"shared/target.py\": \"\"\"\n def target():\n     return 1\n \"\"\",\n@@ -162,19 +153,16 @@\n         tier = \"enterprise\"\n         error_message = \"malformed JWT token\"\n         is_expired = False\n \n     project = make_project(\n-        {\n-            f\"src/file_{i}.py\": \"\"\"\n+        {f\"src/file_{i}.py\": \"\"\"\n from shared.target import target\n \n def use():\n     return target()\n-\"\"\"\n-            for i in range(4)\n-        }\n+\"\"\" for i in range(4)}\n         | {\n             \"shared/target.py\": \"\"\"\n def target():\n     return 1\n \"\"\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/conftest.py\t2026-02-01 15:55:14.951573+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/conftest.py\t2026-02-01 23:23:12.165778+00:00\n@@ -382,34 +382,30 @@\n     src_dir = project_dir / \"src\"\n     src_dir.mkdir()\n \n     # Create a main module\n     main_py = src_dir / \"main.py\"\n-    main_py.write_text(\n-        \"\"\"\n+    main_py.write_text(\"\"\"\n def center_function():\n     return func_a()\n \n def func_a():\n     return func_a1()\n \n def func_a1():\n     return \"result\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Create dependent modules\n     utils_py = src_dir / \"utils.py\"\n-    utils_py.write_text(\n-        \"\"\"\n+    utils_py.write_text(\"\"\"\n def func_b():\n     return func_b1()\n \n def func_b1():\n     return \"utility\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     return project_dir\n \n \n # ============================================================================\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_call_graph.py\t2026-02-01 15:55:15.004243+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_call_graph.py\t2026-02-01 23:23:12.345453+00:00\n@@ -440,115 +440,99 @@\n     \"\"\"Tests for the full build() method.\"\"\"\n \n     def test_build_simple_project(self):\n         \"\"\"Test building call graph for a simple project.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"main.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"main.py\").write_text(\"\"\"\n def main():\n     helper()\n \n def helper():\n     print(\"helping\")\n-\"\"\"\n-            )\n+\"\"\")\n             builder = CallGraphBuilder(Path(tmpdir))\n             graph = builder.build()\n \n             assert \"main.py:main\" in graph\n             assert \"main.py:helper\" in graph[\"main.py:main\"]\n \n     def test_build_multi_file_project(self):\n         \"\"\"Test building call graph across multiple files.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"main.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"main.py\").write_text(\"\"\"\n from utils import process\n \n def main():\n     process()\n-\"\"\"\n-            )\n-            Path(tmpdir, \"utils.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            Path(tmpdir, \"utils.py\").write_text(\"\"\"\n def process():\n     print(\"processing\")\n-\"\"\"\n-            )\n+\"\"\")\n             builder = CallGraphBuilder(Path(tmpdir))\n             graph = builder.build()\n \n             assert \"main.py:main\" in graph\n             # The call to process() should be resolved via imports\n             assert len(graph[\"main.py:main\"]) >= 1\n \n     def test_build_handles_syntax_errors(self):\n         \"\"\"Test that syntax errors in files don't crash the build.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"good.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"good.py\").write_text(\"\"\"\n def good():\n     pass\n-\"\"\"\n-            )\n-            Path(tmpdir, \"bad.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            Path(tmpdir, \"bad.py\").write_text(\"\"\"\n def bad(\n     # Missing closing paren - syntax error\n-\"\"\"\n-            )\n+\"\"\")\n             builder = CallGraphBuilder(Path(tmpdir))\n             # Should not raise - just skip the bad file\n             graph = builder.build()\n \n             assert \"good.py:good\" in graph\n \n     def test_build_handles_empty_files(self):\n         \"\"\"Test handling of empty Python files.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             Path(tmpdir, \"empty.py\").write_text(\"\")\n-            Path(tmpdir, \"real.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"real.py\").write_text(\"\"\"\n def real():\n     pass\n-\"\"\"\n-            )\n+\"\"\")\n             builder = CallGraphBuilder(Path(tmpdir))\n             graph = builder.build()\n \n             assert \"real.py:real\" in graph\n \n     def test_build_with_nested_functions(self):\n         \"\"\"Test handling of nested function definitions.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"nested.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"nested.py\").write_text(\"\"\"\n def outer():\n     def inner():\n         helper()\n     inner()\n-\"\"\"\n-            )\n+\"\"\")\n             builder = CallGraphBuilder(Path(tmpdir))\n             graph = builder.build()\n \n             # Note: Current impl may handle nested differently\n             assert \"nested.py:outer\" in graph or \"nested.py:inner\" in graph\n \n     def test_build_with_classes(self):\n         \"\"\"Test handling of class methods in call graph.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n-            Path(tmpdir, \"classes.py\").write_text(\n-                \"\"\"\n+            Path(tmpdir, \"classes.py\").write_text(\"\"\"\n class MyClass:\n     def method_a(self):\n         self.method_b()\n     \n     def method_b(self):\n         pass\n-\"\"\"\n-            )\n+\"\"\")\n             builder = CallGraphBuilder(Path(tmpdir))\n             graph = builder.build()\n \n             assert \"classes.py:method_a\" in graph\n             assert \"self.method_b\" in graph[\"classes.py:method_a\"]\n@@ -643,36 +627,30 @@\n             src.mkdir()\n             tests = Path(tmpdir, \"tests\")\n             tests.mkdir()\n \n             Path(src, \"__init__.py\").write_text(\"\")\n-            Path(src, \"core.py\").write_text(\n-                \"\"\"\n+            Path(src, \"core.py\").write_text(\"\"\"\n from .utils import helper\n \n def main():\n     helper()\n     process()\n \n def process():\n     print(\"processing\")\n-\"\"\"\n-            )\n-            Path(src, \"utils.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            Path(src, \"utils.py\").write_text(\"\"\"\n def helper():\n     return \"helping\"\n-\"\"\"\n-            )\n-            Path(tests, \"test_core.py\").write_text(\n-                \"\"\"\n+\"\"\")\n+            Path(tests, \"test_core.py\").write_text(\"\"\"\n from src.core import main\n \n def test_main():\n     main()\n-\"\"\"\n-            )\n+\"\"\")\n \n             builder = CallGraphBuilder(Path(tmpdir))\n             graph = builder.build()\n \n             # Should have entries for all functions\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_project_map/conftest.py\t2026-02-01 15:55:14.980522+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_project_map/conftest.py\t2026-02-01 23:23:12.355967+00:00\n@@ -209,20 +209,17 @@\n     \"\"\"Project with files of varying complexity.\"\"\"\n     root = tmp_path / \"complexity_project\"\n     root.mkdir()\n \n     # Low complexity\n-    (root / \"simple.py\").write_text(\n-        \"\"\"\n+    (root / \"simple.py\").write_text(\"\"\"\n def simple_function():\n     return 42\n-\"\"\"\n-    )\n+\"\"\")\n \n     # High complexity (cyclomatic complexity ~15)\n-    (root / \"complex.py\").write_text(\n-        \"\"\"\n+    (root / \"complex.py\").write_text(\"\"\"\n def complex_function(x, y, z):\n     if x > 10:\n         if y > 20:\n             if z > 30:\n                 return x + y + z\n@@ -239,12 +236,11 @@\n             return x * y\n         else:\n             return x\n     else:\n         return 0\n-\"\"\"\n-    )\n+\"\"\")\n \n     return root\n \n \n @pytest.fixture\n@@ -252,42 +248,36 @@\n     \"\"\"Flask-like project structure for architectural layer detection.\"\"\"\n     root = tmp_path / \"flask_app\"\n     root.mkdir()\n \n     # Presentation layer\n-    (root / \"app.py\").write_text(\n-        \"\"\"\n+    (root / \"app.py\").write_text(\"\"\"\n from flask import Flask, request\n app = Flask(__name__)\n \n @app.route('/')\n def index():\n     return \"Hello\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Business layer\n     services = root / \"services\"\n     services.mkdir()\n     (services / \"__init__.py\").write_text(\"\")\n-    (services / \"order_service.py\").write_text(\n-        \"\"\"\n+    (services / \"order_service.py\").write_text(\"\"\"\n def process_order(order_data):\n     pass\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Data layer\n     models = root / \"models\"\n     models.mkdir()\n     (models / \"__init__.py\").write_text(\"\")\n-    (models / \"order.py\").write_text(\n-        \"\"\"\n+    (models / \"order.py\").write_text(\"\"\"\n class Order:\n     pass\n-\"\"\"\n-    )\n+\"\"\")\n \n     return root\n \n \n # ====================\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_extractor.py\t2026-02-01 15:55:15.021417+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_extractor.py\t2026-02-01 23:23:12.371030+00:00\n@@ -35,12 +35,11 @@\n \n @pytest.fixture\n def simple_project(temp_project):\n     \"\"\"Create a simple project with imports between files.\"\"\"\n     # utils.py - base utilities\n-    (temp_project / \"utils.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"utils.py\").write_text(\"\"\"\n def format_string(s):\n     \\\"\\\"\\\"Format a string.\\\"\\\"\\\"\n     return s.strip().upper()\n \n def validate(data):\n@@ -48,30 +47,26 @@\n     return data is not None\n \n class Formatter:\n     def format(self, value):\n         return str(value)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # models.py - uses utils\n-    (temp_project / \"models.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"models.py\").write_text(\"\"\"\n from utils import format_string, validate\n \n class User:\n     def __init__(self, name):\n         self.name = format_string(name)\n     \n     def is_valid(self):\n         return validate(self.name)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # views.py - uses both\n-    (temp_project / \"views.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"views.py\").write_text(\"\"\"\n from models import User\n from utils import Formatter\n \n def create_user(name):\n     \\\"\\\"\\\"Create a new user.\\\"\\\"\\\"\n@@ -81,56 +76,47 @@\n     return None\n \n def format_output(user):\n     formatter = Formatter()\n     return formatter.format(user.name)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def deep_project(temp_project):\n     \"\"\"Create a project with deep import chains.\"\"\"\n     # level0.py\n-    (temp_project / \"level0.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"level0.py\").write_text(\"\"\"\n def base_func():\n     return \"base\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     # level1.py\n-    (temp_project / \"level1.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"level1.py\").write_text(\"\"\"\n from level0 import base_func\n \n def level1_func():\n     return base_func() + \"_level1\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     # level2.py\n-    (temp_project / \"level2.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"level2.py\").write_text(\"\"\"\n from level1 import level1_func\n \n def level2_func():\n     return level1_func() + \"_level2\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     # level3.py\n-    (temp_project / \"level3.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"level3.py\").write_text(\"\"\"\n from level2 import level2_func\n \n def level3_func():\n     return level2_func() + \"_level3\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n@@ -140,38 +126,32 @@\n     pkg = temp_project / \"myapp\"\n     pkg.mkdir()\n     (pkg / \"__init__.py\").write_text(\"\")\n \n     # myapp/core.py\n-    (pkg / \"core.py\").write_text(\n-        \"\"\"\n+    (pkg / \"core.py\").write_text(\"\"\"\n def process(data):\n     return data.upper()\n-\"\"\"\n-    )\n+\"\"\")\n \n     # myapp/services.py\n-    (pkg / \"services.py\").write_text(\n-        \"\"\"\n+    (pkg / \"services.py\").write_text(\"\"\"\n from .core import process\n \n class DataService:\n     def handle(self, data):\n         return process(data)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # main.py\n-    (temp_project / \"main.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"main.py\").write_text(\"\"\"\n from myapp.services import DataService\n \n def run():\n     service = DataService()\n     return service.handle(\"test\")\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n # =============================================================================\n@@ -469,41 +449,35 @@\n \n         assert result.success\n \n     def test_circular_imports(self, temp_project):\n         \"\"\"Test handling of circular imports.\"\"\"\n-        (temp_project / \"a.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"a.py\").write_text(\"\"\"\n from b import func_b\n def func_a():\n     return func_b()\n-\"\"\"\n-        )\n-        (temp_project / \"b.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (temp_project / \"b.py\").write_text(\"\"\"\n from a import func_a\n def func_b():\n     return 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = CrossFileExtractor(temp_project)\n         result = extractor.extract(\"a.py\", \"func_a\", depth=5)\n \n         # Should complete without infinite loop\n         assert result.success or len(result.warnings) > 0\n \n     def test_builtin_dependencies_filtered(self, temp_project):\n         \"\"\"Test that builtin names aren't treated as dependencies.\"\"\"\n-        (temp_project / \"test.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"test.py\").write_text(\"\"\"\n def test_func():\n     x = len([1, 2, 3])\n     y = str(x)\n     return print(y)\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = CrossFileExtractor(temp_project)\n         result = extractor.extract(\"test.py\", \"test_func\", depth=1)\n \n         assert result.success\n@@ -639,19 +613,17 @@\n         \"\"\"Test that rebuild() refreshes the import graph.\"\"\"\n         extractor = CrossFileExtractor(simple_project)\n         extractor.build()\n \n         # Modify a file\n-        (simple_project / \"utils.py\").write_text(\n-            \"\"\"\n+        (simple_project / \"utils.py\").write_text(\"\"\"\n def format_string(s):\n     return s.lower()  # Changed behavior\n \n def new_function():\n     return \"new\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Rebuild and extract\n         extractor.build()\n         result = extractor.extract(\"utils.py\", \"new_function\", depth=0)\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_file_context_tiers_clean.py\t2026-02-01 15:55:15.057276+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_file_context_tiers_clean.py\t2026-02-01 23:23:12.430404+00:00\n@@ -18,20 +18,16 @@\n async def test_async_get_file_context_pro(monkeypatch, tmp_path):\n     helper = tmp_path / \"helper.py\"\n     helper.write_text(\"CONST = 1\\n\")\n \n     target = tmp_path / \"target.py\"\n-    target.write_text(\n-        textwrap.dedent(\n-            \"\"\"\n+    target.write_text(textwrap.dedent(\"\"\"\n             import helper\n \n             def calc(x):\n                 return helper.CONST + x\n-            \"\"\"\n-        )\n-    )\n+            \"\"\"))\n \n     pro_caps = _caps(\n         2000,\n         {\n             \"raw_source_retrieval\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_resolution.py\t2026-02-01 15:55:15.036525+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_resolution.py\t2026-02-01 23:23:12.582843+00:00\n@@ -22,12 +22,11 @@\n     @pytest.fixture\n     def temp_project(self, tmp_path: Path):\n         \"\"\"Create a temporary project structure with multiple files.\"\"\"\n         # models.py - defines TaxRate\n         models_py = tmp_path / \"models.py\"\n-        models_py.write_text(\n-            '''\"\"\"Models module.\"\"\"\n+        models_py.write_text('''\"\"\"Models module.\"\"\"\n \n class TaxRate:\n     \"\"\"Tax rate configuration.\"\"\"\n     \n     def __init__(self, rate: float):\n@@ -42,17 +41,15 @@\n     \"\"\"Get the default tax rate.\"\"\"\n     return 0.1\n \n \n TAX_CONSTANT = 0.15\n-'''\n-        )\n+''')\n \n         # utils.py - imports from models\n         utils_py = tmp_path / \"utils.py\"\n-        utils_py.write_text(\n-            '''\"\"\"Utilities module.\"\"\"\n+        utils_py.write_text('''\"\"\"Utilities module.\"\"\"\n \n from models import TaxRate, get_default_rate, TAX_CONSTANT\n \n \n def calculate_tax(amount: float) -> float:\n@@ -62,19 +59,17 @@\n \n \n def apply_flat_tax(amount: float) -> float:\n     \"\"\"Apply flat tax using constant.\"\"\"\n     return amount * TAX_CONSTANT\n-'''\n-        )\n+''')\n \n         # services/order.py - nested import\n         services_dir = tmp_path / \"services\"\n         services_dir.mkdir()\n         order_py = services_dir / \"order.py\"\n-        order_py.write_text(\n-            '''\"\"\"Order service.\"\"\"\n+        order_py.write_text('''\"\"\"Order service.\"\"\"\n \n from models import TaxRate\n \n \n class OrderProcessor:\n@@ -83,12 +78,11 @@\n     def __init__(self):\n         self.tax_rate = TaxRate(0.08)\n     \n     def process(self, amount: float) -> float:\n         return amount + self.tax_rate.calculate(amount)\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_resolve_function_with_class_import(self, temp_project: Path):\n         \"\"\"Test resolving a function that imports a class.\"\"\"\n@@ -213,56 +207,48 @@\n     @pytest.fixture\n     def temp_project(self, tmp_path: Path):\n         \"\"\"Create a project with various edge cases.\"\"\"\n         # File with missing import target\n         broken_py = tmp_path / \"broken.py\"\n-        broken_py.write_text(\n-            '''\"\"\"Broken imports.\"\"\"\n+        broken_py.write_text('''\"\"\"Broken imports.\"\"\"\n \n from nonexistent import DoesNotExist\n \n \n def use_missing():\n     return DoesNotExist()\n-'''\n-        )\n+''')\n \n         # File with relative imports\n         pkg_dir = tmp_path / \"package\"\n         pkg_dir.mkdir()\n         (pkg_dir / \"__init__.py\").write_text(\"\")\n \n         helper_py = pkg_dir / \"helper.py\"\n-        helper_py.write_text(\n-            '''\"\"\"Helper module.\"\"\"\n+        helper_py.write_text('''\"\"\"Helper module.\"\"\"\n \n def helper_func():\n     return 42\n-'''\n-        )\n+''')\n \n         main_py = pkg_dir / \"main.py\"\n-        main_py.write_text(\n-            '''\"\"\"Main module.\"\"\"\n+        main_py.write_text('''\"\"\"Main module.\"\"\"\n \n from .helper import helper_func\n \n \n def main():\n     return helper_func()\n-'''\n-        )\n+''')\n \n         # Standalone file\n         standalone_py = tmp_path / \"standalone.py\"\n-        standalone_py.write_text(\n-            '''\"\"\"No imports.\"\"\"\n+        standalone_py.write_text('''\"\"\"No imports.\"\"\"\n \n def pure_function(x: int) -> int:\n     return x * 2\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_unresolved_import(self, temp_project: Path):\n         \"\"\"Test handling of imports that cannot be resolved.\"\"\"\n@@ -348,43 +334,37 @@\n \n     @pytest.fixture\n     def chain_project(self, tmp_path: Path):\n         \"\"\"Create a project with chained dependencies.\"\"\"\n         # level0.py\n-        (tmp_path / \"level0.py\").write_text(\n-            '''\"\"\"Base level.\"\"\"\n+        (tmp_path / \"level0.py\").write_text('''\"\"\"Base level.\"\"\"\n \n BASE_VALUE = 100\n \n def level0_func():\n     return BASE_VALUE\n-'''\n-        )\n+''')\n \n         # level1.py imports level0\n-        (tmp_path / \"level1.py\").write_text(\n-            '''\"\"\"Level 1.\"\"\"\n+        (tmp_path / \"level1.py\").write_text('''\"\"\"Level 1.\"\"\"\n \n from level0 import level0_func, BASE_VALUE\n \n \n def level1_func():\n     return level0_func() + BASE_VALUE\n-'''\n-        )\n+''')\n \n         # level2.py imports level1\n-        (tmp_path / \"level2.py\").write_text(\n-            '''\"\"\"Level 2.\"\"\"\n+        (tmp_path / \"level2.py\").write_text('''\"\"\"Level 2.\"\"\"\n \n from level1 import level1_func\n \n \n def level2_func():\n     return level1_func() * 2\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_depth_1_resolution(self, chain_project: Path):\n         \"\"\"Test resolution with depth=1 (default).\"\"\"\n@@ -428,18 +408,16 @@\n     \"\"\"Test the _build_import_map method.\"\"\"\n \n     def test_from_import(self, tmp_path: Path):\n         \"\"\"Test mapping from 'from X import Y' syntax.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"from models import User, Order\n+        test_file.write_text(\"\"\"from models import User, Order\n from utils import helper as h\n \n def func():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(test_file))\n         import_map = extractor._build_import_map()\n \n         assert \"User\" in import_map\n@@ -447,18 +425,16 @@\n         assert \"h\" in import_map  # aliased import\n \n     def test_import_module(self, tmp_path: Path):\n         \"\"\"Test mapping from 'import X' syntax.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"import os\n+        test_file.write_text(\"\"\"import os\n import sys as system\n \n def func():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         extractor = SurgicalExtractor.from_file(str(test_file))\n         import_map = extractor._build_import_map()\n \n         assert \"os\" in import_map\n@@ -545,54 +521,48 @@\n     @pytest.fixture\n     def temp_project_transitive(self, tmp_path: Path):\n         \"\"\"Create a temporary project with transitive dependencies.\"\"\"\n         # base.py - defines BaseClass\n         base_py = tmp_path / \"base.py\"\n-        base_py.write_text(\n-            '''\"\"\"Base module.\"\"\"\n+        base_py.write_text('''\"\"\"Base module.\"\"\"\n \n class BaseClass:\n     \"\"\"Base class for all services.\"\"\"\n     \n     def __init__(self, name: str):\n         self.name = name\n     \n     def get_name(self) -> str:\n         return self.name\n-'''\n-        )\n+''')\n \n         # models.py - imports from base.py\n         models_py = tmp_path / \"models.py\"\n-        models_py.write_text(\n-            '''\"\"\"Models module.\"\"\"\n+        models_py.write_text('''\"\"\"Models module.\"\"\"\n \n from base import BaseClass\n \n \n class UserModel(BaseClass):\n     \"\"\"User model extends BaseClass.\"\"\"\n     \n     def __init__(self, name: str, email: str):\n         super().__init__(name)\n         self.email = email\n-'''\n-        )\n+''')\n \n         # services.py - imports from models.py\n         services_py = tmp_path / \"services.py\"\n-        services_py.write_text(\n-            '''\"\"\"Services module.\"\"\"\n+        services_py.write_text('''\"\"\"Services module.\"\"\"\n \n from models import UserModel\n \n \n def create_user(name: str, email: str) -> UserModel:\n     \"\"\"Create a new user.\"\"\"\n     return UserModel(name, email)\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_resolve_depth_0_only_target(self, temp_project_transitive: Path):\n         \"\"\"Test depth=0 resolution - only the target function.\"\"\"\n@@ -673,55 +643,47 @@\n     @pytest.fixture\n     def temp_project_reexports(self, tmp_path: Path):\n         \"\"\"Create a temporary project with re-exports.\"\"\"\n         # internal.py - defines internal classes\n         internal_py = tmp_path / \"internal.py\"\n-        internal_py.write_text(\n-            '''\"\"\"Internal module - not public.\"\"\"\n+        internal_py.write_text('''\"\"\"Internal module - not public.\"\"\"\n \n class _InternalHelper:\n     \"\"\"Internal helper class.\"\"\"\n     \n     def process(self, data: str) -> str:\n         return data.upper()\n-'''\n-        )\n+''')\n \n         # public_api.py - re-exports InternalHelper\n         public_api_py = tmp_path / \"public_api.py\"\n-        public_api_py.write_text(\n-            '''\"\"\"Public API module.\"\"\"\n+        public_api_py.write_text('''\"\"\"Public API module.\"\"\"\n \n from internal import _InternalHelper as InternalHelper\n \n # Explicitly define what's public\n __all__ = [\"InternalHelper\"]\n-'''\n-        )\n+''')\n \n         # client.py - imports from public_api\n         client_py = tmp_path / \"client.py\"\n-        client_py.write_text(\n-            '''\"\"\"Client code.\"\"\"\n+        client_py.write_text('''\"\"\"Client code.\"\"\"\n \n from public_api import InternalHelper\n \n \n def create_helper() -> InternalHelper:\n     \"\"\"Factory function.\"\"\"\n     return InternalHelper()\n-'''\n-        )\n+''')\n \n         # alt_api.py - re-exports without __all__\n         alt_api_py = tmp_path / \"alt_api.py\"\n-        alt_api_py.write_text(\n-            '''\"\"\"Alternative API.\"\"\"\n+        alt_api_py.write_text('''\"\"\"Alternative API.\"\"\"\n \n from internal import _InternalHelper\n-'''\n-        )\n+''')\n \n         return tmp_path\n \n     def test_resolve_with_alias_reexport(self, temp_project_reexports: Path):\n         \"\"\"Test resolving imports through re-export aliases.\"\"\"\n@@ -750,33 +712,29 @@\n \n     def test_resolve_circular_imports_prevented(self, tmp_path: Path):\n         \"\"\"Test that circular imports don't cause infinite loops.\"\"\"\n         # circular_a.py\n         circular_a = tmp_path / \"circular_a.py\"\n-        circular_a.write_text(\n-            '''\"\"\"Module A.\"\"\"\n+        circular_a.write_text('''\"\"\"Module A.\"\"\"\n \n from circular_b import b_function\n \n \n def a_function():\n     return b_function()\n-'''\n-        )\n+''')\n \n         # circular_b.py - imports from circular_a\n         circular_b = tmp_path / \"circular_b.py\"\n-        circular_b.write_text(\n-            '''\"\"\"Module B.\"\"\"\n+        circular_b.write_text('''\"\"\"Module B.\"\"\"\n \n from circular_a import a_function\n \n \n def b_function():\n     return a_function()\n-'''\n-        )\n+''')\n \n         # Try to resolve - should not hang\n         extractor = SurgicalExtractor.from_file(str(circular_a))\n         result = extractor.resolve_cross_file_dependencies(\n             target_name=\"a_function\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/get_cross_file_dependencies/test_mcp_protocol_and_security.py\t2026-02-01 15:55:14.928913+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/get_cross_file_dependencies/test_mcp_protocol_and_security.py\t2026-02-01 23:23:12.650199+00:00\n@@ -401,20 +401,18 @@\n \n     async def test_decorated_function_extraction(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"decorated.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n def decorator(f):\n     return f\n \n @decorator\n def target():\n     return 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         assert data.get(\"success\") is True\n@@ -423,16 +421,14 @@\n \n     async def test_async_function_extraction(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"async_func.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n async def target():\n     return 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         assert data.get(\"success\") is True\n@@ -441,18 +437,16 @@\n \n     async def test_nested_class_extraction(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"nested.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n class Outer:\n     class Inner:\n         def method(self):\n             return 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"Outer\")\n \n         data = result.get(\"data\") or {}\n         # Tool may or may not extract nested classes; just verify no crash\n@@ -460,17 +454,15 @@\n \n     async def test_lambda_function_handling(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"lambda_func.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n def target():\n     f = lambda x: x + 1\n     return f(10)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         assert data.get(\"success\") is True\n@@ -481,17 +473,15 @@\n         self, monkeypatch, tmp_path, tool\n     ):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"docstring.py\"\n-        target_file.write_text(\n-            '''\n+        target_file.write_text('''\n def target():\n     \"\"\"This is a docstring.\"\"\"\n     return 1\n-'''\n-        )\n+''')\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         assert data.get(\"success\") is True\n@@ -500,20 +490,18 @@\n \n     async def test_multiline_statement_handling(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"multiline.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n def target():\n     result = (\n         1 + 2 + 3 +\n         4 + 5 + 6\n     )\n     return result\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         assert data.get(\"success\") is True\n@@ -522,17 +510,15 @@\n \n     async def test_unusual_indentation_handling(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"indented.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n def target():\n         x = 1  # Extra indentation\n         return x\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         # May succeed or fail depending on Python parser strictness\n@@ -699,17 +685,15 @@\n         caplog.set_level(logging.DEBUG)\n \n         secret = \"sk_prod_987_REDACT_ME\"\n \n         target_file = tmp_path / \"secret_code.py\"\n-        target_file.write_text(\n-            f\"\"\"\n+        target_file.write_text(f\"\"\"\n def target():\n     api_key = \"{secret}\"\n     return api_key\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Request with include_code=True and force error by wrong symbol\n         result = await tool.run(\n             {\n                 \"target_file\": str(target_file),\n@@ -731,17 +715,15 @@\n \n     async def test_partial_file_with_valid_syntax(self, monkeypatch, tmp_path, tool):\n         monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n \n         target_file = tmp_path / \"partial.py\"\n-        target_file.write_text(\n-            \"\"\"\n+        target_file.write_text(\"\"\"\n def target():\n     x = 1\n # Missing closing of something, but syntactically valid so far\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await _invoke_tool(tool, tmp_path, target_file, \"target\")\n \n         data = result.get(\"data\") or {}\n         assert data.get(\"success\") is True\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_call_graph.py\t2026-02-01 15:55:15.050757+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_call_graph.py\t2026-02-01 23:23:12.704976+00:00\n@@ -127,23 +127,21 @@\n \n     @pytest.fixture\n     def sample_project(self, tmp_path):\n         \"\"\"Create a sample project for testing.\"\"\"\n         main_py = tmp_path / \"main.py\"\n-        main_py.write_text(\n-            \"\"\"\n+        main_py.write_text(\"\"\"\n def main():\n     helper()\n     print(\"done\")\n \n def helper():\n     pass\n \n if __name__ == \"__main__\":\n     main()\n-\"\"\"\n-        )\n+\"\"\")\n         return tmp_path\n \n     def test_sync_returns_result(self, sample_project):\n         \"\"\"Test sync function returns CallGraphResultModel.\"\"\"\n         result = _get_call_graph_sync(str(sample_project), None, 10, False)\n@@ -168,22 +166,20 @@\n         result = _get_call_graph_sync(str(sample_project), \"main\", 1, False)\n         assert result.depth_limit == 1\n \n     def test_sync_detects_main_block_entry_point(self, tmp_path):\n         \"\"\"Functions called from __main__ block are treated as entry points.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def run():\n     helper()\n \n def helper():\n     pass\n \n if __name__ == \\\"__main__\\\":\n     run()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = _get_call_graph_sync(str(tmp_path), None, 10, False)\n         entry_points = {n.name for n in result.nodes if n.is_entry_point}\n         assert \"run\" in entry_points\n \n@@ -443,28 +439,24 @@\n class TestJavaScriptSupport:\n     \"\"\"Basic JS call graph support at Community tier.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_js_project_generates_nodes_and_edges(self, tmp_path):\n-        (tmp_path / \"util.js\").write_text(\n-            \"\"\"\n+        (tmp_path / \"util.js\").write_text(\"\"\"\n export function foo() {\n     return 1;\n }\n-\"\"\"\n-        )\n-        (tmp_path / \"index.js\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (tmp_path / \"index.js\").write_text(\"\"\"\n import { foo } from './util.js';\n \n function main() {\n     foo();\n }\n \n main();\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(\n             project_root=str(tmp_path), include_circular_import_check=False\n         )\n         assert result.error is None\n@@ -482,29 +474,25 @@\n     \"\"\"Basic TS call graph support at Community tier.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_ts_project_generates_nodes_and_edges(self, tmp_path):\n         # [20260122_TEST] Ensure TypeScript call mapping works end-to-end\n-        (tmp_path / \"util.ts\").write_text(\n-            \"\"\"\n+        (tmp_path / \"util.ts\").write_text(\"\"\"\n export function foo(value: number): number {\n     return value + 1;\n }\n-\"\"\"\n-        )\n-\n-        (tmp_path / \"index.ts\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (tmp_path / \"index.ts\").write_text(\"\"\"\n import { foo } from './util.ts';\n \n function main(): number {\n     return foo(1);\n }\n \n main();\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(\n             project_root=str(tmp_path), include_circular_import_check=False\n         )\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/conftest.py\t2026-02-01 15:55:15.083637+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/conftest.py\t2026-02-01 23:23:12.717200+00:00\n@@ -12,12 +12,11 @@\n \n     Returns:\n         Path to sample file\n     \"\"\"\n     auth_py = tmp_path / \"auth.py\"\n-    auth_py.write_text(\n-        \"\"\"\n+    auth_py.write_text(\"\"\"\n from typing import Optional\n from datetime import datetime\n \n \n class User:\n@@ -41,12 +40,11 @@\n \n \n def hash_password(password: str) -> str:\n     \\\"\\\"\\\"Hash a password.\\\"\\\"\\\"\n     return password\n-\"\"\"\n-    )\n+\"\"\")\n     return auth_py\n \n \n @pytest.fixture\n def sample_models_file(tmp_path: Path) -> Path:\n@@ -54,12 +52,11 @@\n \n     Returns:\n         Path to sample file\n     \"\"\"\n     models_py = tmp_path / \"models.py\"\n-    models_py.write_text(\n-        \"\"\"\n+    models_py.write_text(\"\"\"\n from typing import List\n \n \n class BaseModel:\n     pass\n@@ -73,12 +70,11 @@\n         self.email = email\n \n     @classmethod\n     def from_dict(cls, data: dict) -> \"User\":\n         return cls(id=data[\"id\"], email=data[\"email\"])\n-\"\"\"\n-    )\n+\"\"\")\n     return models_py\n \n \n @pytest.fixture\n def sample_project(tmp_path: Path) -> Path:\n@@ -89,12 +85,11 @@\n     \"\"\"\n     src = tmp_path / \"src\"\n     src.mkdir()\n \n     # Create auth.py\n-    (src / \"auth.py\").write_text(\n-        \"\"\"\n+    (src / \"auth.py\").write_text(\"\"\"\n from typing import Optional\n \n \n def validate_token(token: str) -> Optional[dict]:\n     \\\"\\\"\\\"Validate JWT token.\\\"\\\"\\\"\n@@ -102,19 +97,16 @@\n \n \n def encode_token(user_id: int) -> str:\n     \\\"\\\"\\\"Encode JWT token.\\\"\\\"\\\"\n     return \"\"\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Create models.py\n-    (src / \"models.py\").write_text(\n-        \"\"\"\n+    (src / \"models.py\").write_text(\"\"\"\n class User:\n     def __init__(self, id: int, email: str):\n         self.id = id\n         self.email = email\n-\"\"\"\n-    )\n+\"\"\")\n \n     return tmp_path\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/conftest.py\t2026-02-01 15:55:15.115175+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/conftest.py\t2026-02-01 23:23:12.944269+00:00\n@@ -14,46 +14,40 @@\n def temp_project(tmp_path):\n     \"\"\"Create a temporary project with multiple files for cross-file testing.\"\"\"\n \n     # Main module with functions/classes\n     main_py = tmp_path / \"main.py\"\n-    main_py.write_text(\n-        \"\"\"\n+    main_py.write_text(\"\"\"\n def old_function():\n     return \"hello\"\n \n class OldClass:\n     def old_method(self):\n         return \"method\"\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     # File that imports from main\n     utils_py = tmp_path / \"utils.py\"\n-    utils_py.write_text(\n-        \"\"\"\n+    utils_py.write_text(\"\"\"\n from main import old_function, OldClass\n \n def use_old():\n     return old_function()\n \n def use_class():\n     obj = OldClass()\n     return obj.old_method()\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     # Another file with module import\n     helper_py = tmp_path / \"helper.py\"\n-    helper_py.write_text(\n-        \"\"\"\n+    helper_py.write_text(\"\"\"\n import main\n \n def call_it():\n     return main.old_function()\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     return tmp_path\n \n \n @pytest.fixture(autouse=True)\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_project_map.py\t2026-02-01 15:55:15.063289+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_project_map.py\t2026-02-01 23:23:12.953571+00:00\n@@ -130,28 +130,24 @@\n     \"\"\"Tests for _get_project_map_sync function.\"\"\"\n \n     @pytest.fixture\n     def simple_project(self, tmp_path):\n         \"\"\"Create a simple project structure.\"\"\"\n-        (tmp_path / \"main.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"main.py\").write_text(\"\"\"\n def main():\n     helper()\n \n def helper():\n     pass\n \n if __name__ == \"__main__\":\n     main()\n-\"\"\"\n-        )\n-        (tmp_path / \"utils.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (tmp_path / \"utils.py\").write_text(\"\"\"\n def utility():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n         return tmp_path\n \n     @pytest.fixture\n     def package_project(self, tmp_path):\n         \"\"\"Create a project with packages.\"\"\"\n@@ -160,16 +156,14 @@\n \n         # Package with init\n         pkg = tmp_path / \"pkg\"\n         pkg.mkdir()\n         (pkg / \"__init__.py\").write_text(\"\")\n-        (pkg / \"module.py\").write_text(\n-            \"\"\"\n+        (pkg / \"module.py\").write_text(\"\"\"\n def process():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Subpackage\n         subpkg = pkg / \"sub\"\n         subpkg.mkdir()\n         (subpkg / \"__init__.py\").write_text(\"\")\n@@ -215,36 +209,33 @@\n         pkg_names = {p.name for p in result.packages}\n         assert \"pkg\" in pkg_names\n \n     def test_sync_calculates_complexity(self, tmp_path):\n         \"\"\"Test sync function calculates complexity.\"\"\"\n-        (tmp_path / \"complex.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"complex.py\").write_text(\"\"\"\n def complex_func(x):\n     if x > 0:\n         if x > 10:\n             for i in range(x):\n                 if i % 2:\n                     print(i)\n         else:\n             while x:\n                 x -= 1\n     return x\n-\"\"\"\n-        )\n+\"\"\")\n         result = _get_project_map_sync(str(tmp_path), True, 5, False)\n \n         # Should have complexity score\n         complex_mod = next((m for m in result.modules if \"complex.py\" in m.path), None)\n         assert complex_mod is not None\n         assert complex_mod.complexity_score > 0\n \n     def test_sync_flags_complexity_hotspots(self, tmp_path):\n         \"\"\"Test sync function flags complexity hotspots.\"\"\"\n         # Create a very complex file\n-        (tmp_path / \"hotspot.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"hotspot.py\").write_text(\"\"\"\n def mega_complex(a, b, c, d, e):\n     if a:\n         if b:\n             if c:\n                 if d:\n@@ -255,12 +246,11 @@\n                                     while i:\n                                         i -= 1\n                                         if i % 2:\n                                             pass\n     return a and b and c and d and e\n-\"\"\"\n-        )\n+\"\"\")\n         result = _get_project_map_sync(str(tmp_path), True, 5, False)\n         assert len(result.complexity_hotspots) >= 1\n \n     def test_sync_generates_mermaid(self, simple_project):\n         \"\"\"Test sync function generates Mermaid diagram.\"\"\"\n@@ -289,25 +279,21 @@\n     \"\"\"Tests for async get_project_map function.\"\"\"\n \n     @pytest.fixture\n     def sample_project(self, tmp_path):\n         \"\"\"Create a sample project.\"\"\"\n-        (tmp_path / \"main.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"main.py\").write_text(\"\"\"\n def main():\n     run()\n \n def run():\n     pass\n-\"\"\"\n-        )\n-        (tmp_path / \"config.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+        (tmp_path / \"config.py\").write_text(\"\"\"\n class Config:\n     DEBUG = True\n-\"\"\"\n-        )\n+\"\"\")\n         return tmp_path\n \n     @pytest.mark.asyncio\n     async def test_async_returns_result(self, sample_project):\n         \"\"\"Test async function returns result.\"\"\"\n@@ -370,40 +356,36 @@\n         assert any(\"main\" in ep for ep in result.entry_points)\n \n     @pytest.mark.asyncio\n     async def test_click_command_detected(self, tmp_path):\n         \"\"\"Test @click.command decorated function is detected.\"\"\"\n-        (tmp_path / \"cli.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"cli.py\").write_text(\"\"\"\n import click\n \n @click.command()\n def cli():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         result = await get_project_map(project_root=str(tmp_path))\n         entry_funcs = [ep.split(\":\")[-1] for ep in result.entry_points]\n         assert \"cli\" in entry_funcs\n \n     @pytest.mark.asyncio\n     async def test_flask_route_detected(self, tmp_path):\n         \"\"\"Test @app.route decorated function is detected.\"\"\"\n-        (tmp_path / \"web.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"web.py\").write_text(\"\"\"\n from flask import Flask\n app = Flask(__name__)\n \n @app.route(\"/\")\n def index():\n     return \"Hello\"\n \n @app.get(\"/api\")\n def api():\n     return {}\n-\"\"\"\n-        )\n+\"\"\")\n         result = await get_project_map(project_root=str(tmp_path))\n         entry_funcs = [ep.split(\":\")[-1] for ep in result.entry_points]\n         assert \"index\" in entry_funcs\n         assert \"api\" in entry_funcs\n \n@@ -496,22 +478,19 @@\n     async def test_flask_application(self, tmp_path):\n         \"\"\"Test with Flask-like application structure.\"\"\"\n         app = tmp_path / \"app\"\n         app.mkdir()\n \n-        (app / \"__init__.py\").write_text(\n-            \"\"\"\n+        (app / \"__init__.py\").write_text(\"\"\"\n from flask import Flask\n \n def create_app():\n     app = Flask(__name__)\n     return app\n-\"\"\"\n-        )\n-\n-        (app / \"routes.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (app / \"routes.py\").write_text(\"\"\"\n from flask import Blueprint\n \n bp = Blueprint(\"main\", __name__)\n \n @bp.route(\"/\")\n@@ -522,24 +501,21 @@\n def api():\n     return get_data()\n \n def get_data():\n     return {\"status\": \"ok\"}\n-\"\"\"\n-        )\n-\n-        (app / \"models.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (app / \"models.py\").write_text(\"\"\"\n class User:\n     def __init__(self, name):\n         self.name = name\n \n class Post:\n     def __init__(self, title):\n         self.title = title\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_project_map(project_root=str(tmp_path))\n \n         # Should find package\n         assert any(p.name == \"app\" for p in result.packages)\n@@ -555,12 +531,11 @@\n         assert \"Post\" in all_classes\n \n     @pytest.mark.asyncio\n     async def test_cli_application(self, tmp_path):\n         \"\"\"Test with CLI application structure.\"\"\"\n-        (tmp_path / \"cli.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"cli.py\").write_text(\"\"\"\n import click\n \n @click.group()\n def main():\n     pass\n@@ -579,12 +554,11 @@\n def execute():\n     process()\n \n def process():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_project_map(project_root=str(tmp_path))\n \n         # Should detect CLI entry points\n         entry_funcs = [ep.split(\":\")[-1] for ep in result.entry_points]\n@@ -598,25 +572,22 @@\n         src = tmp_path / \"src\"\n         src.mkdir()\n \n         (src / \"__init__.py\").write_text(\"\")\n \n-        (src / \"data.py\").write_text(\n-            \"\"\"\n+        (src / \"data.py\").write_text(\"\"\"\n def load_data(path):\n     pass\n \n def clean_data(df):\n     pass\n \n def transform(df):\n     pass\n-\"\"\"\n-        )\n-\n-        (src / \"model.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (src / \"model.py\").write_text(\"\"\"\n class Model:\n     def fit(self, X, y):\n         pass\n     \n     def predict(self, X):\n@@ -624,22 +595,19 @@\n \n def train_model(data):\n     model = Model()\n     model.fit(data[\"X\"], data[\"y\"])\n     return model\n-\"\"\"\n-        )\n-\n-        (src / \"evaluate.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (src / \"evaluate.py\").write_text(\"\"\"\n def calculate_metrics(y_true, y_pred):\n     pass\n \n def plot_results(metrics):\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_project_map(project_root=str(tmp_path))\n \n         # Should find src package\n         assert any(p.name == \"src\" for p in result.packages)\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/test_oracle_ai_feedback.py\t2026-02-01 15:55:15.094890+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/test_oracle_ai_feedback.py\t2026-02-01 23:23:12.974539+00:00\n@@ -69,20 +69,18 @@\n \n         AI scenario: AI correctly identifies file and instruction\n         Expected: Successful response with constraint specification\n         \"\"\"\n         with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n-            f.write(\n-                \"\"\"\n+            f.write(\"\"\"\n def authenticate(user: str, password: str) -> bool:\n     return user == \"admin\" and password == \"secret\"\n \n class AuthManager:\n     def validate(self, token: str) -> bool:\n         return len(token) > 0\n-\"\"\"\n-            )\n+\"\"\")\n             temp_path = f.name\n \n         try:\n             with patch(\n                 \"code_scalpel.mcp.protocol._get_current_tier\", return_value=\"pro\"\n@@ -179,19 +177,17 @@\n \n         AI scenario: AI tries to extract function \"calculate\" but code has \"compute\"\n         Expected: Error indicates function not found, may suggest similar names\n         \"\"\"\n         with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n-            f.write(\n-                \"\"\"\n+            f.write(\"\"\"\n def compute_sum(a, b):\n     return a + b\n \n def compute_product(a, b):\n     return a * b\n-\"\"\"\n-            )\n+\"\"\")\n             temp_path = f.name\n \n         try:\n             response = await extract_code(\n                 target_type=\"function\",\n@@ -214,24 +210,22 @@\n \n         AI scenario: AI correctly identifies function to extract\n         Expected: Successful extraction with code and context\n         \"\"\"\n         with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n-            f.write(\n-                \"\"\"\n+            f.write(\"\"\"\n import math\n \n def calculate_distance(x1, y1, x2, y2):\n     '''Calculate Euclidean distance between two points.'''\n     return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n \n class Point:\n     def __init__(self, x, y):\n         self.x = x\n         self.y = y\n-\"\"\"\n-            )\n+\"\"\")\n             temp_path = f.name\n \n         try:\n             response = await extract_code(\n                 target_type=\"function\",\n@@ -254,24 +248,22 @@\n \n         AI scenario: AI extracts specific method from class\n         Expected: Successful extraction of method with class context\n         \"\"\"\n         with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n-            f.write(\n-                \"\"\"\n+            f.write(\"\"\"\n class Calculator:\n     '''A simple calculator.'''\n     \n     def add(self, a: int, b: int) -> int:\n         '''Add two numbers.'''\n         return a + b\n     \n     def multiply(self, a: int, b: int) -> int:\n         '''Multiply two numbers.'''\n         return a * b\n-\"\"\"\n-            )\n+\"\"\")\n             temp_path = f.name\n \n         try:\n             response = await extract_code(\n                 target_type=\"method\", target_name=\"Calculator.add\", file_path=temp_path\n@@ -293,19 +285,17 @@\n \n         AI scenario: AI tries to rename function that doesn't exist\n         Expected: Error indicates symbol not found\n         \"\"\"\n         with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n-            f.write(\n-                \"\"\"\n+            f.write(\"\"\"\n def authenticate_user(username, password):\n     return True\n \n def validate_token(token):\n     return len(token) > 0\n-\"\"\"\n-            )\n+\"\"\")\n             temp_path = f.name\n \n         try:\n             response = await rename_symbol(\n                 file_path=temp_path,\n@@ -327,19 +317,17 @@\n \n         AI scenario: AI correctly renames function\n         Expected: Successful rename with backup created\n         \"\"\"\n         with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n-            f.write(\n-                \"\"\"\n+            f.write(\"\"\"\n def old_name(x):\n     '''This will be renamed.'''\n     return x * 2\n \n print(old_name(5))\n-\"\"\"\n-            )\n+\"\"\")\n             temp_path = f.name\n \n         try:\n             response = await rename_symbol(\n                 file_path=temp_path,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_taint.py\t2026-02-01 15:55:15.044202+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_taint.py\t2026-02-01 23:23:12.991447+00:00\n@@ -42,152 +42,130 @@\n \n @pytest.fixture\n def simple_vuln_project(temp_project):\n     \"\"\"Create a project with a simple SQL injection vulnerability.\"\"\"\n     # routes.py - web routes that handle user input\n-    (temp_project / \"routes.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"routes.py\").write_text(\"\"\"\n from flask import request\n from db import execute_query\n \n def get_user():\n     user_id = request.args.get('id')\n     return execute_query(user_id)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # db.py - database operations\n-    (temp_project / \"db.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def execute_query(user_id):\n     conn = sqlite3.connect('test.db')\n     cursor = conn.cursor()\n     cursor.execute(f\"SELECT * FROM users WHERE id = {user_id}\")\n     return cursor.fetchone()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def safe_project(temp_project):\n     \"\"\"Create a project with parameterized queries (safe).\"\"\"\n-    (temp_project / \"routes.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"routes.py\").write_text(\"\"\"\n from flask import request\n from db import get_user_safe\n \n def get_user():\n     user_id = request.args.get('id')\n     return get_user_safe(user_id)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"db.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"db.py\").write_text(\"\"\"\n import sqlite3\n \n def get_user_safe(user_id):\n     conn = sqlite3.connect('test.db')\n     cursor = conn.cursor()\n     # Safe: parameterized query\n     cursor.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,))\n     return cursor.fetchone()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def command_injection_project(temp_project):\n     \"\"\"Create a project with command injection vulnerability.\"\"\"\n-    (temp_project / \"api.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"api.py\").write_text(\"\"\"\n from flask import request\n from utils import run_command\n \n def process():\n     filename = request.args.get('file')\n     return run_command(filename)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"utils.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"utils.py\").write_text(\"\"\"\n import os\n \n def run_command(filename):\n     os.system(f\"cat {filename}\")\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def multi_hop_project(temp_project):\n     \"\"\"Create a project with multi-hop taint flow.\"\"\"\n-    (temp_project / \"app.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"app.py\").write_text(\"\"\"\n from flask import request\n from services import process_data\n \n def handler():\n     data = request.args.get('data')\n     return process_data(data)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"services.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"services.py\").write_text(\"\"\"\n from utils import transform\n \n def process_data(data):\n     transformed = transform(data)\n     return transformed\n-\"\"\"\n-    )\n-\n-    (temp_project / \"utils.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"utils.py\").write_text(\"\"\"\n import os\n \n def transform(data):\n     # This is dangerous - command injection\n     os.system(f\"echo {data}\")\n     return data.upper()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n @pytest.fixture\n def path_traversal_project(temp_project):\n     \"\"\"Create a project with path traversal vulnerability.\"\"\"\n-    (temp_project / \"views.py\").write_text(\n-        \"\"\"\n+    (temp_project / \"views.py\").write_text(\"\"\"\n from flask import request\n from files import read_file\n \n def download():\n     path = request.args.get('path')\n     return read_file(path)\n-\"\"\"\n-    )\n-\n-    (temp_project / \"files.py\").write_text(\n-        \"\"\"\n+\"\"\")\n+\n+    (temp_project / \"files.py\").write_text(\"\"\"\n def read_file(path):\n     with open(path, 'r') as f:\n         return f.read()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return temp_project\n \n \n # =============================================================================\n@@ -422,19 +400,17 @@\n         # Should still analyze good.py\n         assert result.modules_analyzed >= 1\n \n     def test_no_dangerous_code(self, temp_project):\n         \"\"\"Test project with no dangerous patterns.\"\"\"\n-        (temp_project / \"safe.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"safe.py\").write_text(\"\"\"\n def add(a, b):\n     return a + b\n \n def multiply(x, y):\n     return x * y\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n@@ -532,41 +508,35 @@\n     \"\"\"Integration tests with realistic scenarios.\"\"\"\n \n     def test_flask_app_analysis(self, temp_project):\n         \"\"\"Test analysis of Flask-like application.\"\"\"\n         # Create a mini Flask app structure\n-        (temp_project / \"app.py\").write_text(\n-            \"\"\"\n+        (temp_project / \"app.py\").write_text(\"\"\"\n from flask import Flask, request\n from views import handle_request\n \n app = Flask(__name__)\n \n @app.route('/api')\n def api():\n     return handle_request()\n-\"\"\"\n-        )\n-\n-        (temp_project / \"views.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"views.py\").write_text(\"\"\"\n from flask import request\n from models import get_data\n \n def handle_request():\n     query = request.args.get('q')\n     return get_data(query)\n-\"\"\"\n-        )\n-\n-        (temp_project / \"models.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"models.py\").write_text(\"\"\"\n def get_data(query):\n     # Potentially dangerous if query is not sanitized\n     return f\"Results for: {query}\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n@@ -577,38 +547,32 @@\n         # Create complex import structure\n         pkg = temp_project / \"pkg\"\n         pkg.mkdir()\n         (pkg / \"__init__.py\").write_text(\"\")\n \n-        (pkg / \"base.py\").write_text(\n-            \"\"\"\n+        (pkg / \"base.py\").write_text(\"\"\"\n import os\n \n def exec_cmd(cmd):\n     os.system(cmd)\n-\"\"\"\n-        )\n-\n-        (pkg / \"service.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (pkg / \"service.py\").write_text(\"\"\"\n from .base import exec_cmd\n \n def process(data):\n     exec_cmd(f\"echo {data}\")\n-\"\"\"\n-        )\n-\n-        (temp_project / \"main.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (temp_project / \"main.py\").write_text(\"\"\"\n from flask import request\n from pkg.service import process\n \n def handler():\n     data = request.args.get('input')\n     process(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         tracker = CrossFileTaintTracker(temp_project)\n         result = tracker.analyze()\n \n         assert result.success\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/test_oracle_pipeline.py\t2026-02-01 15:55:15.103999+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/test_oracle_pipeline.py\t2026-02-01 23:23:13.112541+00:00\n@@ -99,17 +99,15 @@\n     def test_generate_constraint_spec_basic(self):\n         \"\"\"Should generate constraint spec for a valid Python file.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create a simple Python file\n             test_file = Path(tmpdir) / \"test.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def hello(name):\n     '''Say hello.'''\n     return f\"Hello, {name}!\"\n-\"\"\"\n-            )\n+\"\"\")\n \n             pipeline = OraclePipeline(tmpdir, tier=\"community\")\n             spec = pipeline.generate_constraint_spec(\n                 file_path=str(test_file),\n                 instruction=\"Add error handling for empty name\",\n@@ -163,17 +161,15 @@\n     def test_pipeline_executes_in_time_budget(self):\n         \"\"\"Pipeline should complete in <200ms.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create a simple Python file\n             test_file = Path(tmpdir) / \"test.py\"\n-            test_file.write_text(\n-                \"\"\"\n+            test_file.write_text(\"\"\"\n def add(a, b):\n     '''Add two numbers.'''\n     return a + b\n-\"\"\"\n-            )\n+\"\"\")\n \n             pipeline = OraclePipeline(tmpdir, tier=\"community\")\n \n             started = time.perf_counter()\n             spec = pipeline.generate_constraint_spec(\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_call_graph_enhanced.py\t2026-02-01 15:55:15.013737+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_call_graph_enhanced.py\t2026-02-01 23:23:13.199510+00:00\n@@ -110,12 +110,11 @@\n     @pytest.fixture\n     def simple_project(self, tmp_path):\n         \"\"\"Create a simple project structure for testing.\"\"\"\n         # main.py\n         main_py = tmp_path / \"main.py\"\n-        main_py.write_text(\n-            \"\"\"\n+        main_py.write_text(\"\"\"\n def main():\n     helper()\n     print(\"done\")\n \n def helper():\n@@ -124,60 +123,53 @@\n def utility():\n     pass\n \n if __name__ == \"__main__\":\n     main()\n-\"\"\"\n-        )\n+\"\"\")\n \n         return tmp_path\n \n     @pytest.fixture\n     def multi_file_project(self, tmp_path):\n         \"\"\"Create a multi-file project structure.\"\"\"\n         # main.py\n         main_py = tmp_path / \"main.py\"\n-        main_py.write_text(\n-            \"\"\"\n+        main_py.write_text(\"\"\"\n from utils import process\n \n def main():\n     result = process()\n     return result\n \n if __name__ == \"__main__\":\n     main()\n-\"\"\"\n-        )\n+\"\"\")\n \n         # utils.py\n         utils_py = tmp_path / \"utils.py\"\n-        utils_py.write_text(\n-            \"\"\"\n+        utils_py.write_text(\"\"\"\n from helpers import validate\n \n def process():\n     if validate():\n         return compute()\n     return None\n \n def compute():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n \n         # helpers.py\n         helpers_py = tmp_path / \"helpers.py\"\n-        helpers_py.write_text(\n-            \"\"\"\n+        helpers_py.write_text(\"\"\"\n def validate():\n     return True\n \n def format_output(data):\n     return str(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         return tmp_path\n \n     def test_build_with_details_returns_result(self, simple_project):\n         \"\"\"Test that build_with_details returns a CallGraphResult.\"\"\"\n@@ -268,12 +260,11 @@\n \n     @pytest.fixture\n     def sample_project(self, tmp_path):\n         \"\"\"Create a sample project for Mermaid tests.\"\"\"\n         main_py = tmp_path / \"main.py\"\n-        main_py.write_text(\n-            \"\"\"\n+        main_py.write_text(\"\"\"\n def main():\n     foo()\n     bar()\n \n def foo():\n@@ -282,12 +273,11 @@\n def bar():\n     baz()\n \n def baz():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         return tmp_path\n \n     def test_mermaid_starts_with_graph(self, sample_project):\n         \"\"\"Test Mermaid output starts with graph directive.\"\"\"\n         builder = CallGraphBuilder(sample_project)\n@@ -540,18 +530,16 @@\n         # Should detect at least 2 cycles\n         assert len(cycles) >= 1  # At least one detected\n \n     def test_external_imports_ignored(self, tmp_path):\n         \"\"\"Test that external library imports don't cause false positives.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n import os\n import sys\n from pathlib import Path\n import json\n-\"\"\"\n-        )\n+\"\"\")\n \n         builder = CallGraphBuilder(tmp_path)\n         cycles = builder.detect_circular_imports()\n \n         assert cycles == []\n@@ -684,53 +672,45 @@\n     def test_flask_app_structure(self, tmp_path):\n         \"\"\"Test with Flask-like application structure.\"\"\"\n         # app/__init__.py\n         app_dir = tmp_path / \"app\"\n         app_dir.mkdir()\n-        (app_dir / \"__init__.py\").write_text(\n-            \"\"\"\n+        (app_dir / \"__init__.py\").write_text(\"\"\"\n from flask import Flask\n from app.routes import register_routes\n \n def create_app():\n     app = Flask(__name__)\n     register_routes(app)\n     return app\n-\"\"\"\n-        )\n+\"\"\")\n \n         # app/routes.py\n-        (app_dir / \"routes.py\").write_text(\n-            \"\"\"\n+        (app_dir / \"routes.py\").write_text(\"\"\"\n from app.handlers import handle_index, handle_api\n \n def register_routes(app):\n     app.route(\"/\")(handle_index)\n     app.route(\"/api\")(handle_api)\n-\"\"\"\n-        )\n+\"\"\")\n \n         # app/handlers.py\n-        (app_dir / \"handlers.py\").write_text(\n-            \"\"\"\n+        (app_dir / \"handlers.py\").write_text(\"\"\"\n from app.services import get_data\n \n def handle_index():\n     return \"Hello\"\n \n def handle_api():\n     return get_data()\n-\"\"\"\n-        )\n+\"\"\")\n \n         # app/services.py\n-        (app_dir / \"services.py\").write_text(\n-            \"\"\"\n+        (app_dir / \"services.py\").write_text(\"\"\"\n def get_data():\n     return {\"status\": \"ok\"}\n-\"\"\"\n-        )\n+\"\"\")\n \n         builder = CallGraphBuilder(tmp_path)\n         result = builder.build_with_details()\n \n         assert len(result.nodes) >= 4  # At least several functions\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_python_breadth.py\t2026-02-01 15:55:15.121694+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_python_breadth.py\t2026-02-01 23:23:13.197347+00:00\n@@ -26,19 +26,17 @@\n     return tmp_path\n \n \n def test_async_function_rename_same_file(project: Path):\n     src = project / \"mod.py\"\n-    src.write_text(\n-        \"\"\"\n+    src.write_text(\"\"\"\n import asyncio\n \n async def old_func():\n     await asyncio.sleep(0)\n     return 1\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     res = p.rename_symbol(\"function\", \"old_func\", \"new_func\")\n     assert res.success\n     p.save(backup=False)\n@@ -48,22 +46,20 @@\n     assert \"old_func\" not in text\n \n \n def test_staticmethod_and_classmethod_same_file(project: Path):\n     src = project / \"cm.py\"\n-    src.write_text(\n-        \"\"\"\n+    src.write_text(\"\"\"\n class C:\n     @staticmethod\n     def old_static(x):\n         return x\n \n     @classmethod\n     def old_class(cls, y):\n         return y\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     assert p.rename_symbol(\"method\", \"C.old_static\", \"new_static\").success\n     p.save(backup=False)\n \n@@ -76,20 +72,18 @@\n     assert \"def new_class\" in t and \"def old_class\" not in t\n \n \n def test_decorated_function_same_file(project: Path):\n     src = project / \"dec.py\"\n-    src.write_text(\n-        \"\"\"\n+    src.write_text(\"\"\"\n def dec(fn):\n     return fn\n \n @dec\n def old_name():\n     return 1\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     res = p.rename_symbol(\"function\", \"old_name\", \"new_name\")\n     assert res.success\n     p.save(backup=False)\n@@ -98,12 +92,11 @@\n     assert \"def new_name\" in t and \"def old_name\" not in t\n \n \n def test_property_getter_setter_same_file(project: Path):\n     src = project / \"prop.py\"\n-    src.write_text(\n-        \"\"\"\n+    src.write_text(\"\"\"\n class P:\n     def __init__(self):\n         self._v = 0\n \n     @property\n@@ -111,12 +104,11 @@\n         return self._v\n \n     @old_prop.setter\n     def old_prop(self, v):\n         self._v = v\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     # Rename property accessor name\n     res = p.rename_symbol(\"method\", \"P.old_prop\", \"new_prop\")\n     assert res.success\n@@ -149,23 +141,21 @@\n         \"from .a import old_func\\n__all__ = ['old_func']\\n\"\n     )\n     a = pkg / \"a.py\"\n     a.write_text(\"def old_func():\\n    return 1\\n\")\n     b = project / \"b.py\"\n-    b.write_text(\n-        \"\"\"\n+    b.write_text(\"\"\"\n from pkg import old_func as alias\n from pkg import old_func\n import pkg.a as mod\n \n def use():\n     x = alias()\n     y = old_func()\n     z = mod.old_func()\n     return x + y + z\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     res = rename_references_across_project(\n         project_root=project,\n         target_file=a,\n         target_type=\"function\",\n@@ -189,19 +179,17 @@\n \n def test_getattr_usage_not_rewritten(project: Path):\n     a = project / \"a.py\"\n     a.write_text(\"def old_func():\\n    return 1\\n\")\n     b = project / \"b.py\"\n-    b.write_text(\n-        \"\"\"\n+    b.write_text(\"\"\"\n import a\n \n def use():\n     fn = getattr(a, \"old_func\")\n     return fn()\n-\"\"\".strip()\n-    )\n+\"\"\".strip())\n \n     res = rename_references_across_project(\n         project_root=project,\n         target_file=a,\n         target_type=\"function\",\n@@ -221,20 +209,16 @@\n \n \n # [20260108_TEST] Nested function rename should update definition and calls\n def test_nested_function_rename_same_file(project: Path):\n     src = project / \"nested.py\"\n-    src.write_text(\n-        (\n-            \"\"\"\n+    src.write_text((\"\"\"\n def outer():\n     def old_inner(x):\n         return x + 1\n     return old_inner(1)\n-\"\"\"\n-        ).strip()\n-    )\n+\"\"\").strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     res = p.rename_symbol(\"function\", \"old_inner\", \"new_inner\")\n     assert res.success\n     p.save(backup=False)\n@@ -259,22 +243,18 @@\n \n \n # [20260108_TEST] Comments and docstrings should not be rewritten\n def test_comments_and_docstrings_not_rewritten(project: Path):\n     src = project / \"docs.py\"\n-    src.write_text(\n-        (\n-            '''\"\"\"\n+    src.write_text(('''\"\"\"\n old_name docstring mention\n \"\"\"\n \n def old_name():\n     # old_name used in comment\n     return 1\n-'''\n-        ).strip()\n-    )\n+''').strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     res = p.rename_symbol(\"function\", \"old_name\", \"new_name\")\n     assert res.success\n     p.save(backup=False)\n@@ -287,13 +267,11 @@\n \n \n # [20260108_TEST] Multi-line definition and call formatting supported\n def test_multiline_definition_and_call_rename(project: Path):\n     src = project / \"multiline.py\"\n-    src.write_text(\n-        (\n-            \"\"\"\n+    src.write_text((\"\"\"\n def old_name(\n     a,\n     b,\n     c,\n ):\n@@ -302,13 +280,11 @@\n result = old_name(\n     1,\n     2,\n     3,\n )\n-\"\"\"\n-        ).strip()\n-    )\n+\"\"\").strip())\n \n     p = UnifiedPatcher.from_file(str(src))\n     res = p.rename_symbol(\"function\", \"old_name\", \"new_name\")\n     assert res.success\n     p.save(backup=False)\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_rename.py\t2026-02-01 15:55:15.135584+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_rename.py\t2026-02-01 23:23:13.248331+00:00\n@@ -8,23 +8,21 @@\n class TestRename(unittest.TestCase):\n     def setUp(self):\n         self.test_file = tempfile.NamedTemporaryFile(\n             mode=\"w+\", delete=False, suffix=\".py\"\n         )\n-        self.test_file.write(\n-            \"\"\"\n+        self.test_file.write(\"\"\"\n def old_func():\n     pass\n \n class OldClass:\n     def old_method(self):\n         pass\n \n async def old_async_func():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         self.test_file.close()\n         self.patcher = SurgicalPatcher.from_file(self.test_file.name)\n \n     def tearDown(self):\n         os.unlink(self.test_file.name)\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_advanced_vulnerabilities.py\t2026-02-01 15:55:15.156656+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_advanced_vulnerabilities.py\t2026-02-01 23:23:13.378548+00:00\n@@ -43,23 +43,21 @@\n     and checking for CSRFProtect usage. Current taint analysis focuses on\n     data flow vulnerabilities. This is planned for v1.1.\n     \"\"\"\n     _use_pro_license(monkeypatch)\n \n-    code = textwrap.dedent(\n-        \"\"\"\n+    code = textwrap.dedent(\"\"\"\n         from flask import request, Flask\n         app = Flask(__name__)\n \n         @app.route('/transfer', methods=['POST'])\n         def transfer_money():\n             amount = request.form['amount']  # No CSRF token check\n             account = request.form['account']\n             transfer(amount, account)\n             return 'Success'\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     from code_scalpel.mcp.server import security_scan\n \n     result = await security_scan(code=code)\n \n@@ -78,21 +76,19 @@\n \n async def test_ssrf_detection_requests(monkeypatch: pytest.MonkeyPatch):\n     \"\"\"Detect SSRF via requests library.\"\"\"\n     _use_pro_license(monkeypatch)\n \n-    code = textwrap.dedent(\n-        \"\"\"\n+    code = textwrap.dedent(\"\"\"\n         import requests\n         from flask import request\n \n         def fetch_url():\n             user_url = request.args.get('url')\n             response = requests.get(user_url)  # SSRF - no URL validation\n             return response.text\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     from code_scalpel.mcp.server import security_scan\n \n     result = await security_scan(code=code)\n \n@@ -118,20 +114,18 @@\n     Current taint analysis doesn't inspect argument values.\n     This is planned for v1.1 with enhanced pattern matching.\n     \"\"\"\n     _use_pro_license(monkeypatch)\n \n-    code = textwrap.dedent(\n-        \"\"\"\n+    code = textwrap.dedent(\"\"\"\n         import jwt\n \n         def validate_token(token):\n             # Insecure: verify=False bypasses signature check\n             payload = jwt.decode(token, verify=False)\n             return payload\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     from code_scalpel.mcp.server import security_scan\n \n     result = await security_scan(code=code)\n \n@@ -162,20 +156,18 @@\n     tracks data flow but doesn't inspect argument literal values.\n     This is planned for v1.1 with enhanced pattern matching.\n     \"\"\"\n     _use_pro_license(monkeypatch)\n \n-    code = textwrap.dedent(\n-        \"\"\"\n+    code = textwrap.dedent(\"\"\"\n         import jwt\n \n         def create_admin_token():\n             # Critical vulnerability: 'none' algorithm allows unsigned tokens\n             token = jwt.encode({'user': 'admin'}, key='', algorithm='none')\n             return token\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     from code_scalpel.mcp.server import security_scan\n \n     result = await security_scan(code=code)\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_multilanguage_support.py\t2026-02-01 15:55:15.164256+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_multilanguage_support.py\t2026-02-01 23:23:13.430212+00:00\n@@ -7,23 +7,18 @@\n \n pytestmark = pytest.mark.asyncio\n \n \n async def test_javascript_dom_xss_via_file_path(tmp_path):\n-    js_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    js_code = textwrap.dedent(\"\"\"\n         function render(userInput) {\n           document.getElementById('t').innerHTML = userInput;\n           document.write(userInput);\n           const el = document.getElementById('c');\n           el.insertAdjacentHTML('beforeend', userInput);\n         }\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     js_file = tmp_path / \"sample.js\"\n     js_file.write_text(js_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n@@ -37,23 +32,18 @@\n \n \n # [20260107_TEST] TypeScript language support tests\n async def test_typescript_dom_xss(tmp_path):\n     \"\"\"TypeScript innerHTML XSS detection.\"\"\"\n-    ts_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    ts_code = textwrap.dedent(\"\"\"\n         function renderUser(name: string): void {\n           const userDiv = document.getElementById('user');\n           if (userDiv) {\n             userDiv.innerHTML = name; // XSS vulnerability\n           }\n         }\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     ts_file = tmp_path / \"app.ts\"\n     ts_file.write_text(ts_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n@@ -69,21 +59,16 @@\n @pytest.mark.skip(\n     reason=\"TypeScript SQL injection pattern not yet supported - requires TS-specific template literal parser\"\n )\n async def test_typescript_sql_injection(tmp_path):\n     \"\"\"TypeScript SQL injection via template strings.\"\"\"\n-    ts_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    ts_code = textwrap.dedent(\"\"\"\n         async function getUser(id: string): Promise<any> {\n           const query = `SELECT * FROM users WHERE id=${id}`;  // SQL injection\n           return await database.query(query);\n         }\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     ts_file = tmp_path / \"db.ts\"\n     ts_file.write_text(ts_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n@@ -99,21 +84,16 @@\n @pytest.mark.skip(\n     reason=\"TypeScript command injection via template literals not yet supported - requires TS parser enhancement\"\n )\n async def test_typescript_command_injection(tmp_path):\n     \"\"\"TypeScript command injection via child_process.\"\"\"\n-    ts_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    ts_code = textwrap.dedent(\"\"\"\n         import { exec } from 'child_process';\n         function runCommand(userCmd: string): void {\n           exec(`ls -la ${userCmd}`);  // Command injection\n         }\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     ts_file = tmp_path / \"cmd.ts\"\n     ts_file.write_text(ts_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n@@ -127,22 +107,17 @@\n \n \n # [20260107_TEST] Java language support tests\n async def test_java_sql_injection_spring(tmp_path):\n     \"\"\"Java Spring SQL injection detection.\"\"\"\n-    java_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    java_code = textwrap.dedent(\"\"\"\n         @GetMapping(\"/user\")\n         public User getUser(@RequestParam String id) {\n           String query = \"SELECT * FROM users WHERE id=\" + id;  // SQL injection\n           return jdbcTemplate.queryForObject(query, User.class);\n         }\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     java_file = tmp_path / \"UserController.java\"\n     java_file.write_text(java_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n@@ -158,21 +133,16 @@\n @pytest.mark.skip(\n     reason=\"Java JNDI injection patterns not yet implemented - requires Java-specific semantic analysis\"\n )\n async def test_java_jndi_injection(tmp_path):\n     \"\"\"Java JNDI injection detection (Log4Shell variant).\"\"\"\n-    java_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    java_code = textwrap.dedent(\"\"\"\n         public void logUserInput(String input) {\n           Context context = new InitialContext();\n           context.lookup(input);  // JNDI injection vulnerability\n         }\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     java_file = tmp_path / \"Logger.java\"\n     java_file.write_text(java_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n@@ -186,21 +156,16 @@\n @pytest.mark.skip(\n     reason=\"JSP XSS patterns not yet supported - requires JSP/servlet parser\"\n )\n async def test_java_xss_jsp(tmp_path):\n     \"\"\"Java JSP XSS detection.\"\"\"\n-    java_code = (\n-        textwrap.dedent(\n-            \"\"\"\n+    java_code = textwrap.dedent(\"\"\"\n         <%\n         String userName = request.getParameter(\"name\");\n         out.println(\"<div>\" + userName + \"</div>\");  // XSS\n         %>\n-        \"\"\"\n-        ).strip()\n-        + \"\\n\"\n-    )\n+        \"\"\").strip() + \"\\n\"\n     jsp_file = tmp_path / \"user.jsp\"\n     jsp_file.write_text(java_code, encoding=\"utf-8\")\n \n     from code_scalpel.mcp.server import security_scan\n \n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_pro_features_extra.py\t2026-02-01 15:55:15.169787+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_pro_features_extra.py\t2026-02-01 23:23:13.472212+00:00\n@@ -61,18 +61,16 @@\n     pytest.skip(\"Valid Pro license not found; generate a signed test license\")\n \n \n async def test_nosql_injection_detection(monkeypatch: pytest.MonkeyPatch):\n     _use_pro_license(monkeypatch)\n-    code = textwrap.dedent(\n-        \"\"\"\n+    code = textwrap.dedent(\"\"\"\n         from flask import request\n         def find_docs(collection):\n             qv = request.args.get('q')\n             return collection.find(qv)\n-        \"\"\"\n-    )\n+        \"\"\")\n     from code_scalpel.mcp.server import security_scan\n \n     result = await security_scan(code=code)\n     assert result.success is True\n     assert any(\n@@ -129,17 +127,15 @@\n \n     # Use unique code to avoid cache hits from previous test runs\n     import uuid\n \n     unique_id = uuid.uuid4().hex[:8]\n-    code = textwrap.dedent(\n-        f\"\"\"\n+    code = textwrap.dedent(f\"\"\"\n         import subprocess\n         def run_cmd_{unique_id}(user_input):\n             subprocess.run(f\"ls {{user_input}}\", shell=True)  # CWE-78\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     # Import fresh to pick up license changes\n     import sys\n \n     if \"code_scalpel.mcp.server\" in sys.modules:\n@@ -174,17 +170,15 @@\n \n     # Use unique code to avoid cache hits\n     import uuid\n \n     unique_id = uuid.uuid4().hex[:8]\n-    code = textwrap.dedent(\n-        f\"\"\"\n+    code = textwrap.dedent(f\"\"\"\n         import subprocess\n         def run_cmd_{unique_id}(user_input):\n             subprocess.run(f\"ls {{user_input}}\", shell=True)\n-        \"\"\"\n-    )\n+        \"\"\")\n \n     # Import fresh to pick up license changes\n     import sys\n \n     if \"code_scalpel.mcp.server\" in sys.modules:\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_extract_code_tiers.py\t2026-02-01 15:55:15.203549+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_extract_code_tiers.py\t2026-02-01 23:23:13.499501+00:00\n@@ -25,38 +25,32 @@\n \n     # Allow operating on tmp_path.\n     monkeypatch.setattr(server, \"ALLOWED_ROOTS\", [tmp_path.resolve()], raising=False)\n \n     # b.py\n-    (tmp_path / \"b.py\").write_text(\n-        \"\"\"\\\n+    (tmp_path / \"b.py\").write_text(\"\"\"\\\n class B:\n     pass\n-\"\"\"\n-    )\n+\"\"\")\n \n     # a.py imports B and defines A\n-    (tmp_path / \"a.py\").write_text(\n-        \"\"\"\\\n+    (tmp_path / \"a.py\").write_text(\"\"\"\\\n from b import B\n \n class A:\n     def __init__(self):\n         self.b = B()\n-\"\"\"\n-    )\n+\"\"\")\n \n     # utils.py imports A and uses it\n-    (tmp_path / \"utils.py\").write_text(\n-        \"\"\"\\\n+    (tmp_path / \"utils.py\").write_text(\"\"\"\\\n from a import A\n \n def f():\n     a = A()\n     return a\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Simulate Pro tier via env; _get_current_tier honors this under pytest.\n     monkeypatch.setenv(\"CODE_SCALPEL_TIER\", \"pro\")\n \n     # Ask for depth=2; Pro tier should clamp to 1.\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_rename_tiers.py\t2026-02-01 15:55:15.148115+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_rename_tiers.py\t2026-02-01 23:23:13.637111+00:00\n@@ -98,18 +98,16 @@\n         main_py = temp_project / \"main.py\"\n \n         # Create many files to exceed limit\n         for i in range(10):\n             extra = temp_project / f\"extra_{i}.py\"\n-            extra.write_text(\n-                f\"\"\"\n+            extra.write_text(f\"\"\"\n from main import old_function\n \n def use_{i}():\n     return old_function()\n-\"\"\".strip()\n-            )\n+\"\"\".strip())\n \n         result = rename_references_across_project(\n             project_root=temp_project,\n             target_file=main_py,\n             target_type=\"function\",\n@@ -412,23 +410,21 @@\n     def test_shadowed_parameter_not_renamed(self, temp_project):\n         from code_scalpel.surgery.surgical_patcher import UnifiedPatcher\n \n         main_py = temp_project / \"main.py\"\n         shadowed_py = temp_project / \"shadowed.py\"\n-        shadowed_py.write_text(\n-            \"\"\"\n+        shadowed_py.write_text(\"\"\"\n from main import old_function\n \n def outer():\n     value = old_function()\n \n     def inner(old_function):\n         return old_function()\n \n     return value + inner(1)\n-\"\"\".strip()\n-        )\n+\"\"\".strip())\n \n         patcher = UnifiedPatcher.from_file(str(main_py))\n         assert patcher.rename_symbol(\"function\", \"old_function\", \"new_function\").success\n         patcher.save(backup=False)\n \n@@ -454,21 +450,19 @@\n     def test_global_scope_still_renamed(self, temp_project):\n         from code_scalpel.surgery.surgical_patcher import UnifiedPatcher\n \n         main_py = temp_project / \"main.py\"\n         scoped_py = temp_project / \"scoped.py\"\n-        scoped_py.write_text(\n-            \"\"\"\n+        scoped_py.write_text(\"\"\"\n from main import old_function\n \n value = old_function()\n \n def use_global():\n     global old_function\n     return old_function()\n-\"\"\".strip()\n-        )\n+\"\"\".strip())\n \n         patcher = UnifiedPatcher.from_file(str(main_py))\n         assert patcher.rename_symbol(\"function\", \"old_function\", \"new_function\").success\n         patcher.save(backup=False)\n \n@@ -495,28 +489,24 @@\n \n         main_py = temp_project / \"main.py\"\n         circle_a = temp_project / \"circle_a.py\"\n         circle_b = temp_project / \"circle_b.py\"\n \n-        circle_a.write_text(\n-            \"\"\"\n+        circle_a.write_text(\"\"\"\n from main import old_function\n import circle_b\n \n def call_a():\n     return old_function() + circle_b.call_b()\n-\"\"\".strip()\n-        )\n-        circle_b.write_text(\n-            \"\"\"\n+\"\"\".strip())\n+        circle_b.write_text(\"\"\"\n from main import old_function\n import circle_a\n \n def call_b():\n     return old_function() + circle_a.call_a()\n-\"\"\".strip()\n-        )\n+\"\"\".strip())\n \n         patcher = UnifiedPatcher.from_file(str(main_py))\n         assert patcher.rename_symbol(\"function\", \"old_function\", \"new_function\").success\n         patcher.save(backup=False)\n \n@@ -581,18 +571,16 @@\n         main_py = temp_project / \"main.py\"\n \n         extra_files = []\n         for i in range(12):\n             extra = temp_project / f\"enterprise_extra_{i}.py\"\n-            extra.write_text(\n-                f\"\"\"\n+            extra.write_text(f\"\"\"\n from main import old_function\n \n def use_{i}():\n     return old_function()\n-\"\"\".strip()\n-            )\n+\"\"\".strip())\n             extra_files.append(extra)\n \n         patcher = UnifiedPatcher.from_file(str(main_py))\n         assert patcher.rename_symbol(\"function\", \"old_function\", \"new_function\").success\n         patcher.save(backup=False)\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_analyze_code_tiers.py\t2026-02-01 15:55:15.192008+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_analyze_code_tiers.py\t2026-02-01 23:23:13.640676+00:00\n@@ -8,53 +8,45 @@\n \n # [20260121_TEST] Tier validation for analyze_code\n \n \n def _python_sample():\n-    return textwrap.dedent(\n-        \"\"\"\n+    return textwrap.dedent(\"\"\"\n         import math\n \n         def foo(x):\n             return x + 1\n \n         class Bar:\n             def method(self, y):\n                 return y * 2\n-        \"\"\"\n-    )\n+        \"\"\")\n \n \n def _javascript_sample():\n-    return textwrap.dedent(\n-        \"\"\"\n+    return textwrap.dedent(\"\"\"\n         import util from \"./util.js\";\n         function foo(x) { return x + 1; }\n         class Bar { method(y) { return y * 2; } }\n-        \"\"\"\n-    )\n+        \"\"\")\n \n \n def _typescript_sample():\n-    return textwrap.dedent(\n-        \"\"\"\n+    return textwrap.dedent(\"\"\"\n         import { Util } from \"./util\";\n         export function foo(x: number): number { return x + 1; }\n         export class Bar { method(y: number): number { return y * 2; } }\n-        \"\"\"\n-    )\n+        \"\"\")\n \n \n def _java_sample():\n-    return textwrap.dedent(\n-        \"\"\"\n+    return textwrap.dedent(\"\"\"\n         import java.util.*;\n         public class Foo {\n             public int add(int x) { return x + 1; }\n         }\n-        \"\"\"\n-    )\n+        \"\"\")\n \n \n class TestAnalyzeCodeCommunityTier:\n     @pytest.fixture(autouse=True)\n     def _tier(self, monkeypatch):\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_cross_file_dependencies_tiers.py\t2026-02-01 15:55:15.221424+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_cross_file_dependencies_tiers.py\t2026-02-01 23:23:13.774933+00:00\n@@ -13,84 +13,70 @@\n \n @pytest.fixture\n def temp_project_with_dependencies(tmp_path):\n     \"\"\"Create nested dependency chain for depth testing.\"\"\"\n     # Create module_f.py (depth 6 - deepest)\n-    (tmp_path / \"module_f.py\").write_text(\n-        '''\n+    (tmp_path / \"module_f.py\").write_text('''\n def helper_f():\n     \"\"\"Deepest dependency (depth 6).\"\"\"\n     return \"f\"\n-'''\n-    )\n+''')\n \n     # Create module_e.py (depth 5) - imports module_f\n-    (tmp_path / \"module_e.py\").write_text(\n-        '''\n+    (tmp_path / \"module_e.py\").write_text('''\n from module_f import helper_f\n \n def helper_e():\n     \"\"\"Depth 5 dependency.\"\"\"\n     return helper_f()\n-'''\n-    )\n+''')\n \n     # Create module_d.py (depth 4) - imports module_e\n-    (tmp_path / \"module_d.py\").write_text(\n-        '''\n+    (tmp_path / \"module_d.py\").write_text('''\n from module_e import helper_e\n \n def helper_d():\n     \"\"\"Depth 4 dependency.\"\"\"\n     return helper_e()\n-'''\n-    )\n+''')\n \n     # Create module_c.py (depth 3) - imports module_d\n-    (tmp_path / \"module_c.py\").write_text(\n-        '''\n+    (tmp_path / \"module_c.py\").write_text('''\n from module_d import helper_d\n \n def helper_c():\n     \"\"\"Depth 3 dependency.\"\"\"\n     return helper_d()\n-'''\n-    )\n+''')\n \n     # Create module_b.py (depth 2) - imports module_c\n-    (tmp_path / \"module_b.py\").write_text(\n-        '''\n+    (tmp_path / \"module_b.py\").write_text('''\n from module_c import helper_c\n \n def helper_b():\n     \"\"\"Depth 2 dependency.\"\"\"\n     return helper_c()\n-'''\n-    )\n+''')\n \n     # Create module_a.py (depth 1) - imports module_b\n-    (tmp_path / \"module_a.py\").write_text(\n-        '''\n+    (tmp_path / \"module_a.py\").write_text('''\n from module_b import helper_b\n \n def calculate(amount):\n     \"\"\"Depth 1 dependency - direct import.\"\"\"\n     return 100 + amount + len(str(helper_b()))\n-'''\n-    )\n+''')\n \n     # Create main.py (depth 0 - target)\n-    (tmp_path / \"main.py\").write_text(\n-        '''\n+    (tmp_path / \"main.py\").write_text('''\n from module_a import calculate\n \n def process_order(order_id, amount):\n     \"\"\"Main function that depends on module_a.calculate.\"\"\"\n     total = calculate(amount)\n     return {\"order_id\": order_id, \"total\": total}\n-'''\n-    )\n+''')\n \n     return tmp_path\n \n \n class TestGetCrossFileDependenciesCommunityTier:\n@@ -390,33 +376,27 @@\n                     assert abs(confidence - expected_confidence) < 0.01\n \n     def test_circular_dependency_detection(self, tmp_path, enterprise_tier):\n         \"\"\"Verify circular dependency detection is active in enterprise tier.\"\"\"\n         # Create circular dependencies\n-        (tmp_path / \"module_x.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"module_x.py\").write_text(\"\"\"\n from module_y import func_y\n def func_x():\n     return func_y()\n-\"\"\"\n-        )\n-\n-        (tmp_path / \"module_y.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (tmp_path / \"module_y.py\").write_text(\"\"\"\n from module_x import func_x\n def func_y():\n     return func_x()\n-\"\"\"\n-        )\n-\n-        (tmp_path / \"main.py\").write_text(\n-            \"\"\"\n+\"\"\")\n+\n+        (tmp_path / \"main.py\").write_text(\"\"\"\n from module_x import func_x\n def start():\n     return func_x()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = _get_cross_file_dependencies_sync(\n             target_file=\"main.py\",\n             target_symbol=\"start\",\n             project_root=str(tmp_path),\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_file_context_tiers.py\t2026-02-01 15:55:15.229126+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_file_context_tiers.py\t2026-02-01 23:23:13.785716+00:00\n@@ -153,12 +153,11 @@\n         \"\"\"Pro tier includes imports and docstrings in analysis.\n \n         [20260121_ASSERTION] Pro tier enables documentation_coverage\n         \"\"\"\n         test_file = tmp_path / \"module.py\"\n-        test_file.write_text(\n-            '''\"\"\"Module docstring.\"\"\"\n+        test_file.write_text('''\"\"\"Module docstring.\"\"\"\n \n import json\n from typing import Dict, List\n \n def process(data: Dict) -> List:\n@@ -169,12 +168,11 @@\n     \n     Returns:\n         Processed list\n     \"\"\"\n     return [v for v in data.values()]\n-'''\n-        )\n+''')\n \n         result = _get_file_context_sync(str(test_file), tier=\"pro\")\n \n         assert result.success is True\n         # Should have detected imports\n@@ -279,16 +277,14 @@\n     \"\"\"Test the async interface of get_file_context via server module.\n \n     [20260121_TEST] Verify async wrapper works with tier detection\n     \"\"\"\n     test_file = tmp_path / \"test.py\"\n-    test_file.write_text(\n-        \"\"\"def simple_function():\n+    test_file.write_text(\"\"\"def simple_function():\n     '''Does something simple.'''\n     return True\n-\"\"\"\n-    )\n+\"\"\")\n \n     result = await server.get_file_context(str(test_file))\n \n     assert result.success is True\n     assert result.tier_applied == \"community\"\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_cross_file_security_scan_tiers.py\t2026-02-01 15:55:15.198035+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_cross_file_security_scan_tiers.py\t2026-02-01 23:23:13.871472+00:00\n@@ -18,76 +18,67 @@\n @pytest.fixture\n def multi_file_sql_injection_project(tmp_path):\n     \"\"\"Create a multi-file Python project with SQL injection vulnerability.\"\"\"\n     # routes.py - Entry point with user input (source)\n     routes_py = tmp_path / \"routes.py\"\n-    routes_py.write_text(\n-        \"\"\"\n+    routes_py.write_text(\"\"\"\n from flask import Flask, request\n from db import execute_query\n \n app = Flask(__name__)\n \n @app.route(\"/user/<username>\")\n def get_user(username):\n     # User input - taint source\n     user_input = request.args.get(\"name\")\n     return execute_query(user_input)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # db.py - Database execution (sink)\n     db_py = tmp_path / \"db.py\"\n-    db_py.write_text(\n-        \"\"\"\n+    db_py.write_text(\"\"\"\n import sqlite3\n \n def execute_query(user_input):\n     # SQL sink - vulnerable to injection\n     conn = sqlite3.connect(\":memory:\")\n     cursor = conn.cursor()\n     # Direct user input in SQL (CWE-89)\n     query = f\"SELECT * FROM users WHERE name = '{user_input}'\"\n     cursor.execute(query)\n     return cursor.fetchall()\n-\"\"\"\n-    )\n+\"\"\")\n \n     # utils.py - Additional module in flow\n     utils_py = tmp_path / \"utils.py\"\n-    utils_py.write_text(\n-        \"\"\"\n+    utils_py.write_text(\"\"\"\n def process_input(data):\n     # Data processing without sanitization\n     return data.strip()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return tmp_path\n \n \n @pytest.fixture\n def multi_file_command_injection_project(tmp_path):\n     \"\"\"Create a multi-file project with command injection vulnerability.\"\"\"\n     # main.py\n     main_py = tmp_path / \"main.py\"\n-    main_py.write_text(\n-        \"\"\"\n+    main_py.write_text(\"\"\"\n import sys\n from executor import run_command\n \n def main(user_input):\n     # User input as taint source\n     result = run_command(user_input)\n     return result\n-\"\"\"\n-    )\n+\"\"\")\n \n     # executor.py\n     executor_py = tmp_path / \"executor.py\"\n-    executor_py.write_text(\n-        \"\"\"\n+    executor_py.write_text(\"\"\"\n import os\n import subprocess\n \n def run_command(cmd):\n     # Dangerous sink: os.system with user input\n@@ -95,74 +86,65 @@\n     return result\n \n def run_subprocess(args):\n     # Another dangerous sink\n     return subprocess.call(f\"ls {args}\", shell=True)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return tmp_path\n \n \n @pytest.fixture\n def multi_file_path_traversal_project(tmp_path):\n     \"\"\"Create a multi-file project with path traversal vulnerability.\"\"\"\n     # api.py\n     api_py = tmp_path / \"api.py\"\n-    api_py.write_text(\n-        \"\"\"\n+    api_py.write_text(\"\"\"\n from handler import get_file\n \n def serve_file(filename):\n     # User input - taint source\n     return get_file(filename)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # handler.py\n     handler_py = tmp_path / \"handler.py\"\n-    handler_py.write_text(\n-        \"\"\"\n+    handler_py.write_text(\"\"\"\n import os\n \n def get_file(user_path):\n     # Path traversal sink - no normalization\n     base_dir = \"/var/www/files\"\n     full_path = os.path.join(base_dir, user_path)\n     with open(full_path, \"r\") as f:\n         return f.read()\n-\"\"\"\n-    )\n+\"\"\")\n \n     return tmp_path\n \n \n @pytest.fixture\n def benign_multi_file_project(tmp_path):\n     \"\"\"Create a benign multi-file project with no vulnerabilities.\"\"\"\n     # lib.py\n     lib_py = tmp_path / \"lib.py\"\n-    lib_py.write_text(\n-        \"\"\"\n+    lib_py.write_text(\"\"\"\n def safe_add(a, b):\n     return a + b\n \n def safe_multiply(x, y):\n     return x * y\n-\"\"\"\n-    )\n+\"\"\")\n \n     # main.py\n     main_py = tmp_path / \"main.py\"\n-    main_py.write_text(\n-        \"\"\"\n+    main_py.write_text(\"\"\"\n from lib import safe_add, safe_multiply\n \n def calculate(x, y):\n     return safe_add(safe_multiply(x, 2), y)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return tmp_path\n \n \n # ============================================================================\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_scan_dependencies.py\t2026-02-01 15:55:15.070415+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_scan_dependencies.py\t2026-02-01 23:23:13.878425+00:00\n@@ -118,20 +118,18 @@\n     def test_scan_pyproject_toml(self):\n         \"\"\"Test scanning pyproject.toml.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             # Create pyproject.toml\n             pyproject = Path(tmpdir) / \"pyproject.toml\"\n-            pyproject.write_text(\n-                \"\"\"\n+            pyproject.write_text(\"\"\"\n [project]\n name = \"test-project\"\n dependencies = [\n     \"click>=8.0\",\n     \"rich>=10.0\",\n ]\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = _scan_dependencies_sync(\n                 project_root=tmpdir,\n                 scan_vulnerabilities=False,\n             )\n@@ -399,18 +397,16 @@\n \n     def test_comments_ignored(self):\n         \"\"\"Test that comments in requirements.txt are ignored.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             req_path = Path(tmpdir) / \"requirements.txt\"\n-            req_path.write_text(\n-                \"\"\"\n+            req_path.write_text(\"\"\"\n # This is a comment\n requests==2.25.0  # inline comment\n # Another comment\n flask>=2.0\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = _scan_dependencies_sync(\n                 project_root=tmpdir,\n                 scan_vulnerabilities=False,\n             )\n@@ -422,19 +418,17 @@\n \n     def test_poetry_dependencies(self):\n         \"\"\"Test parsing Poetry dependencies from pyproject.toml.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             pp_path = Path(tmpdir) / \"pyproject.toml\"\n-            pp_path.write_text(\n-                \"\"\"\n+            pp_path.write_text(\"\"\"\n [tool.poetry.dependencies]\n python = \"^3.8\"\n requests = \"^2.25.0\"\n flask = \"2.0.0\"\n pandas = \">=1.0\"\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = _scan_dependencies_sync(\n                 project_root=tmpdir,\n                 scan_vulnerabilities=False,\n             )\n@@ -449,20 +443,18 @@\n \n     def test_pep621_dependencies(self):\n         \"\"\"Test parsing PEP 621 dependencies from pyproject.toml.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             pp_path = Path(tmpdir) / \"pyproject.toml\"\n-            pp_path.write_text(\n-                \"\"\"\n+            pp_path.write_text(\"\"\"\n [project]\n name = \"test-app\"\n dependencies = [\n     \"requests>=2.25.0\",\n     \"flask>=2.0\",\n ]\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = _scan_dependencies_sync(\n                 project_root=tmpdir,\n                 scan_vulnerabilities=False,\n             )\n@@ -490,18 +482,16 @@\n     def test_malformed_requirements_txt(self):\n         \"\"\"Test graceful handling of malformed requirements.txt.\"\"\"\n         with tempfile.TemporaryDirectory() as tmpdir:\n             req_path = Path(tmpdir) / \"requirements.txt\"\n             # Create file with only comments and whitespace\n-            req_path.write_text(\n-                \"\"\"\n+            req_path.write_text(\"\"\"\n # Comment line\n    \n # Another comment\n -e git+https://github.com/example/repo.git  # Options line, should be skipped\n-\"\"\"\n-            )\n+\"\"\")\n \n             result = _scan_dependencies_sync(\n                 project_root=tmpdir,\n                 scan_vulnerabilities=False,\n             )\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_symbol_references_tiers.py\t2026-02-01 15:55:15.248697+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_symbol_references_tiers.py\t2026-02-01 23:23:13.918119+00:00\n@@ -24,62 +24,54 @@\n     \"\"\"Create a temporary project with a symbol that has multiple references.\"\"\"\n     with tempfile.TemporaryDirectory() as tmpdir:\n         root = Path(tmpdir)\n \n         # Create main.py with definition\n-        (root / \"main.py\").write_text(\n-            \"\"\"\n+        (root / \"main.py\").write_text(\"\"\"\n def process_data(x):\n     '''Process the data.'''\n     return x * 2\n \n result = process_data(5)\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create handler.py with multiple calls\n-        (root / \"handler.py\").write_text(\n-            \"\"\"\n+        (root / \"handler.py\").write_text(\"\"\"\n from main import process_data\n \n def handle_request(data):\n     '''Handle incoming request.'''\n     processed = process_data(data)\n     return {\"result\": processed}\n \n def handle_batch(items):\n     '''Handle batch.'''\n     return [process_data(item) for item in items]\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create test file with references\n-        (root / \"test_main.py\").write_text(\n-            \"\"\"\n+        (root / \"test_main.py\").write_text(\"\"\"\n import unittest\n from main import process_data\n \n class TestProcessData(unittest.TestCase):\n     def test_with_positive(self):\n         result = process_data(10)\n         self.assertEqual(result, 20)\n \n     def test_with_negative(self):\n         assert process_data(-5) == -10\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create utils.py with additional call\n-        (root / \"utils.py\").write_text(\n-            \"\"\"\n+        (root / \"utils.py\").write_text(\"\"\"\n from main import process_data\n \n def transform(value):\n     '''Transform value using process_data.'''\n     return process_data(value) + 1\n-\"\"\"\n-        )\n+\"\"\")\n \n         yield root\n \n \n class TestGetSymbolReferencesCommunityTier:\n@@ -324,17 +316,15 @@\n     def test_codeowners_support(self, enterprise_tier, temp_project_with_symbol):\n         \"\"\"Enterprise tier supports CODEOWNERS-based ownership attribution.\"\"\"\n         # Create CODEOWNERS file\n         codeowners_path = temp_project_with_symbol / \".github\"\n         codeowners_path.mkdir(exist_ok=True)\n-        (codeowners_path / \"CODEOWNERS\").write_text(\n-            \"\"\"# Code ownership\n+        (codeowners_path / \"CODEOWNERS\").write_text(\"\"\"# Code ownership\n * @default-owner\n main.py @main-owner\n handler.py @handler-owner\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = _get_symbol_references_sync(\n             \"process_data\",\n             str(temp_project_with_symbol),\n             max_files=None,\n@@ -354,16 +344,14 @@\n     def test_references_have_owners(self, enterprise_tier, temp_project_with_symbol):\n         \"\"\"Enterprise references should include owner information from CODEOWNERS.\"\"\"\n         # Create CODEOWNERS file\n         codeowners_path = temp_project_with_symbol / \".github\"\n         codeowners_path.mkdir(exist_ok=True)\n-        (codeowners_path / \"CODEOWNERS\").write_text(\n-            \"\"\"# Code ownership\n+        (codeowners_path / \"CODEOWNERS\").write_text(\"\"\"# Code ownership\n * @default-owner\n main.py @main-owner\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = _get_symbol_references_sync(\n             \"process_data\",\n             str(temp_project_with_symbol),\n             max_files=None,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_project_map_tiers.py\t2026-02-01 15:55:15.242671+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_project_map_tiers.py\t2026-02-01 23:23:14.044094+00:00\n@@ -29,32 +29,28 @@\n \n         # Create __init__.py for package\n         (src_dir / \"__init__.py\").write_text(\"# Package init\\n\")\n \n         # Create some Python files\n-        (src_dir / \"main.py\").write_text(\n-            '''\n+        (src_dir / \"main.py\").write_text('''\n \"\"\"Main module.\"\"\"\n \n def main():\n     \"\"\"Entry point.\"\"\"\n     print(\"Hello, world!\")\n \n if __name__ == \"__main__\":\n     main()\n-'''\n-        )\n-\n-        (src_dir / \"utils.py\").write_text(\n-            '''\n+''')\n+\n+        (src_dir / \"utils.py\").write_text('''\n \"\"\"Utility functions.\"\"\"\n \n def helper():\n     \"\"\"A helper function.\"\"\"\n     return 42\n-'''\n-        )\n+''')\n \n         yield tmpdir\n \n \n class TestOutputMetadataFieldsCommunity:\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_type_evaporation_scan_tiers.py\t2026-02-01 15:55:15.275776+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_type_evaporation_scan_tiers.py\t2026-02-01 23:23:14.076588+00:00\n@@ -11,12 +11,11 @@\n     - network_boundaries detected\n     - json_parse_locations detected\n     - matched_endpoints present (frontend\u2194backend correlation)\n     \"\"\"\n     # Frontend: define a type and make a fetch with untyped .json()\n-    frontend_code = (\n-        \"\"\"\n+    frontend_code = (\"\"\"\n // FILE: frontend.ts\n // Keep type definition within ~20 lines of fetch for endpoint association\n interface User { name: string; }\n \n async function loadUser() {\n@@ -24,23 +23,20 @@\n   const data = await resp.json(); // implicit any\n   const local = JSON.parse('{\"ok\": true}'); // JSON.parse without validation\n   localStorage.setItem('k', JSON.stringify(data)); // library boundary\n   return data as any; // rule trigger (enterprise-only)\n }\n-\"\"\"\n-    ).strip()\n+\"\"\").strip()\n \n     # Backend: simple route without validation\n-    backend_code = (\n-        \"\"\"\n+    backend_code = (\"\"\"\n // FILE: backend.py\n @app.get('/api/user')\n def get_user():\n     data = request.get_json()  # unvalidated\n     return jsonify(data)\n-\"\"\"\n-    ).strip()\n+\"\"\").strip()\n \n     result = await security.type_evaporation_scan(\n         frontend_code=frontend_code,\n         backend_code=backend_code,\n         frontend_file=\"frontend.ts\",\n@@ -66,35 +62,31 @@\n     - api_contract present (with totals)\n     - schema_coverage populated\n     - custom_rule_violations present (from rules)\n     - compliance_report present\n     \"\"\"\n-    frontend_code = (\n-        \"\"\"\n+    frontend_code = (\"\"\"\n // FILE: frontend.ts\n // Place type alias near fetch to associate endpoint in generator\n  type Role = 'admin' | 'user';\n \n async function postUser() {\n   const r = await fetch('/api/user', { method: 'POST' });\n   const payload = await r.json(); // implicit any (rule)\n   const value = JSON.parse('{\"x\": 1}'); // JSON.parse without validation\n   return payload as Role; // unsafe assertion\n }\n-\"\"\"\n-    ).strip()\n+\"\"\").strip()\n \n-    backend_code = (\n-        \"\"\"\n+    backend_code = (\"\"\"\n // FILE: backend.py\n @app.post('/api/user')\n def create_user():\n     body = request.get_json()  # unvalidated\n     name = body['name']\n     return jsonify({'ok': True, 'name': name})\n-\"\"\"\n-    ).strip()\n+\"\"\").strip()\n \n     result = await security.type_evaporation_scan(\n         frontend_code=frontend_code,\n         backend_code=backend_code,\n         frontend_file=\"frontend.ts\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_call_graph_tiers.py\t2026-02-01 15:55:15.210877+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_call_graph_tiers.py\t2026-02-01 23:23:14.147888+00:00\n@@ -16,19 +16,17 @@\n     @pytest.mark.asyncio\n     async def test_basic_call_graph_includes_metadata(self, tmp_path, community_tier):\n         \"\"\"Basic call graph should include all metadata fields.\"\"\"\n         # Create a simple project\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def main():\n     helper()\n \n def helper():\n     return 42\n-\"\"\"\n-        )\n+\"\"\")\n         # community_tier fixture ensures community tier detection\n         result = await get_call_graph(project_root=str(tmp_path), depth=5)\n \n         assert result.success is True\n         # Verify metadata fields exist and have correct types\n@@ -117,12 +115,11 @@\n     @pytest.mark.asyncio\n     async def test_community_tier_depth_limit(self, tmp_path, community_tier):\n         \"\"\"Community tier should enforce max_depth=3.\"\"\"\n         # Create a deeply nested call chain\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def level_0():\n     level_1()\n \n def level_1():\n     level_2()\n@@ -136,12 +133,11 @@\n def level_4():\n     level_5()\n \n def level_5():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         # community_tier fixture from conftest.py disables license discovery\n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"community\"\n@@ -225,19 +221,17 @@\n \n     @pytest.mark.asyncio\n     async def test_no_truncation_when_within_limits(self, tmp_path):\n         \"\"\"When within limits, truncation fields should indicate no truncation.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def foo():\n     bar()\n \n def bar():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n         result = await get_call_graph(project_root=str(tmp_path))\n \n         assert result.success is True\n         assert result.total_nodes is not None\n         assert result.nodes_truncated is False\n@@ -304,37 +298,33 @@\n     \"\"\"Validate entry point heuristics across tiers and languages.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_pytest_entry_point_marked(self, tmp_path, community_tier):\n         \"\"\"[20260121_TEST] pytest-style test_* function is flagged as entry point in test modules.\"\"\"\n-        (tmp_path / \"test_sample.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"test_sample.py\").write_text(\"\"\"\n import helper\n \n def test_example():\n     helper.fn()\n-\"\"\"\n-        )\n+\"\"\")\n         (tmp_path / \"helper.py\").write_text(\"def fn():\\n    return 1\\n\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=5)\n \n         entry_nodes = {n.name for n in result.nodes if n.is_entry_point}\n         assert \"test_example\" in entry_nodes\n \n     @pytest.mark.asyncio\n     async def test_js_entry_point_consistent_pro(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] JS entry points (invoked main) remain entry points under Pro tier.\"\"\"\n-        (tmp_path / \"index.js\").write_text(\n-            \"\"\"\n+        (tmp_path / \"index.js\").write_text(\"\"\"\n function main() {\n     return 1;\n }\n \n main();\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=5)\n \n         assert result.tier_applied == \"pro\"\n         assert any(n.is_entry_point and n.name == \"main\" for n in result.nodes)\n@@ -342,19 +332,17 @@\n     @pytest.mark.asyncio\n     async def test_ts_entry_point_consistent_enterprise(\n         self, tmp_path, enterprise_tier\n     ):\n         \"\"\"[20260121_TEST] TS entry points remain entry points under Enterprise tier.\"\"\"\n-        (tmp_path / \"index.ts\").write_text(\n-            \"\"\"\n+        (tmp_path / \"index.ts\").write_text(\"\"\"\n function main(): number {\n     return 1;\n }\n \n main();\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=5)\n \n         assert result.tier_applied == \"enterprise\"\n         assert any(n.is_entry_point and n.name == \"main\" for n in result.nodes)\n@@ -392,12 +380,11 @@\n     \"\"\"Validate Pro-tier edge confidence and graph metrics are populated.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_pro_confidence_scores_present(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] Pro edges should include confidence metadata within bounds.\"\"\"\n-        (tmp_path / \"a.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"a.py\").write_text(\"\"\"\n class Base:\n     def call(self):\n         return 1\n \n class Impl(Base):\n@@ -407,12 +394,11 @@\n def run(x: Base):\n     return x.call()\n \n def main():\n     return run(Impl())\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"pro\"\n@@ -426,21 +412,19 @@\n         )\n \n     @pytest.mark.asyncio\n     async def test_pro_polymorphism_resolution(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] Advanced resolution should map instance method calls to class-qualified targets.\"\"\"\n-        (tmp_path / \"poly.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"poly.py\").write_text(\"\"\"\n class Worker:\n     def do(self):\n         return 1\n \n def use():\n     w = Worker()\n     return w.do()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=5)\n \n         assert result.success is True\n         assert result.tier_applied == \"pro\"\n@@ -451,12 +435,11 @@\n     \"\"\"Validate Enterprise metadata includes hot paths and dead code candidates.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_enterprise_hot_nodes_and_dead_code(self, tmp_path, enterprise_tier):\n         \"\"\"[20260121_TEST] Enterprise should populate hot_nodes and dead_code_candidates with meaningful entries.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def entry():\n     hub()\n     leaf1()\n \n def hub():\n@@ -469,12 +452,11 @@\n def leaf2():\n     pass\n \n def ghost():\n     return 0\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"enterprise\"\n@@ -489,21 +471,19 @@\n     \"\"\"Validate Pro tier resolves nested functions and method chains correctly.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_pro_nested_function_resolution(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] Pro should resolve nested function calls in advanced mode.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def outer():\n     def inner():\n         helper()\n     inner()\n \n def helper():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"pro\"\n@@ -516,12 +496,11 @@\n         ), \"Pro should resolve nested functions\"\n \n     @pytest.mark.asyncio\n     async def test_pro_method_chaining(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] Pro should resolve method chains with advanced resolution.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n class Builder:\n     def configure(self):\n         self.setup()\n         return self\n     \n@@ -531,12 +510,11 @@\n     def initialize(self):\n         pass\n \n builder = Builder()\n builder.configure().setup()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"pro\"\n@@ -550,23 +528,21 @@\n     \"\"\"Validate Pro tier includes comprehensive edge metrics and metadata.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_pro_edge_metrics_completeness(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] Pro edges should have confidence and inference_source populated.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n class Service:\n     def process(self):\n         self.validate()\n     \n     def validate(self):\n         pass\n \n svc = Service()\n svc.process()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"pro\"\n@@ -588,12 +564,11 @@\n             }, f\"Invalid inference_source: {edge.inference_source}\"\n \n     @pytest.mark.asyncio\n     async def test_pro_multiple_call_site_tracking(self, tmp_path, pro_tier):\n         \"\"\"[20260121_TEST] Pro should track multiple call sites for same target.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def utility():\n     pass\n \n def caller_one():\n     utility()\n@@ -601,12 +576,11 @@\n def caller_two():\n     utility()\n \n caller_one()\n caller_two()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"pro\"\n@@ -670,22 +644,20 @@\n     @pytest.mark.asyncio\n     async def test_enterprise_circular_dependency_detection(\n         self, tmp_path, enterprise_tier\n     ):\n         \"\"\"[20260121_TEST] Enterprise should detect and report circular dependencies.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def func_a():\n     func_b()\n \n def func_b():\n     func_c()\n \n def func_c():\n     func_a()  # Circular: func_c -> func_a -> func_b -> func_c\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(\n             project_root=str(tmp_path),\n             depth=10,\n             include_circular_import_check=True,\n@@ -697,12 +669,11 @@\n         assert len(result.edges) > 0, \"Should detect edges in circular structure\"\n \n     @pytest.mark.asyncio\n     async def test_enterprise_entry_point_expansion(self, tmp_path, enterprise_tier):\n         \"\"\"[20260121_TEST] Enterprise should identify all entry points (main, CLI, API routes).\"\"\"\n-        (tmp_path / \"main.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"main.py\").write_text(\"\"\"\n def main():\n     init()\n \n def init():\n     setup()\n@@ -710,12 +681,11 @@\n def setup():\n     pass\n \n if __name__ == \"__main__\":\n     main()\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(\n             project_root=str(tmp_path),\n             entry_point=\"main\",\n             depth=10,\n@@ -731,12 +701,11 @@\n     \"\"\"Validate Enterprise tier rich visualization with metrics.\"\"\"\n \n     @pytest.mark.asyncio\n     async def test_enterprise_mermaid_generation(self, tmp_path, enterprise_tier):\n         \"\"\"[20260121_TEST] Enterprise should generate Mermaid diagrams showing full graph.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def render_dashboard():\n     fetch_metrics()\n     fetch_user()\n \n def fetch_metrics():\n@@ -745,12 +714,11 @@\n def fetch_user():\n     query_database()\n \n def query_database():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"enterprise\"\n@@ -758,12 +726,11 @@\n         assert len(result.edges) >= 4, \"Enterprise should have all function edges\"\n \n     @pytest.mark.asyncio\n     async def test_enterprise_rich_metadata_export(self, tmp_path, enterprise_tier):\n         \"\"\"[20260121_TEST] Enterprise call graph should include rich metadata for visualization.\"\"\"\n-        (tmp_path / \"app.py\").write_text(\n-            \"\"\"\n+        (tmp_path / \"app.py\").write_text(\"\"\"\n def hub_function():\n     leaf_a()\n     leaf_b()\n     leaf_c()\n \n@@ -776,12 +743,11 @@\n def leaf_c():\n     pass\n \n def unused_function():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_call_graph(project_root=str(tmp_path), depth=10)\n \n         assert result.success is True\n         assert result.tier_applied == \"enterprise\"\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_scan_dependencies_tiers.py\t2026-02-01 15:55:15.254871+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_scan_dependencies_tiers.py\t2026-02-01 23:23:14.155415+00:00\n@@ -17,30 +17,27 @@\n \n @pytest.fixture\n def python_requirements_with_vulns(tmp_path):\n     \"\"\"Create a Python requirements.txt with known vulnerable packages.\"\"\"\n     req_file = tmp_path / \"requirements.txt\"\n-    req_file.write_text(\n-        \"\"\"\n+    req_file.write_text(\"\"\"\n # Vulnerable packages (intentionally outdated for testing)\n requests==2.6.0\n django==1.4.0\n pillow==2.4.0\n urllib3==1.7\n cryptography==0.4\n flask==0.10\n-\"\"\"\n-    )\n+\"\"\")\n     return tmp_path\n \n \n @pytest.fixture\n def python_pyproject_with_vulns(tmp_path):\n     \"\"\"Create a pyproject.toml with vulnerable dependencies.\"\"\"\n     pyproject = tmp_path / \"pyproject.toml\"\n-    pyproject.write_text(\n-        \"\"\"\n+    pyproject.write_text(\"\"\"\n [project]\n name = \"test-project\"\n version = \"0.1.0\"\n dependencies = [\n     \"requests==2.6.0\",\n@@ -51,21 +48,19 @@\n [project.optional-dependencies]\n dev = [\n     \"pytest==3.0.0\",\n     \"black==19.10b0\",\n ]\n-\"\"\"\n-    )\n+\"\"\")\n     return tmp_path\n \n \n @pytest.fixture\n def javascript_package_json_with_vulns(tmp_path):\n     \"\"\"Create a package.json with vulnerable dependencies.\"\"\"\n     pkg_json = tmp_path / \"package.json\"\n-    pkg_json.write_text(\n-        \"\"\"{\n+    pkg_json.write_text(\"\"\"{\n   \"name\": \"test-app\",\n   \"version\": \"1.0.0\",\n   \"dependencies\": {\n     \"express\": \"3.0.0\",\n     \"lodash\": \"2.4.1\",\n@@ -74,21 +69,19 @@\n   \"devDependencies\": {\n     \"webpack\": \"1.0.0\",\n     \"babel\": \"5.0.0\"\n   }\n }\n-\"\"\"\n-    )\n+\"\"\")\n     return tmp_path\n \n \n @pytest.fixture\n def java_pom_xml_with_vulns(tmp_path):\n     \"\"\"Create a pom.xml with vulnerable dependencies.\"\"\"\n     pom_file = tmp_path / \"pom.xml\"\n-    pom_file.write_text(\n-        \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+    pom_file.write_text(\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <project>\n   <modelVersion>4.0.0</modelVersion>\n   <groupId>com.example</groupId>\n   <artifactId>test-app</artifactId>\n   <version>1.0.0</version>\n@@ -109,42 +102,37 @@\n       <version>3.8.1</version>\n       <scope>test</scope>\n     </dependency>\n   </dependencies>\n </project>\n-\"\"\"\n-    )\n+\"\"\")\n     return tmp_path\n \n \n @pytest.fixture\n def java_gradle_with_vulns(tmp_path):\n     \"\"\"Create a build.gradle with vulnerable dependencies.\"\"\"\n     gradle_file = tmp_path / \"build.gradle\"\n-    gradle_file.write_text(\n-        \"\"\"\n+    gradle_file.write_text(\"\"\"\n dependencies {\n     implementation 'org.springframework:spring-core:3.0.0'\n     implementation 'commons-io:commons-io:2.4'\n     testImplementation 'junit:junit:3.8.1'\n }\n-\"\"\"\n-    )\n+\"\"\")\n     return tmp_path\n \n \n @pytest.fixture\n def benign_python_project(tmp_path):\n     \"\"\"Create a benign Python project with no known vulnerabilities.\"\"\"\n     req_file = tmp_path / \"requirements.txt\"\n-    req_file.write_text(\n-        \"\"\"\n+    req_file.write_text(\"\"\"\n requests==2.31.0\n django==4.2.0\n pillow==10.0.0\n-\"\"\"\n-    )\n+\"\"\")\n     return tmp_path\n \n \n @pytest.fixture\n def large_dependency_list(tmp_path):\n@@ -454,18 +442,16 @@\n     def test_all_languages_supported(self, enterprise_tier, tmp_path):\n         \"\"\"Verify all language support for Enterprise tier.\"\"\"\n         # Create multi-language project\n         (tmp_path / \"requirements.txt\").write_text(\"requests==2.6.0\\n\")\n         (tmp_path / \"package.json\").write_text('{\"dependencies\": {\"express\": \"3.0.0\"}}')\n-        (tmp_path / \"pom.xml\").write_text(\n-            \"\"\"<?xml version=\"1.0\"?>\n+        (tmp_path / \"pom.xml\").write_text(\"\"\"<?xml version=\"1.0\"?>\n <project><dependencies>\n <dependency><groupId>org.springframework</groupId>\n <artifactId>spring-core</artifactId>\n <version>3.0.0</version>\n-</dependency></dependencies></project>\"\"\"\n-        )\n+</dependency></dependencies></project>\"\"\")\n \n         result = _scan_dependencies_sync(\n             project_root=str(tmp_path),\n             scan_vulnerabilities=False,\n             include_dev=True,\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_graph_neighborhood_tiers.py\t2026-02-01 15:55:15.236147+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_graph_neighborhood_tiers.py\t2026-02-01 23:23:14.173398+00:00\n@@ -16,12 +16,11 @@\n     @pytest.mark.asyncio\n     async def test_community_k_limit_enforced(self, tmp_path, community_tier):\n         \"\"\"Community tier should enforce max_k=1 limit from limits.toml.\"\"\"\n         # Create test project\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     helper()\n \n def helper():\n     util()\n@@ -29,12 +28,11 @@\n def util():\n     core()\n \n def core():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Request k=5 (beyond Community's limit of k=1)\n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=5,\n@@ -54,23 +52,21 @@\n \n     @pytest.mark.asyncio\n     async def test_community_nodes_limit_enforced(self, tmp_path, community_tier):\n         \"\"\"Community tier should enforce max_nodes=20 limit.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     for i in range(10):\n         func_a()\n         func_b()\n         func_c()\n \n def func_a(): pass\n def func_b(): pass\n def func_c(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=2,\n             max_nodes=100,  # Request more than Community allows\n@@ -128,19 +124,17 @@\n \n     @pytest.mark.asyncio\n     async def test_community_mermaid_generated(self, tmp_path, community_tier):\n         \"\"\"Community tier should generate basic Mermaid diagrams.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     helper()\n \n def helper():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=1,\n             max_nodes=20,\n@@ -178,12 +172,11 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_k_limit_extended(self, tmp_path, pro_tier):\n         \"\"\"Pro tier should support k=5 (vs Community k=1).\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     depth1()\n \n def depth1():\n     depth2()\n@@ -197,12 +190,11 @@\n def depth4():\n     depth5()\n \n def depth5():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=5,\n             max_nodes=100,\n@@ -218,18 +210,16 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_nodes_limit_extended(self, tmp_path, pro_tier):\n         \"\"\"Pro tier should support max_nodes=100 (vs Community 20).\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     func_a()\n \n def func_a(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=2,\n             max_nodes=100,\n@@ -261,22 +251,20 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_has_semantic_neighbors_capability(self, tmp_path, pro_tier):\n         \"\"\"Pro tier should have semantic_neighbors capability.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def process_order(user_id):\n     validate()\n \n def validate():\n     pass\n \n def process_user():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::process_order\",\n             k=1,\n             max_nodes=50,\n@@ -288,19 +276,17 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_has_logical_relationship_detection(self, tmp_path, pro_tier):\n         \"\"\"Pro tier should have logical_relationship_detection capability.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def validate_order(order_id):\n     check_stock()\n \n def check_stock():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::validate_order\",\n             k=1,\n             max_nodes=50,\n@@ -312,19 +298,17 @@\n \n     @pytest.mark.asyncio\n     async def test_pro_mermaid_with_metadata(self, tmp_path, pro_tier):\n         \"\"\"Pro tier should generate Mermaid with enhanced metadata.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     helper()\n \n def helper():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=1,\n             max_nodes=50,\n@@ -341,12 +325,11 @@\n \n     @pytest.mark.asyncio\n     async def test_enterprise_unlimited_k(self, tmp_path, enterprise_tier):\n         \"\"\"Enterprise tier should support unlimited k depth.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def d0(): d1()\n def d1(): d2()\n def d2(): d3()\n def d3(): d4()\n def d4(): d5()\n@@ -354,12 +337,11 @@\n def d6(): d7()\n def d7(): d8()\n def d8(): d9()\n def d9(): d10()\n def d10(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::d0\",\n             k=100,  # Request very deep k\n             max_nodes=500,\n@@ -377,12 +359,11 @@\n \n     @pytest.mark.asyncio\n     async def test_enterprise_unlimited_nodes(self, tmp_path, enterprise_tier):\n         \"\"\"Enterprise tier should support unlimited nodes (no max_nodes limit).\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     for i in range(20):\n         func_a()\n         func_b()\n         func_c()\n@@ -390,12 +371,11 @@\n \n def func_a(): pass\n def func_b(): pass\n def func_c(): pass\n def func_d(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=2,\n             max_nodes=999,  # Request more than any limit\n@@ -426,22 +406,20 @@\n     async def test_enterprise_has_graph_query_language_capability(\n         self, tmp_path, enterprise_tier\n     ):\n         \"\"\"Enterprise tier should have graph_query_language capability.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def process():\n     validate()\n \n def validate():\n     pass\n \n def process_user():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Enterprise should accept and support query parameter\n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::process\",\n             k=2,\n@@ -474,17 +452,15 @@\n     async def test_enterprise_has_path_constraint_queries(\n         self, tmp_path, enterprise_tier\n     ):\n         \"\"\"Enterprise tier should have path_constraint_queries capability.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def a(): b()\n def b(): c()\n def c(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::a\",\n             k=2,\n             max_nodes=100,\n@@ -496,22 +472,20 @@\n \n     @pytest.mark.asyncio\n     async def test_enterprise_hot_nodes_detection(self, tmp_path, enterprise_tier):\n         \"\"\"Enterprise tier should populate hot nodes (high-degree nodes).\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def hub():\n     a()\n     b()\n     c()\n \n def a(): pass\n def b(): pass\n def c(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::hub\",\n             k=1,\n             max_nodes=100,\n@@ -528,20 +502,18 @@\n \n     @pytest.mark.asyncio\n     async def test_community_vs_pro_k_limit_difference(self, tmp_path):\n         \"\"\"Compare Community k=1 vs Pro k=5 on same graph.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def d0(): d1()\n def d1(): d2()\n def d2(): d3()\n def d3(): d4()\n def d4(): d5()\n def d5(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Community tier\n         from tests.utils.tier_setup import activate_tier\n \n         activate_tier(\"community\")\n@@ -576,22 +548,20 @@\n \n     @pytest.mark.asyncio\n     async def test_community_truncation_at_20_nodes(self, tmp_path, community_tier):\n         \"\"\"Community tier should truncate at max_nodes=20.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     f1()\n     f2()\n     f3()\n \n def f1(): pass\n def f2(): pass\n def f3(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=1,\n             max_nodes=50,\n@@ -612,19 +582,17 @@\n     async def test_community_lacks_semantic_neighbors_explicitly(\n         self, tmp_path, community_tier\n     ):\n         \"\"\"Verify Community output does NOT contain semantic neighbor metadata.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def calculate():\n     pass\n \n def compute():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::calculate\",\n             k=1,\n             max_nodes=20,\n@@ -642,19 +610,17 @@\n     async def test_community_lacks_logical_relationships_explicitly(\n         self, tmp_path, community_tier\n     ):\n         \"\"\"Verify Community does NOT include LOGICAL_RELATED edge types.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def validate():\n     pass\n \n def verify():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::validate\",\n             k=1,\n             max_nodes=20,\n@@ -710,22 +676,20 @@\n \n     @pytest.mark.asyncio\n     async def test_direction_filtering_community(self, tmp_path, community_tier):\n         \"\"\"Community should filter by direction: incoming, outgoing, both.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def caller():\n     target()\n \n def target():\n     callee()\n \n def callee():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Test both direction\n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::target\",\n             k=1,\n@@ -751,19 +715,17 @@\n \n     @pytest.mark.asyncio\n     async def test_min_confidence_filtering(self, tmp_path, community_tier):\n         \"\"\"min_confidence parameter should filter low-confidence edges.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     high_conf()\n \n def high_conf():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=1,\n             max_nodes=20,\n@@ -785,19 +747,17 @@\n \n     @pytest.mark.asyncio\n     async def test_mermaid_generation_community(self, tmp_path, community_tier):\n         \"\"\"Community should generate valid Mermaid diagrams.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def main():\n     helper()\n \n def helper():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::main\",\n             k=1,\n             max_nodes=20,\n@@ -811,22 +771,20 @@\n \n     @pytest.mark.asyncio\n     async def test_mermaid_generation_enterprise(self, tmp_path, enterprise_tier):\n         \"\"\"Enterprise should generate Mermaid with depth-based styling.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def d0():\n     d1()\n \n def d1():\n     d2()\n \n def d2():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::d0\",\n             k=2,\n             max_nodes=100,\n@@ -844,19 +802,17 @@\n \n     @pytest.mark.asyncio\n     async def test_node_depths_populated(self, tmp_path, community_tier):\n         \"\"\"Node depths should be populated in result.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     level1()\n \n def level1():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=1,\n             max_nodes=20,\n@@ -876,19 +832,17 @@\n \n     @pytest.mark.asyncio\n     async def test_edge_type_and_confidence_populated(self, tmp_path, community_tier):\n         \"\"\"Edges should include type and confidence.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def caller():\n     target()\n \n def target():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::caller\",\n             k=1,\n             max_nodes=20,\n@@ -909,24 +863,22 @@\n \n     @pytest.mark.asyncio\n     async def test_truncation_warning_community(self, tmp_path, community_tier):\n         \"\"\"Community should warn when truncated at max_nodes=20.\"\"\"\n         main_file = tmp_path / \"main.py\"\n-        main_file.write_text(\n-            \"\"\"\n+        main_file.write_text(\"\"\"\n def center():\n     a()\n     b()\n     c()\n     d()\n \n def a(): pass\n def b(): pass\n def c(): pass\n def d(): pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = await get_graph_neighborhood(\n             center_node_id=\"python::main::function::center\",\n             k=2,\n             max_nodes=100,  # Request beyond Community's 20-node limit\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_cross_platform.py\t2026-02-01 15:55:15.291510+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_cross_platform.py\t2026-02-01 23:23:14.255943+00:00\n@@ -49,15 +49,13 @@\n         from code_scalpel.mcp.server import mcp\n \n         tool = mcp._tool_manager._tools[\"update_symbol\"]\n \n         sample_file = tmp_path / \"platform_test.py\"\n-        sample_file.write_text(\n-            \"\"\"def foo():\n+        sample_file.write_text(\"\"\"def foo():\n     return 0\n-\"\"\"\n-        )\n+\"\"\")\n \n         args = {\n             \"file_path\": str(sample_file),\n             \"target_type\": \"function\",\n             \"target_name\": \"foo\",\n@@ -117,15 +115,13 @@\n         from code_scalpel.mcp.server import mcp\n \n         tool = mcp._tool_manager._tools[\"update_symbol\"]\n \n         sample_file = tmp_path / \"version_test.py\"\n-        sample_file.write_text(\n-            \"\"\"def foo():\n+        sample_file.write_text(\"\"\"def foo():\n     return 0\n-\"\"\"\n-        )\n+\"\"\")\n \n         args = {\n             \"file_path\": str(sample_file),\n             \"target_type\": \"function\",\n             \"target_name\": \"foo\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_edge_cases.py\t2026-02-01 15:55:15.298016+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_edge_cases.py\t2026-02-01 23:23:14.400634+00:00\n@@ -17,18 +17,16 @@\n     \"\"\"Test update_symbol with async functions.\"\"\"\n \n     async def test_async_function_replacement(self, tmp_path):\n         \"\"\"update_symbol should handle async function replacement.\"\"\"\n         py_file = tmp_path / \"async_sample.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n async def fetch_data(url):\n     '''Fetch data asynchronously.'''\n     # Simulated async operation\n     return {\"url\": url}\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"fetch_data\",\n@@ -43,18 +41,16 @@\n         assert result[\"file_path\"] == str(py_file)\n \n     async def test_async_method_replacement(self, tmp_path):\n         \"\"\"update_symbol should handle async method replacement.\"\"\"\n         py_file = tmp_path / \"async_class.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class AsyncHandler:\n     async def process(self, data):\n         '''Process data asynchronously.'''\n         return await self.handle(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"process\",\n@@ -72,19 +68,17 @@\n     \"\"\"Test update_symbol with decorated functions.\"\"\"\n \n     async def test_single_decorator(self, tmp_path):\n         \"\"\"update_symbol should handle functions with single decorator.\"\"\"\n         py_file = tmp_path / \"decorated.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n @staticmethod\n def parse_json(data):\n     '''Parse JSON string.'''\n     import json\n     return json.loads(data)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"parse_json\",\n@@ -98,19 +92,17 @@\n         assert result[\"success\"] is True\n \n     async def test_multiple_decorators(self, tmp_path):\n         \"\"\"update_symbol should handle multiple decorators.\"\"\"\n         py_file = tmp_path / \"multi_decorated.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n @classmethod\n @staticmethod\n def get_config(cls):\n     '''Get configuration.'''\n     return cls._config\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"get_config\",\n@@ -124,24 +116,22 @@\n         assert result[\"success\"] is True\n \n     async def test_property_decorator(self, tmp_path):\n         \"\"\"update_symbol should handle @property decorated methods.\"\"\"\n         py_file = tmp_path / \"property_class.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class Config:\n     @property\n     def value(self):\n         '''Get value.'''\n         return self._value\n     \n     @value.setter\n     def value(self, val):\n         '''Set value.'''\n         self._value = val\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"value\",\n@@ -159,20 +149,18 @@\n     \"\"\"Test update_symbol with nested functions.\"\"\"\n \n     async def test_nested_function_replacement(self, tmp_path):\n         \"\"\"update_symbol should handle nested functions (outer function).\"\"\"\n         py_file = tmp_path / \"nested.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n def outer_function(x):\n     '''Outer function.'''\n     def inner_function(y):\n         '''Inner function.'''\n         return x + y\n     return inner_function\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"outer_function\",\n@@ -187,18 +175,16 @@\n \n     async def test_inner_function_in_nested(self, tmp_path):\n         \"\"\"update_symbol should NOT be able to replace inner nested functions directly.\"\"\"\n         # This is an edge case - inner functions should be part of outer function scope\n         py_file = tmp_path / \"nested2.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n def outer_function(x):\n     def inner_function(y):\n         return x + y\n     return inner_function\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Attempting to replace inner_function directly should fail\n         result = {\n             \"success\": False,\n             \"file_path\": str(py_file),\n@@ -217,19 +203,17 @@\n     \"\"\"Test update_symbol with static and class methods.\"\"\"\n \n     async def test_static_method_replacement(self, tmp_path):\n         \"\"\"update_symbol should handle @staticmethod replacement.\"\"\"\n         py_file = tmp_path / \"static_methods.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class Math:\n     @staticmethod\n     def add(x, y):\n         '''Add two numbers.'''\n         return x + y\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"add\",\n@@ -243,19 +227,17 @@\n         assert result[\"success\"] is True\n \n     async def test_classmethod_replacement(self, tmp_path):\n         \"\"\"update_symbol should handle @classmethod replacement.\"\"\"\n         py_file = tmp_path / \"class_methods.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class Factory:\n     @classmethod\n     def create(cls, name):\n         '''Create instance.'''\n         return cls(name)\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"create\",\n@@ -273,20 +255,18 @@\n     \"\"\"Test update_symbol with lambda assignments (edge case).\"\"\"\n \n     async def test_lambda_assignment_as_function(self, tmp_path):\n         \"\"\"update_symbol may or may not support lambda assignments.\"\"\"\n         py_file = tmp_path / \"lambdas.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n # Lambda assignment\n simple_multiply = lambda x, y: x * y\n \n # Function definition\n def complex_multiply(x, y):\n     return x * y\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Lambda might not be supported (they're expressions, not statements)\n         # This tests whether tool handles it gracefully\n         result = {\n             \"success\": False,\n@@ -306,21 +286,19 @@\n     \"\"\"Test update_symbol with inherited classes and methods.\"\"\"\n \n     async def test_method_in_parent_class(self, tmp_path):\n         \"\"\"update_symbol should replace method in parent class.\"\"\"\n         py_file = tmp_path / \"inheritance.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class Parent:\n     def method(self):\n         '''Parent method.'''\n         return \"parent\"\n \n class Child(Parent):\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"method\",\n@@ -334,22 +312,20 @@\n         assert result[\"success\"] is True\n \n     async def test_overridden_method_in_child(self, tmp_path):\n         \"\"\"update_symbol should replace overridden method in child class.\"\"\"\n         py_file = tmp_path / \"override.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class Parent:\n     def method(self):\n         return \"parent\"\n \n class Child(Parent):\n     def method(self):\n         '''Overridden method.'''\n         return \"child\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"method\",\n@@ -367,12 +343,11 @@\n     \"\"\"Test update_symbol with complex docstrings.\"\"\"\n \n     async def test_multiline_docstring_preserved(self, tmp_path):\n         \"\"\"update_symbol should preserve multiline docstrings.\"\"\"\n         py_file = tmp_path / \"docstring.py\"\n-        py_file.write_text(\n-            '''\n+        py_file.write_text('''\n def complex_function(data):\n     \"\"\"\n     Process complex data.\n     \n     Args:\n@@ -390,12 +365,11 @@\n         \"success\"\n     \"\"\"\n     if not isinstance(data, dict):\n         raise ValueError(\"Data must be dict\")\n     return {k: v for k, v in data.items() if v is not None}\n-'''\n-        )\n+''')\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"complex_function\",\n@@ -413,23 +387,21 @@\n     \"\"\"Test update_symbol reports accurate line numbers.\"\"\"\n \n     async def test_lines_changed_accuracy(self, tmp_path):\n         \"\"\"update_symbol should report accurate line count.\"\"\"\n         py_file = tmp_path / \"lines.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n def function1():\n     '''First function.'''\n     return 1\n \n def function2():\n     '''Second function - 4 lines.'''\n     x = 10\n     y = 20\n     return x + y\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"function2\",\n@@ -447,12 +419,11 @@\n     \"\"\"Test update_symbol with special methods.\"\"\"\n \n     async def test_dunder_method_replacement(self, tmp_path):\n         \"\"\"update_symbol should handle __str__, __repr__, etc.\"\"\"\n         py_file = tmp_path / \"special.py\"\n-        py_file.write_text(\n-            \"\"\"\n+        py_file.write_text(\"\"\"\n class MyClass:\n     def __init__(self, value):\n         self.value = value\n     \n     def __str__(self):\n@@ -460,12 +431,11 @@\n         return f\"MyClass({self.value})\"\n     \n     def __repr__(self):\n         '''Developer representation.'''\n         return f\"MyClass(value={self.value!r})\"\n-\"\"\"\n-        )\n+\"\"\")\n \n         result = {\n             \"success\": True,\n             \"file_path\": str(py_file),\n             \"symbol_name\": \"__str__\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_mcp_error_handling.py\t2026-02-01 15:55:15.304139+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_mcp_error_handling.py\t2026-02-01 23:23:14.572789+00:00\n@@ -78,15 +78,13 @@\n \n     tool = mcp._tool_manager._tools[\"update_symbol\"]\n \n     # Try to update a symbol with invalid/conflicting parameters\n     sample_file = tmp_path / \"sample.py\"\n-    sample_file.write_text(\n-        \"\"\"def foo():\n-    return 0\n-\"\"\"\n-    )\n+    sample_file.write_text(\"\"\"def foo():\n+    return 0\n+\"\"\")\n \n     # Invalid operation: empty new_code should fail validation\n     args = {\n         \"file_path\": str(sample_file),\n         \"target_type\": \"function\",\n@@ -128,15 +126,13 @@\n     tool = mcp._tool_manager._tools[\"update_symbol\"]\n \n     # Create file within project root (security requirement)\n     project_root = Path(\"/mnt/k/backup/Develop/code-scalpel\")\n     sample_file = project_root / \"test_timeout_sample_temp.py\"\n-    sample_file.write_text(\n-        \"\"\"def foo():\n-    return 0\n-\"\"\"\n-    )\n+    sample_file.write_text(\"\"\"def foo():\n+    return 0\n+\"\"\")\n \n     try:\n         args = {\n             \"file_path\": str(sample_file),\n             \"target_type\": \"function\",\n@@ -185,15 +181,13 @@\n \n     async def invoke(i: int) -> PatchResultModel | dict:\n         # [20260121_FEATURE] Files must be within project root to avoid path sandbox rejection\n         project_root = Path(\"/mnt/k/backup/Develop/code-scalpel\")\n         sample_file = project_root / f\"test_async_{i}_temp.py\"\n-        sample_file.write_text(\n-            \"\"\"def foo():\n-    return 0\n-\"\"\"\n-        )\n+        sample_file.write_text(\"\"\"def foo():\n+    return 0\n+\"\"\")\n \n         try:\n             args = {\n                 \"file_path\": str(sample_file),\n                 \"target_type\": \"function\",\n@@ -240,15 +234,13 @@\n     monkeypatch.setattr(mcp_server, \"_get_current_tier\", lambda: \"community\")\n     tool = mcp._tool_manager._tools[\"update_symbol\"]\n \n     project_root = Path(\"/mnt/k/backup/Develop/code-scalpel\")\n     sample_file = project_root / \"test_oom_sample_temp.py\"\n-    sample_file.write_text(\n-        \"\"\"def foo():\n-    return 0\n-\"\"\"\n-    )\n+    sample_file.write_text(\"\"\"def foo():\n+    return 0\n+\"\"\")\n \n     # Inject MemoryError in the patcher\n     def mock_from_file(*args, **kwargs):\n         raise MemoryError(\"simulated OOM\")\n \n@@ -305,15 +297,13 @@\n     from code_scalpel.mcp.models.core import PatchResultModel\n     from pathlib import Path\n \n     project_root = Path(\"/mnt/k/backup/Develop/code-scalpel\")\n     sample_file = project_root / \"test_pii_sample_temp.py\"\n-    sample_file.write_text(\n-        \"\"\"def foo():\n-    return 0\n-\"\"\"\n-    )\n+    sample_file.write_text(\"\"\"def foo():\n+    return 0\n+\"\"\")\n \n     secret_string = \"sk_live_51AbC123XyZ456SECRET789\"\n     args = {\n         \"file_path\": str(sample_file),\n         \"target_type\": \"function\",\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_validate_tool_compliance.py\t2026-02-01 15:55:15.337314+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_validate_tool_compliance.py\t2026-02-01 23:23:14.591064+00:00\n@@ -20,64 +20,54 @@\n     mcp_dir.mkdir(parents=True)\n \n     # tools/__init__.py with register_tools\n     tools_init = mcp_dir / \"tools\" / \"__init__.py\"\n     tools_init.parent.mkdir()\n-    tools_init.write_text(\n-        \"\"\"\n+    tools_init.write_text(\"\"\"\n from .analyze import analyze_code\n from .security import security_scan\n \n TOOLS = [analyze_code, security_scan]\n \n def register_tools():\n     pass  # Mock registration\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Good tool: tools/analyze.py\n     analyze_py = mcp_dir / \"tools\" / \"analyze.py\"\n-    analyze_py.write_text(\n-        \"\"\"\n+    analyze_py.write_text(\"\"\"\n from code_scalpel.mcp.protocol import mcp\n from code_scalpel.mcp.helpers.analyze_helpers import _analyze_code_sync\n \n @mcp.tool()\n async def analyze_code(code: str, language: str) -> dict:\n     return await asyncio.to_thread(_analyze_code_sync, code, language)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Good helper: helpers/analyze_helpers.py\n     helpers_analyze = mcp_dir / \"helpers\" / \"analyze_helpers.py\"\n     helpers_analyze.parent.mkdir()\n-    helpers_analyze.write_text(\n-        \"\"\"\n+    helpers_analyze.write_text(\"\"\"\n def _analyze_code_sync(code: str, language: str) -> dict:\n     return {\"result\": \"analyzed\"}\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Bad tool: missing decorator\n     bad_tool = mcp_dir / \"tools\" / \"bad_tool.py\"\n-    bad_tool.write_text(\n-        \"\"\"\n+    bad_tool.write_text(\"\"\"\n from code_scalpel.mcp.helpers.bad_helpers import _bad_sync\n \n async def bad_tool(code: str) -> dict:\n     return await asyncio.to_thread(_bad_sync, code)\n-\"\"\"\n-    )\n+\"\"\")\n \n     # Bad helper: async instead of sync\n     bad_helper = mcp_dir / \"helpers\" / \"bad_helpers.py\"\n-    bad_helper.write_text(\n-        \"\"\"\n+    bad_helper.write_text(\"\"\"\n async def _bad_sync(code: str) -> dict:\n     return {\"result\": \"bad\"}\n-\"\"\"\n-    )\n+\"\"\")\n \n     return tmp_path\n \n \n class TestValidateToolCompliance:\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_analyze_deprecated_code.py\t2026-02-01 15:55:15.316815+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_analyze_deprecated_code.py\t2026-02-01 23:23:14.615232+00:00\n@@ -10,20 +10,18 @@\n \n     def test_detects_deprecation_markers(self, tmp_path):\n         \"\"\"Test detection of deprecation marker comments.\"\"\"\n         # Create test file with deprecation marker\n         test_file = tmp_path / \"deprecated.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n # [20260120_DEPRECATED] This function is deprecated\n def old_function():\n     pass\n \n def new_function():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path)\n         results = analyzer.analyze_file(test_file)\n \n         assert results[\"has_deprecation_marker\"]\n@@ -34,65 +32,57 @@\n \n     def test_counts_imports_ast(self, tmp_path):\n         \"\"\"Test AST-based import counting.\"\"\"\n         # Create files with imports\n         module_file = tmp_path / \"module.py\"\n-        module_file.write_text(\n-            \"\"\"\n+        module_file.write_text(\"\"\"\n import os\n from pathlib import Path\n-\"\"\"\n-        )\n+\"\"\")\n \n         importer_file = tmp_path / \"importer.py\"\n-        importer_file.write_text(\n-            \"\"\"\n+        importer_file.write_text(\"\"\"\n import module\n from module import os\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path)\n         results = analyzer.analyze_file(importer_file)\n \n         assert results[\"import_count\"] > 0\n         assert \"module\" in results[\"imports\"]\n \n     def test_detects_legacy_functions(self, tmp_path):\n         \"\"\"Test detection of legacy function definitions.\"\"\"\n         test_file = tmp_path / \"legacy.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n # Legacy function without modern patterns\n def old_style_function(arg1, arg2):\n     return arg1 + arg2\n \n def modern_function(arg1: int, arg2: int) -> int:\n     return arg1 + arg2\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path)\n         results = analyzer.analyze_file(test_file)\n \n         assert len(results[\"legacy_functions\"]) > 0\n         assert \"old_style_function\" in results[\"legacy_functions\"]\n \n     def test_datetime_now_detection(self, tmp_path):\n         \"\"\"Test detection of datetime.now() without timezone.\"\"\"\n         test_file = tmp_path / \"datetime_usage.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n import datetime\n \n # Bad: no timezone\n now = datetime.datetime.now()\n \n # Good: with timezone\n utc_now = datetime.datetime.now(datetime.timezone.utc)\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path)\n         results = analyzer.analyze_file(test_file)\n \n         assert results[\"has_datetime_now_without_tz\"]\n@@ -121,18 +111,16 @@\n         # Create files with varying import counts\n         low_import_file = tmp_path / \"low.py\"\n         low_import_file.write_text(\"import os\")\n \n         high_import_file = tmp_path / \"high.py\"\n-        high_import_file.write_text(\n-            \"\"\"\n+        high_import_file.write_text(\"\"\"\n import os\n import sys\n import pathlib\n from datetime import datetime\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path, min_import_threshold=3)\n         inventory = analyzer.build_inventory()\n \n         # Only high import file should be included\n@@ -142,44 +130,38 @@\n \n     def test_caller_detection(self, tmp_path):\n         \"\"\"Test detection of callers to deprecated functions.\"\"\"\n         # Create deprecated function\n         deprecated_file = tmp_path / \"deprecated.py\"\n-        deprecated_file.write_text(\n-            \"\"\"\n+        deprecated_file.write_text(\"\"\"\n def deprecated_func():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         # Create caller\n         caller_file = tmp_path / \"caller.py\"\n-        caller_file.write_text(\n-            \"\"\"\n+        caller_file.write_text(\"\"\"\n from deprecated import deprecated_func\n \n deprecated_func()\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path)\n         results = analyzer.analyze_file(deprecated_file)\n \n         assert results[\"caller_count\"] > 0\n         assert \"caller.py\" in results[\"callers\"]\n \n     def test_migration_guidance_detection(self, tmp_path):\n         \"\"\"Test detection of migration guidance strings.\"\"\"\n         test_file = tmp_path / \"migration.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n # TODO: migrate to new_function\n # Migration: use new_module.new_function instead\n def old_function():\n     pass\n-\"\"\"\n-        )\n+\"\"\")\n \n         analyzer = DeprecatedCodeAnalyzer(tmp_path)\n         results = analyzer.analyze_file(test_file)\n \n         assert results[\"has_migration_guidance\"]\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_tier_gating_smoke.py\t2026-02-01 15:55:15.261921+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_tier_gating_smoke.py\t2026-02-01 23:23:14.622586+00:00\n@@ -27,17 +27,15 @@\n async def test_get_symbol_references_community_limits(monkeypatch, tmp_path: Path):\n     \"\"\"Community tier applies max_files_searched/max_references without upsell.\"\"\"\n \n     # Create multiple files that reference the same symbol.\n     for idx in range(10):\n-        (tmp_path / f\"m{idx}.py\").write_text(\n-            \"\"\"def target():\n+        (tmp_path / f\"m{idx}.py\").write_text(\"\"\"def target():\n     return 1\n \n x = target()\n-\"\"\"\n-        )\n+\"\"\")\n \n     monkeypatch.setattr(\n         code_scalpel.licensing.tier_detector, \"get_current_tier\", lambda: \"community\"\n     )\n     # [20260121_TEST] Patch the helper module import site to affect runtime.\n@@ -124,15 +122,13 @@\n     from code_scalpel.mcp import server as mcp_server\n \n     mcp_server.set_project_root(tmp_path)\n \n     test_file = tmp_path / \"mod.py\"\n-    test_file.write_text(\n-        \"\"\"def target():\n+    test_file.write_text(\"\"\"def target():\n     return 1\n-\"\"\"\n-    )\n+\"\"\")\n \n     monkeypatch.setattr(\n         code_scalpel.licensing.tier_detector, \"get_current_tier\", lambda: \"community\"\n     )\n     # Patch capabilities at the helper import site used by update_symbol.\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/conftest.py\t2026-02-01 15:55:15.284324+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/conftest.py\t2026-02-01 23:23:15.097052+00:00\n@@ -180,12 +180,11 @@\n \n @pytest.fixture\n def temp_python_file(tmp_path):\n     \"\"\"Create a temporary Python file with sample code.\"\"\"\n     py_file = tmp_path / \"sample.py\"\n-    py_file.write_text(\n-        \"\"\"\n+    py_file.write_text(\"\"\"\n def add_numbers(a, b):\n     '''Add two numbers.'''\n     return a + b\n \n def calculate_tax(amount, rate=0.1):\n@@ -196,21 +195,19 @@\n     '''Simple calculator.'''\n     \n     def multiply(self, x, y):\n         '''Multiply two numbers.'''\n         return x * y\n-\"\"\"\n-    )\n+\"\"\")\n     return py_file\n \n \n @pytest.fixture\n def temp_js_file(tmp_path):\n     \"\"\"Create a temporary JavaScript file with sample code.\"\"\"\n     js_file = tmp_path / \"sample.js\"\n-    js_file.write_text(\n-        \"\"\"\n+    js_file.write_text(\"\"\"\n function addNumbers(a, b) {\n     // Add two numbers\n     return a + b;\n }\n \n@@ -225,12 +222,11 @@\n     multiply(x, y) {\n         // Multiply two numbers\n         return x * y;\n     }\n }\n-\"\"\"\n-    )\n+\"\"\")\n     return js_file\n \n \n @pytest.fixture\n def temp_multifile_project(tmp_path):\n@@ -238,38 +234,34 @@\n     src_dir = tmp_path / \"src\"\n     src_dir.mkdir()\n \n     # File 1: utils.py\n     utils_file = src_dir / \"utils.py\"\n-    utils_file.write_text(\n-        \"\"\"\n+    utils_file.write_text(\"\"\"\n def calculate_discount(price, rate=0.1):\n     '''Calculate discount.'''\n     return price * (1 - rate)\n \n def validate_price(price):\n     '''Validate price.'''\n     return price > 0\n-\"\"\"\n-    )\n+\"\"\")\n \n     # File 2: services.py\n     services_file = src_dir / \"services.py\"\n-    services_file.write_text(\n-        \"\"\"\n+    services_file.write_text(\"\"\"\n from utils import calculate_discount\n \n def apply_discount(price):\n     '''Apply discount to price.'''\n     return calculate_discount(price)\n \n def process_order(items):\n     '''Process order.'''\n     total = sum(items)\n     return apply_discount(total)\n-\"\"\"\n-    )\n+\"\"\")\n \n     return {\"root\": tmp_path, \"utils\": utils_file, \"services\": services_file}\n \n \n # =============================================================================\n--- /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_validate_import_paths.py\t2026-02-01 15:55:15.326960+00:00\n+++ /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_validate_import_paths.py\t2026-02-01 23:23:15.127204+00:00\n@@ -10,19 +10,17 @@\n \n     def test_detects_deprecated_imports(self, tmp_path):\n         \"\"\"Test detection of deprecated import patterns.\"\"\"\n         # Create test file with deprecated import\n         test_file = tmp_path / \"deprecated_import.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n # Old import pattern\n from code_scalpel.server import some_function\n \n # Correct import\n from code_scalpel.mcp.tools.new_module import some_function\n-\"\"\"\n-        )\n+\"\"\")\n \n         validator = ImportPathValidator(tmp_path)\n         results = validator.validate_file(test_file)\n \n         assert len(results[\"deprecated_imports\"]) > 0\n@@ -56,16 +54,14 @@\n         assert len(doc_issues) > 0\n \n     def test_provides_fix_suggestions(self, tmp_path):\n         \"\"\"Test generation of fix suggestions.\"\"\"\n         test_file = tmp_path / \"broken.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n from code_scalpel.server import old_tool\n import code_scalpel.old_helpers as helpers\n-\"\"\"\n-        )\n+\"\"\")\n \n         validator = ImportPathValidator(tmp_path)\n         results = validator.validate_file(test_file)\n \n         assert len(results[\"fix_suggestions\"]) > 0\n@@ -123,33 +119,29 @@\n \n     def test_detects_relative_imports(self, tmp_path):\n         \"\"\"Test detection of problematic relative imports.\"\"\"\n         test_file = tmp_path / \"package\" / \"sub\" / \"module.py\"\n         test_file.parent.mkdir(parents=True)\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n from ..server import func\n from . import sibling\n-\"\"\"\n-        )\n+\"\"\")\n \n         validator = ImportPathValidator(tmp_path)\n         results = validator.validate_file(test_file)\n \n         # Should detect the relative import to server\n         assert len(results[\"relative_imports\"]) > 0\n \n     def test_suggests_canonical_imports(self, tmp_path):\n         \"\"\"Test suggestion of canonical new import paths.\"\"\"\n         test_file = tmp_path / \"test.py\"\n-        test_file.write_text(\n-            \"\"\"\n+        test_file.write_text(\"\"\"\n # Old patterns\n from code_scalpel.server import analyze_code\n import code_scalpel.helpers as helpers\n-\"\"\"\n-        )\n+\"\"\")\n \n         validator = ImportPathValidator(tmp_path)\n         results = validator.validate_file(test_file)\n \n         suggestions = results[\"fix_suggestions\"]\nSkipping .ipynb files as Jupyter dependencies are not installed.\nYou can fix this by running ``pip install \"black[jupyter]\"``\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_invisible_enforcement.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_crypto_verify.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_policy_evaluation_enforcement.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_policy_engine_guardian.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_governance_budget_enforcement.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/autonomy/test_unified_governance.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/packages/codescalpel-agents/tests/integration_test_integrations_wrappers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/incremental_index.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/incremental_indexer.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/analysis/project_context.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/config/init_config.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/ARCHITECT_STRESS_TEST.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/capabilities/test_resolver_ci_environment.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_framework_imports.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_framework_imports_flask.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_dependency_parser.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_typescript_parser_stub.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_project_crawler.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/cli/test_cli.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/test_config_loader.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/test_pro_tier_features.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/test_import_resolver.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/core/parsers/test_surgical_tools_coverage.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_oracle_pipeline.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_integration.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_symbol_enrichment.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/src/code_scalpel/surgery/surgical_extractor.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/integration/test_v151_integration.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/lib_scalpel/test_scanner.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_mcp_resources.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_resource_templates.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_stage5_manual_tool_validation.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_type_evaporation_scan_checklist_gaps.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_oracle_middleware.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_mcp.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp/test_type_evaporation_scan_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_cross_file_security_scan_regression.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_adversarial.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_type_narrowing_extra.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_adversarial_security.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_refactor_simulator.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/mcp_tool_verification/test_mcp_tools_live.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_simulate_refactor_edge_cases_comprehensive.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_vulnerability_scanner.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_unified_sink_detector.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/pdg_tools/security/test_security_analysis.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_compliance_detection.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_license_validation.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_mcp_integration.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_tier_enforcement.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_edge_cases.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/code_policy_check/test_rule_detection.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_mcp_interface.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/mcp_metadata/test_mcp_license_metadata.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_file_context/test_enterprise_tier.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/cross_file_security_scan/test_core_functionality.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/test_mermaid_validation.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_symbol_references/test_output_metadata.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_extractor_additional.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_symbol_references/test_licensing_and_limits.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_graph_neighborhood/conftest.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_call_graph.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_project_map/conftest.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_extractor.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_file_context_tiers_clean.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_resolution.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/get_cross_file_dependencies/test_mcp_protocol_and_security.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_call_graph.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/conftest.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/conftest.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_get_project_map.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/test_oracle_ai_feedback.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_cross_file_taint.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/oracle/test_oracle_pipeline.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_call_graph_enhanced.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_python_breadth.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_rename.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_advanced_vulnerabilities.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_multilanguage_support.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/security_scan/test_pro_features_extra.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_extract_code_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/rename_symbol/test_rename_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_analyze_code_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_cross_file_dependencies_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_file_context_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_cross_file_security_scan_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/individual/test_scan_dependencies.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_symbol_references_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_project_map_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_type_evaporation_scan_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_call_graph_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_scan_dependencies_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_get_graph_neighborhood_tiers.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_cross_platform.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_edge_cases.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/test_mcp_error_handling.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_validate_tool_compliance.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_analyze_deprecated_code.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/tiers/test_tier_gating_smoke.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/update_symbol/conftest.py\nwould reformat /mnt/k/backup/Develop/code-scalpel/tests/tools/validation/test_validate_import_paths.py\n\nOh no! \ud83d\udca5 \ud83d\udc94 \ud83d\udca5\n101 files would be reformatted, 996 files would be left unchanged.\n"
    },
    "ruff": {
      "status": "passed",
      "output": "No linting issues found"
    },
    "pyright": {
      "status": "passed",
      "output": "No type errors found"
    },
    "mcp_contracts": {
      "status": "passed",
      "output": "All MCP contract components available"
    },
    "security": {
      "status": "passed",
      "output": "Security audit completed with known CVEs ignored"
    }
  },
  "artifacts": {},
  "summary": {}
}