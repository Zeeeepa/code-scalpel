{
  "_tag": "[20251214_DOCS] v1.5.5 parallel execution results",
  "status": "complete",
  "configuration": {
    "executor": "ProcessPoolExecutor",
    "max_workers": "os.cpu_count() (16 on test machine)",
    "batch_size": 100,
    "batch_rationale": "100 files per worker reduces pickle serialization overhead by ~75%"
  },
  "benchmark_fixture": "tests/fixtures/data/synthetic (1201 files, 4190 imports)",
  "results": {
    "per_file_tasking": {
      "elapsed_s": 12.093,
      "approach": "1 ProcessPoolExecutor submit per file",
      "overhead": "High pickle serialization (1201 roundtrips)"
    },
    "batch_100_tasking": {
      "elapsed_s": 3.077,
      "approach": "100 files per batch, ~12 batches total",
      "overhead": "~12 pickle roundtrips instead of 1201"
    }
  },
  "improvement": {
    "before_s": 12.093,
    "after_s": 3.077,
    "improvement_pct": "74.6%"
  },
  "scaling_notes": "Batching amortizes pickle overhead; diminishing returns beyond batch_size ~100 on this workload."
}
