# Python Parsers Module

> **Code Scalpel's Python Parser provides surgical precision for Python code analysis, integrating the best static analysis tools in the Python ecosystem.**

## Overview

This module provides unified interfaces to 10 Python static analysis tools, offering:
- **Consistent API** across all tools
- **Structured output** via dataclasses
- **Configuration parsing** from standard config files
- **Comprehensive coverage** of linting, type checking, security, and quality metrics

## Module Architecture

```
python_parsers/
â”œâ”€â”€ __init__.py              # Public API with lazy loading
â”œâ”€â”€ python_parsers_ast.py    # Core AST analysis, symbols, CFG/DFG
â”œâ”€â”€ python_parsers_ruff.py   # Fast Rust-based linting
â”œâ”€â”€ python_parsers_mypy.py   # Static type checking
â”œâ”€â”€ python_parsers_pylint.py # Code quality analysis
â”œâ”€â”€ python_parsers_bandit.py # Security vulnerability detection
â”œâ”€â”€ python_parsers_flake8.py # Style checking with plugins
â”œâ”€â”€ python_parsers_code_quality.py  # Complexity metrics
â”œâ”€â”€ python_parsers_pydocstyle.py    # Docstring validation
â”œâ”€â”€ python_parsers_pycodestyle.py   # PEP 8 enforcement
â”œâ”€â”€ python_parsers_prospector.py    # Meta-linter aggregation
â”œâ”€â”€ python_parsers_isort.py         # Import sorting (PLANNED)
â”œâ”€â”€ python_parsers_vulture.py       # Dead code detection (PLANNED)
â”œâ”€â”€ python_parsers_radon.py         # Code complexity metrics (PLANNED)
â”œâ”€â”€ python_parsers_safety.py        # Dependency security (PLANNED)
â”œâ”€â”€ python_parsers_interrogate.py   # Documentation coverage (PLANNED)
â””â”€â”€ README.md                # This file
```

## Data Flow Architecture

### Input Sources

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           INPUTS TO PYTHON_PARSERS MODULE           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. SOURCE CODE
   â”œâ”€ Python files (.py)
   â”œâ”€ Stub files (.pyi)
   â””â”€ String content (in-memory)

2. CONFIGURATION FILES
   â”œâ”€ pyproject.toml
   â”œâ”€ .pylintrc / pylintrc
   â”œâ”€ setup.cfg
   â”œâ”€ ruff.toml
   â”œâ”€ mypy.ini
   â”œâ”€ .bandit
   â”œâ”€ .flake8
   â”œâ”€ tox.ini
   â”œâ”€ .prospector.yaml
   â””â”€ Programmatic config objects

3. TOOL OUTPUTS
   â”œâ”€ JSON output (mypy, pylint, bandit, ruff, prospector)
   â”œâ”€ Text output (flake8, pydocstyle, pycodestyle)
   â””â”€ SARIF format (bandit, prospector)

4. ENVIRONMENT
   â”œâ”€ Python version
   â”œâ”€ Tool installation paths
   â”œâ”€ Virtual environment
   â””â”€ Working directory
```

### Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PROCESSING PIPELINE WITHIN PARSERS                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SOURCE CODE INPUT
    â”‚
    â”œâ”€â†’ [PythonASTParser] â”€â”€â”€â”€â”€â†’ AST Analysis
    â”‚      â”œâ”€ Symbol extraction (functions, classes, imports)
    â”‚      â”œâ”€ Scope analysis (LEGB rule)
    â”‚      â”œâ”€ Control Flow Graph (CFG)
    â”‚      â””â”€ Data Flow Analysis (DFG)
    â”‚
    â”œâ”€â†’ [RuffParser] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Fast Linting
    â”‚      â”œâ”€ JSON output parsing
    â”‚      â”œâ”€ Rule categorization
    â”‚      â””â”€ Auto-fix extraction
    â”‚
    â”œâ”€â†’ [MypyParser] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Type Checking
    â”‚      â”œâ”€ JSON output parsing
    â”‚      â”œâ”€ Error classification
    â”‚      â”œâ”€ Type coverage calculation
    â”‚      â””â”€ Typeshed suggestion matching
    â”‚
    â”œâ”€â†’ [PylintParser] â”€â”€â”€â”€â”€â”€â”€â”€â†’ Quality Analysis
    â”‚      â”œâ”€ JSON output parsing
    â”‚      â”œâ”€ Message grouping by checker
    â”‚      â”œâ”€ Score calculation
    â”‚      â””â”€ Improvement suggestions
    â”‚
    â”œâ”€â†’ [BanditParser] â”€â”€â”€â”€â”€â”€â”€â”€â†’ Security Analysis
    â”‚      â”œâ”€ JSON output parsing
    â”‚      â”œâ”€ CWE/CVE mapping
    â”‚      â”œâ”€ Severity normalization
    â”‚      â””â”€ SARIF generation
    â”‚
    â”œâ”€â†’ [Flake8Parser] â”€â”€â”€â”€â”€â”€â”€â”€â†’ Style Checking
    â”‚      â”œâ”€ Output parsing
    â”‚      â”œâ”€ Plugin detection
    â”‚      â””â”€ Code categorization
    â”‚
    â”œâ”€â†’ [CodeQualityParser] â”€â”€â”€â†’ Complexity Metrics
    â”‚      â”œâ”€ Cyclomatic complexity
    â”‚      â”œâ”€ Cognitive complexity
    â”‚      â”œâ”€ Maintainability index
    â”‚      â””â”€ LOC calculation
    â”‚
    â”œâ”€â†’ [PydocstyleParser] â”€â”€â”€â”€â†’ Docstring Validation
    â”‚      â”œâ”€ Convention detection
    â”‚      â”œâ”€ Coverage analysis
    â”‚      â””â”€ Quality checking
    â”‚
    â”œâ”€â†’ [PycodestyleParser] â”€â”€â”€â†’ PEP 8 Enforcement
    â”‚      â””â”€ Style compliance percentage
    â”‚
    â””â”€â†’ [ProspectorParser] â”€â”€â”€â”€â†’ Meta-Linter Aggregation
           â”œâ”€ Multi-tool execution
           â”œâ”€ Message deduplication
           â””â”€ Profile management

CONFIGURATION PARSING (Parallel)
    â”‚
    â”œâ”€â†’ TOML Parser (tomllib/tomli)
    â”œâ”€â†’ INI Parser (configparser)
    â””â”€â†’ YAML Parser (PyYAML)
```

### Output Data Structures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OUTPUTS FROM PYTHON_PARSERS MODULE              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. STRUCTURED RESULT OBJECTS
   
   Common structure across all parsers:
   â”œâ”€ Result/Message/Issue dataclass
   â”‚  â”œâ”€ code/id/test_id (unique identifier)
   â”‚  â”œâ”€ message/text (human-readable message)
   â”‚  â”œâ”€ severity (error, warning, info, note)
   â”‚  â”œâ”€ path (file location)
   â”‚  â”œâ”€ line (line number)
   â”‚  â”œâ”€ column (column number)
   â”‚  â””â”€ metadata (tool-specific)
   â”‚
   â”œâ”€ Report/Result dataclass
   â”‚  â”œâ”€ messages/results/issues (list of findings)
   â”‚  â”œâ”€ statistics (counts, scores, metrics)
   â”‚  â”œâ”€ metadata (tool version, execution time)
   â”‚  â””â”€ success (execution status)
   â”‚
   â””â”€ Config dataclass
      â”œâ”€ Tool-specific options
      â””â”€ Methods: from_file(), to_cli_args()

2. AGGREGATE REPORT FORMATS
   
   Individual Reports (one per parser):
   â”œâ”€ RuffViolation / RuffReport
   â”œâ”€ MypyError / MypyResult
   â”œâ”€ PylintMessage / PylintReport
   â”œâ”€ BanditIssue / BanditReport
   â”œâ”€ Flake8Violation / Flake8Report
   â”œâ”€ ComplexityMetrics / CodeQualityReport
   â”œâ”€ PydocstyleViolation / PydocstyleReport
   â”œâ”€ PycodestyleViolation / PycodestyleReport
   â””â”€ ProspectorMessage / ProspectorReport

3. EXPORT FORMATS
   
   â”œâ”€ Python dataclass dicts (via asdict())
   â”œâ”€ JSON serialization (for APIs, files)
   â”œâ”€ SARIF format (bandit, prospector for CI/CD)
   â”œâ”€ Human-readable text (format() methods)
   â”œâ”€ CSV export (via pandas if available)
   â””â”€ HTML reports (tool-specific)

4. ANALYSIS PRODUCTS
   
   â”œâ”€ Symbols: PythonFunction, PythonClass, PythonImport
   â”œâ”€ Graphs: CFG (ControlFlowGraph), DFG (DataFlowGraph)
   â”œâ”€ Metrics: Complexity, Maintainability, Coverage
   â”œâ”€ Coverage: TypeCoverage, DocCoverage, StyleCompliance
   â””â”€ Suggestions: QuickWins, ScoreImprovements, Refactorings
```

### Integration Points with Other Modules

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INTEGRATION WITH CODEBASE ECOSYSTEM                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

UPSTREAM CONSUMERS (Import from python_parsers):
â”œâ”€ code_scalpel.code_parser (BaseToolParser interface)
â”œâ”€ code_scalpel.code_analyzer (Cross-language analysis)
â”œâ”€ code_scalpel.report_generator (Multi-parser reporting)
â”œâ”€ code_scalpel.ide_integration (VS Code/IDE features)
â””â”€ code_scalpel.cli (Command-line interface)

DOWNSTREAM SOURCES (Provide data to python_parsers):
â”œâ”€ Filesystem (load Python files, config files)
â”œâ”€ External tools (ruff, mypy, pylint, bandit, flake8, etc.)
â”œâ”€ Configuration managers (pyproject.toml, setup.cfg)
â””â”€ Environment (Python version, virtualenv)

CROSS-PARSER DATA FLOW:
â”œâ”€ AST Parser (foundation)
â”‚  â””â”€ Output: Symbol table, scopes, CFG/DFG
â”‚     â””â”€ Consumed by: Code quality metrics, framework detection
â”‚
â”œâ”€ Ruff, Mypy, Pylint, Bandit, Flake8 (parallel analysis)
â”‚  â””â”€ Output: Structured findings
â”‚     â””â”€ Aggregated by: ProspectorParser, report_generator
â”‚
â”œâ”€ ProspectorParser (meta-analysis)
â”‚  â””â”€ Input: Results from all other parsers
â”‚  â””â”€ Output: Deduplicated, unified severity report
â”‚     â””â”€ Consumed by: Report generation, CI/CD pipelines
â”‚
â””â”€ CodeQualityParser (metrics-focused)
   â””â”€ Input: AST output, complexity calculations
   â””â”€ Output: Metrics dashboard data
      â””â”€ Consumed by: Trend analysis, quality gates
```

### Data Flow Diagram (Simplified)

```
FILE SYSTEM              CONFIGURATION           EXTERNAL TOOLS
    â”‚                        â”‚                         â”‚
    â”‚                        â”‚                         â”‚
    â”œâ”€ .py files     [pyproject.toml]     [Ruff binary]
    â”œâ”€ .pyi files    [.pylintrc]          [mypy binary]
    â””â”€ Directories   [setup.cfg]          [pylint binary]
                     [ruff.toml]          [bandit binary]
                                          [flake8 binary]
    â”‚                â”‚                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  python_parsers module      â”‚
        â”‚  (10 specialized parsers)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼
   AST Analysis  Tool Output    Configuration
   (Symbols,     Parsing        Objects
    CFG/DFG)     (JSON, text)
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Structured Report Objects   â”‚
        â”‚ (dataclasses with metrics)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚              â”‚
        â–¼             â–¼              â–¼
    Report      JSON/SARIF    Python dicts
    Generator   Export        (asdict)
        â”‚             â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Upstream Consumers        â”‚
        â”‚ (analyzers, reporters, CLI) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Complete Data Flow

```python
# INPUT: Source file
source_code = Path("example.py").read_text()

# PROCESSING: Multiple parsers in parallel
ast_parser = PythonASTParser()
module = ast_parser.parse_file("example.py")

ruff = RuffParser()
ruff_report = ruff.analyze("example.py")

mypy = MypyParser()
mypy_result = mypy.check("example.py")

# TRANSFORMATION: Extract and enrich results
violations = [
    {
        "tool": "ruff",
        "code": v.code,
        "line": v.line,
        "message": v.message,
        "severity": v.severity.value,
    }
    for v in ruff_report.violations
]

# AGGREGATION: Combine results
from dataclasses import asdict
all_results = {
    "ast": {
        "functions": len(module.functions),
        "classes": len(module.classes),
    },
    "ruff": asdict(ruff_report.statistics),
    "mypy": asdict(mypy_result.statistics),
}

# OUTPUT: Export to various formats
import json
json.dump(all_results, open("report.json", "w"))

# or use in reports
from code_scalpel.report_generator import create_report
report = create_report(
    [ruff_report, mypy_result, ast_output],
    format="html"
)
```

## Parser Summary

| Parser | Tool | Purpose | Status | Key Features |
|--------|------|---------|--------|--------------|
| `PythonASTParser` | Built-in `ast` | Core analysis | âœ“ DONE | Symbol extraction, CFG/DFG, scope analysis |
| `RuffParser` | Ruff | Fast linting | âœ“ DONE | 800+ rules, auto-fix, pyproject.toml config |
| `MypyParser` | mypy | Type checking | âœ“ DONE | Type coverage, JSON output, error context |
| `PylintParser` | Pylint | Quality analysis | âœ“ DONE | 200+ messages, scoring, checker grouping |
| `BanditParser` | Bandit | Security | âœ“ DONE | CVE/CWE mapping, SARIF output, profiles |
| `Flake8Parser` | Flake8 | Style checking | âœ“ DONE | Plugin support, noqa handling |
| `CodeQualityParser` | Built-in | Metrics | âœ“ DONE | Cyclomatic/cognitive complexity, LOC |
| `PydocstyleParser` | pydocstyle | Docstrings | âœ“ DONE | Convention support, quality analysis |
| `PycodestyleParser` | pycodestyle | PEP 8 | âœ“ DONE | Style compliance percentage |
| `ProspectorParser` | Prospector | Meta-linter | âœ“ DONE | Profile management, deduplication |
| `IsortParser` | isort | Import sorting | â³ PLANNED | Sorting checks, profile support, multi-line imports |
| `VultureParser` | Vulture | Dead code | â³ PLANNED | Unused detection, confidence filtering, false positive handling |
| `RadonParser` | Radon | Complexity metrics | â³ PLANNED | CC/MI analysis, grading, maintainability scoring |
| `SafetyParser` | Safety | Dependency security | â³ PLANNED | CVE mapping, CVSS scoring, remediation steps |
| `InterrogateParser` | Interrogate | Doc coverage | â³ PLANNED | Coverage percentage, missing docs, style detection |

## Quick Start

### Basic Usage

```python
from code_scalpel.code_parser.python_parsers import (
    PythonASTParser,
    RuffParser,
    MypyParser,
    PylintParser,
)

# AST Analysis
ast_parser = PythonASTParser()
module = ast_parser.parse_file("example.py")
print(f"Functions: {len(module.functions)}")
print(f"Classes: {len(module.classes)}")

# Linting with Ruff (fast!)
ruff = RuffParser()
report = ruff.analyze("example.py")
for violation in report.violations:
    print(f"{violation.code}: {violation.message}")

# Type Checking with mypy
mypy = MypyParser()
result = mypy.check("example.py")
print(f"Type coverage: {result.coverage.coverage_percent:.1f}%")

# Quality Analysis with Pylint
pylint = PylintParser()
report = pylint.analyze("example.py")
print(f"Score: {report.statistics.score}/10")
```

### Configuration

Each parser supports configuration from standard config files:

```python
from code_scalpel.code_parser.python_parsers import (
    RuffConfig,
    MypyConfig,
    PylintConfig,
)

# Load from pyproject.toml
ruff_config = RuffConfig.from_pyproject("pyproject.toml")
mypy_config = MypyConfig.from_pyproject("pyproject.toml")

# Load from tool-specific files
pylint_config = PylintConfig.from_file(".pylintrc")

# Programmatic configuration
ruff_config = RuffConfig(
    select=["E", "F", "W"],
    ignore=["E501"],
    line_length=120,
    target_version="py311",
)
```

## Detailed Parser Documentation

### PythonASTParser - Core Analysis

The foundation parser providing AST-based analysis:

```python
from code_scalpel.code_parser.python_parsers import (
    PythonASTParser,
    PythonModule,
    PythonFunction,
    PythonClass,
)

parser = PythonASTParser()
module = parser.parse_file("example.py")

# Symbol extraction
for func in module.functions:
    print(f"{func.name}({', '.join(func.parameters)})")
    print(f"  Complexity: {func.complexity}")
    print(f"  Is async: {func.is_async}")

# Control Flow Graph
cfg = parser.build_cfg(module)
for block in cfg.basic_blocks:
    print(f"Block {block.id}: {len(block.statements)} statements")

# Data Flow Analysis
dfg = parser.build_dfg(module)
reaching_defs = dfg.get_reaching_definitions("variable_name")
```

### RuffParser - Fast Linting

Rust-based linter with auto-fix capabilities:

```python
from code_scalpel.code_parser.python_parsers import (
    RuffParser,
    RuffConfig,
    RULE_PREFIXES,
)

# See all rule categories
print(RULE_PREFIXES)  # 53 categories

# Analyze with specific rules
config = RuffConfig(
    select=["E", "F", "B", "I"],  # Error, Flake8, Bugbear, isort
    extend_select=["UP"],         # Add pyupgrade
    fixable=["I"],                # Only autofix imports
)
parser = RuffParser(config)
report = parser.analyze("src/")

# Apply auto-fixes programmatically
from code_scalpel.code_parser.python_parsers import apply_fix_to_source

fixed = apply_fix_to_source(source_code, ruff_fix)
print(get_fix_preview(source_code, ruff_fix))  # Unified diff
```

### MypyParser - Type Checking

Static type analysis with coverage metrics:

```python
from code_scalpel.code_parser.python_parsers import (
    MypyParser,
    MypyConfig,
    TYPESHED_SUGGESTIONS,
)

config = MypyConfig(
    strict=True,
    python_version="3.11",
    enable_error_codes=["redundant-expr", "truthy-bool"],
)
parser = MypyParser(config)
result = parser.check("src/")

# Type coverage
print(f"Coverage: {result.coverage.coverage_percent:.1f}%")
print(f"Typed functions: {result.coverage.typed_functions}")
print(f"Untyped functions: {result.coverage.untyped_functions}")

# Missing stub suggestions
for error in result.errors:
    if "library stub" in error.message:
        package = error.extract_package_name()
        if package in TYPESHED_SUGGESTIONS:
            print(f"Install: pip install {TYPESHED_SUGGESTIONS[package]}")
```

### PylintParser - Quality Analysis

Comprehensive code quality with scoring:

```python
from code_scalpel.code_parser.python_parsers import (
    PylintParser,
    PylintConfig,
    MESSAGE_CHECKERS,
    PylintChecker,
)

parser = PylintParser()
report = parser.analyze("src/")

# Score analysis
print(f"Score: {report.statistics.score}/10")
if report.statistics.score_delta:
    print(f"Change: {report.statistics.score_delta:+.2f}")

# Group messages by checker
by_checker = parser.get_messages_by_checker(report.messages)
for checker, messages in by_checker.items():
    print(f"{checker.value}: {len(messages)} issues")

# Get quick wins for score improvement
quick_wins = parser.get_quick_wins(report)
for win in quick_wins[:5]:
    print(f"Fix {win['count']} {win['symbol']} issues ({win['reason']})")

# Score improvement suggestions
suggestions = parser.get_score_improvement_suggestions(report)
for s in suggestions:
    print(f"{s['description']}")
```

### BanditParser - Security Analysis

Security vulnerability detection:

```python
from code_scalpel.code_parser.python_parsers import (
    BanditParser,
    BanditConfig,
    BANDIT_PROFILES,
)

# Use a security profile
config = BanditConfig(
    profile=BANDIT_PROFILES["high_severity"],
    confidence_level="MEDIUM",
)
parser = BanditParser(config)
report = parser.scan("src/")

# Analyze issues
for issue in report.issues:
    print(f"[{issue.severity}] {issue.test_id}: {issue.issue_text}")
    print(f"  CWE: {issue.cwe}")
    print(f"  File: {issue.filename}:{issue.line_number}")

# SARIF output for CI/CD
sarif = parser.to_sarif(report)
```

### CodeQualityParser - Metrics

Complexity and maintainability metrics:

```python
from code_scalpel.code_parser.python_parsers import (
    CodeQualityParser,
    ComplexityMetrics,
)

parser = CodeQualityParser()
metrics = parser.analyze_file("example.py")

# Complexity metrics
for func in metrics.functions:
    print(f"{func.name}:")
    print(f"  Cyclomatic: {func.cyclomatic_complexity}")
    print(f"  Cognitive: {func.cognitive_complexity}")
    print(f"  Nesting depth: {func.max_nesting}")

# Maintainability
print(f"Maintainability Index: {metrics.maintainability_index:.1f}")
print(f"Lines of Code: {metrics.loc}")
print(f"Comment Ratio: {metrics.comment_ratio:.1%}")
```

### ProspectorParser - Meta-Linter

Aggregate multiple tools with profile management:

```python
from code_scalpel.code_parser.python_parsers import (
    ProspectorParser,
    ProspectorConfig,
    ProspectorProfileLoader,
    BUILTIN_PROFILES,
)

# Load custom profile
loader = ProspectorProfileLoader()
profile = loader.load_profile(".prospector.yaml")

# Or use built-in profiles
config = ProspectorConfig(
    profile="django",
    strictness="high",
    with_tool=["pylint", "pyflakes", "mccabe"],
)
parser = ProspectorParser(config)
report = parser.analyze("src/")

# Deduplicate cross-tool messages
unique = parser.deduplicate_messages(report.messages)
print(f"Total: {len(report.messages)}, Unique: {len(unique)}")
```

## Configuration Files

### pyproject.toml Support

Most parsers read from `pyproject.toml`:

```toml
[tool.ruff]
line-length = 120
target-version = "py311"
select = ["E", "F", "W", "B", "I"]

[tool.ruff.lint]
extend-select = ["UP"]

[tool.mypy]
python_version = "3.11"
strict = true
warn_unused_ignores = true

[tool.pylint.messages_control]
disable = ["C0114", "C0115"]

[tool.bandit]
skips = ["B101"]
```

### Tool-Specific Files

| Tool | Config Files |
|------|--------------|
| Ruff | `ruff.toml`, `pyproject.toml` |
| mypy | `mypy.ini`, `setup.cfg`, `pyproject.toml` |
| Pylint | `.pylintrc`, `pylintrc`, `setup.cfg`, `pyproject.toml` |
| Bandit | `.bandit`, `bandit.yaml`, `pyproject.toml` |
| Flake8 | `.flake8`, `setup.cfg`, `tox.ini` |
| pydocstyle | `.pydocstyle`, `setup.cfg`, `tox.ini` |

## Implementation Status

All major features are implemented. See `__init__.py` for the complete TODO roadmap.

### Completed Features âœ…

| Priority | Feature | Status |
|----------|---------|--------|
| P1 | AST parsing, symbol extraction, scope analysis | âœ… Complete |
| P1 | Ruff integration with auto-fix | âœ… Complete |
| P2 | CFG/DFG generation | âœ… Complete |
| P2 | mypy with JSON output, type coverage | âœ… Complete |
| P2 | Pylint with full message parsing | âœ… Complete |
| P2 | Bandit security analysis | âœ… Complete |
| P3 | Complexity metrics (cyclomatic, cognitive) | âœ… Complete |
| P3 | Import analysis and circular detection | âœ… Complete |
| P3 | Flake8 with plugin support | âœ… Complete |
| P3 | pydocstyle with quality analysis | âœ… Complete |
| P4 | pycodestyle PEP 8 checking | âœ… Complete |
| P5 | Prospector with profile management | âœ… Complete |

### Future Development Roadmap

| Priority | Feature | Status |
|----------|---------|--------|
| P4 | Framework detection (Django, Flask, FastAPI) | ðŸ”œ Planned |
| P4 | Pydantic/dataclass analysis | ðŸ”œ Planned |
| P5 | Inter-procedural analysis | ðŸ”œ Planned |
| P5 | Whole-program dead code detection | ðŸ”œ Planned |
| P5 | Refactoring suggestions | ðŸ”œ Planned |
| P5 | Incremental analysis with caching | ðŸ”œ Planned |

## Design Principles

### Consistent Parser Pattern

Every parser follows the same structure:

```python
@dataclass
class ToolConfig:
    """Configuration dataclass with from_file() classmethod."""
    option: str = "default"
    
    @classmethod
    def from_file(cls, path: str) -> "ToolConfig":
        ...
    
    def to_cli_args(self) -> list[str]:
        ...

@dataclass
class ToolResult:
    """Structured result with severity, location, message."""
    code: str
    message: str
    path: str
    line: int
    column: int
    severity: ToolSeverity

@dataclass
class ToolReport:
    """Aggregated results with statistics."""
    results: list[ToolResult]
    statistics: ToolStatistics

class ToolParser:
    """Main parser interface."""
    
    def __init__(self, config: ToolConfig | None = None):
        self.config = config or ToolConfig()
    
    def analyze(self, path: str) -> ToolReport:
        ...
    
    def analyze_string(self, source: str) -> ToolReport:
        ...
```

### Lazy Loading

Imports are lazy-loaded to minimize startup time:

```python
# Only loads when first accessed
from code_scalpel.code_parser.python_parsers import RuffParser
```

### Type Safety

All public APIs are fully typed with Python 3.12 type hints:
- Generic types for collections
- Union types with `|` syntax
- Optional values properly annotated
- TYPE_CHECKING for import-time optimization

## Dependencies

### Required
- Python 3.10+ (3.11+ recommended for `tomllib`)

### Optional (for specific parsers)
- `ruff` - RuffParser
- `mypy` - MypyParser
- `pylint` - PylintParser
- `bandit` - BanditParser
- `flake8` - Flake8Parser
- `pydocstyle` - PydocstyleParser
- `pycodestyle` - PycodestyleParser
- `prospector` - ProspectorParser
- `pyyaml` - ProspectorParser profile loading
- `tomli` - TOML parsing on Python < 3.11

## Testing

Run the parser tests:

```bash
# All parser tests
pytest tests/test_python_parsers/ -v

# Specific parser
pytest tests/test_python_parsers/test_ruff.py -v
pytest tests/test_python_parsers/test_pylint.py -v

# With coverage
pytest tests/test_python_parsers/ --cov=src/code_scalpel/code_parser/python_parsers
```

## Contributing

When adding a new parser:

1. Create `python_parsers_<tool>.py` following the standard pattern
2. Add exports to `__init__.py` in both `__all__` and `__getattr__`
3. Add a TODO section in file header documenting planned features
4. Write comprehensive tests in `tests/test_python_parsers/`
5. Update this README with the new parser documentation
6. Include TODO comments for NotImplementedError methods
7. Document data structures and output formats
8. Provide API design documentation

## Planned Parsers (Future Development)

The following parser stubs have been created for future implementation:

### IsortParser - Import Sorting and Organization

- **Tool**: [isort](https://pycqa.github.io/isort/)
- **Priority**: P2 - HIGH
- **Status**: NOT IMPLEMENTED
- **Purpose**: Validate import ordering and organization
- **Key Features** (Planned):
  - Check import sorting against isort rules
  - Support multiple profiles (black, django, flask, etc.)
  - Identify import categories (stdlib, third-party, local)
  - Detect unsorted imports and multi-line import handling
  - Configuration parsing from setup.cfg/pyproject.toml

**TODO**:
- [ ] P2-ISORT-001: Parse isort output format
- [ ] P2-ISORT-002: Configuration parsing
- [ ] P2-ISORT-003: Import grouping analysis
- [ ] P2-ISORT-004: Sorting correctness checking
- [ ] P2-ISORT-005: Multi-line import handling

### VultureParser - Dead Code Detection

- **Tool**: [Vulture](https://github.com/jendrikseipp/vulture)
- **Priority**: P2 - HIGH
- **Status**: NOT IMPLEMENTED
- **Purpose**: Find unused code and dead branches
- **Key Features** (Planned):
  - Detect unused imports, variables, functions, classes
  - Track confidence levels for findings
  - Support min-confidence filtering
  - Handle __all__ definitions
  - Identify unreachable code

**TODO**:
- [ ] P2-VULTURE-001: Parse Vulture JSON output
- [ ] P2-VULTURE-002: Configuration parsing
- [ ] P2-VULTURE-003: False positive filtering
- [ ] P2-VULTURE-004: Dead code categorization
- [ ] P2-VULTURE-005: Unused import detection

### RadonParser - Code Complexity Metrics

- **Tool**: [Radon](https://radon.readthedocs.io/)
- **Priority**: P2 - HIGH
- **Status**: NOT IMPLEMENTED
- **Purpose**: Measure code complexity with Cyclomatic Complexity and Maintainability Index
- **Key Features** (Planned):
  - Cyclomatic Complexity (CC) analysis
  - Cognitive Complexity analysis
  - Maintainability Index (MI) calculation
  - Complexity grading (A-F)
  - Function and class-level metrics

**TODO**:
- [ ] P2-RADON-001: Parse Radon CC output
- [ ] P2-RADON-002: Parse Radon MI output
- [ ] P2-RADON-003: Cognitive complexity analysis
- [ ] P2-RADON-004: Function and class metrics
- [ ] P2-RADON-005: Complexity grading system

### SafetyParser - Dependency Security Vulnerabilities

- **Tool**: [Safety](https://safety.readthedocs.io/)
- **Priority**: P2 - HIGH
- **Status**: NOT IMPLEMENTED
- **Purpose**: Check dependencies for known security vulnerabilities
- **Key Features** (Planned):
  - Scan dependencies for CVE/CVSS vulnerabilities
  - Map to CVE/CWE identifiers
  - CVSS scoring and severity levels
  - Support requirements.txt and poetry.lock
  - Remediation suggestions
  - Transitive dependency analysis

**TODO**:
- [ ] P2-SAFETY-001: Parse Safety JSON output
- [ ] P2-SAFETY-002: Vulnerability database querying
- [ ] P2-SAFETY-003: CVE/CWE mapping
- [ ] P2-SAFETY-004: Dependency graph analysis
- [ ] P2-SAFETY-005: Remediation suggestion extraction

### InterrogateParser - Documentation Coverage Analysis

- **Tool**: [Interrogate](https://interrogate.readthedocs.io/)
- **Priority**: P3 - MEDIUM
- **Status**: NOT IMPLEMENTED
- **Purpose**: Measure documentation coverage of docstrings
- **Key Features** (Planned):
  - Calculate documentation coverage percentage
  - Identify undocumented functions, classes, methods
  - Detect docstring styles (NumPy, Google, Sphinx, etc.)
  - Module-level and nested documentation tracking
  - Configuration file support

**TODO**:
- [ ] P3-INTERROGATE-001: Parse Interrogate output format
- [ ] P3-INTERROGATE-002: Coverage calculation and reporting
- [ ] P3-INTERROGATE-003: Configuration parsing
- [ ] P3-INTERROGATE-004: Undocumented item identification
- [ ] P3-INTERROGATE-005: Docstring quality analysis

## License

See [LICENSE](../../../../LICENSE) for details.
