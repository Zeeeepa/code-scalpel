# Code Scalpel Agents

**Internal specialized agents for automated code analysis and recommendations**

---

## Overview

This directory contains Code Scalpel's **core analysis agents**. These agents implement the **OODA Loop** pattern (Observe â†’ Orient â†’ Decide â†’ Act) to autonomously analyze code and provide actionable recommendations.

Unlike the integrations in `autonomy/integrations/`, these agents are **Code Scalpel's own implementations** that:
- Extend `BaseCodeAnalysisAgent` (OODA loop framework)
- Use MCP tools for code analysis
- Provide specialized analysis capabilities
- Can be used standalone via MCP protocol
- Can be embedded in external AI frameworks

---

## Agent Types (8 Total)

### Core Agents (Stable - âœ…)

| Agent | Purpose | Key Methods | Status |
|-------|---------|------------|--------|
| **CodeReviewAgent** | Code quality analysis | `analyze_code_quality()`, `suggest_refactorings()` | âœ… Stable |
| **SecurityAgent** | Vulnerability detection | `analyze_security()`, `find_exploits()` | âœ… Stable |
| **OptimizationAgent** | Performance optimization | `analyze_performance()`, `suggest_optimizations()` | âœ… Stable |
| **BaseCodeAnalysisAgent** | OODA loop framework | `execute_ooda_loop()`, `observe()`, `orient()`, `decide()`, `act()` | âœ… Stable |

### New Agents (v3.0.0 - Stub Implementation - ðŸ†•)

| Agent | Purpose | Key Methods | Status |
|-------|---------|------------|--------|
| **RefactoringAgent** | Code restructuring & design patterns | `analyze_structure()`, `detect_pattern_violations()` | ðŸ†• TODO |
| **TestingAgent** | Test generation & coverage analysis | `analyze_coverage()`, `identify_edge_cases()` | ðŸ†• TODO |
| **DocumentationAgent** | Documentation generation | `analyze_docstring_coverage()`, `suggest_api_docs()` | ðŸ†• TODO |
| **MetricsAgent** | Code metrics & analytics | `calculate_complexity_metrics()`, `analyze_coupling()` | ðŸ†• TODO |

---

## OODA Loop Pattern

All agents follow this **observe â†’ orient â†’ decide â†’ act** cycle:

```python
# In BaseCodeAnalysisAgent.execute_ooda_loop():

1. OBSERVE: Gather data
   - observe_file() - Get file structure
   - find_symbol_usage() - Trace usage
   - analyze_code_security() - Check security
   
2. ORIENT: Analyze & classify
   - Run analysis tools (analyzer, security_scan, etc.)
   - Classify issues by severity
   - Prioritize findings
   
3. DECIDE: Plan actions
   - Select recommendations
   - Estimate impact
   - Check safety constraints
   
4. ACT: Apply changes
   - Use MCP tools (simulate_refactor, update_symbol)
   - Verify results
   - Report status
```

---

## Usage Examples

### Standalone (Direct Instantiation)

```python
from code_scalpel.agents import SecurityAgent

agent = SecurityAgent(
    quality_threshold=0.8,
    risk_level="high"
)

# Execute full OODA loop
results = agent.execute_ooda_loop(
    file_path="src/handlers.py",
    max_iterations=3
)

print(results.recommendations)
```

### Via MCP Protocol (Recommended)

```python
# Claude/Copilot calls Code Scalpel MCP server
# Server instantiates agents internally
# Agents perform analysis using MCP tools
```

### Integrated in External Frameworks

```python
# See autonomy/integrations/ for:
# - AutoGen integration
# - CrewAI integration
# - LangGraph integration
```

---

## Agent Configuration

Each agent accepts configuration parameters:

```python
# Common parameters
CodeReviewAgent(
    quality_threshold=0.85,      # Quality target
    risk_level="medium",         # Risk tolerance
    max_iterations=5,            # Max refinement loops
    timeout_seconds=300          # Execution timeout
)

# Agent-specific parameters
SecurityAgent(
    severity_threshold="high",   # Min severity to report
    check_dependencies=True,     # Scan CVEs
    enable_exploit_check=True    # Check exploitability
)

RefactoringAgent(
    preserve_behavior=True,      # Safety constraint
    min_impact_score=0.7,        # Impact threshold
    enable_auto_fix=False        # Manual review required
)
```

---

## Agent Capabilities by Type

### CodeReviewAgent âœ…
- Cyclomatic complexity analysis
- Code duplication detection
- Style enforcement (Black, Ruff)
- Quick fix suggestions
- Code smell detection

**TODOs (5):**
- [ ] Custom metrics plugins
- [ ] Linter integration hooks
- [ ] CI/CD reporting
- [ ] Code smell patterns
- [ ] Style guide enforcement

### SecurityAgent âœ…
- SQL Injection detection
- XSS vulnerability scanning
- Command injection detection
- Dependency CVE scanning
- Taint flow analysis

**TODOs (5):**
- [ ] CVSS scoring
- [ ] Exploit reachability assessment
- [ ] Threat database integration
- [ ] Threat modeling
- [ ] Exploit test generation

### OptimizationAgent âœ…
- Complexity hotspot identification
- Performance pattern suggestions
- Memory profiling hooks
- Bottleneck detection
- Parallelization opportunities

**TODOs (5):**
- [ ] Profiler integration
- [ ] Complexity-aware refactoring
- [ ] Memory leak detection
- [ ] Benchmark integration
- [ ] Parallelization suggestions

### RefactoringAgent ðŸ†•
- Code structure analysis
- Design pattern detection
- Modularization suggestions
- Refactoring impact estimation

**TODOs (6):**
- [ ] Extract method suggestions
- [ ] Extract class patterns
- [ ] Move fields/methods
- [ ] Compose methods
- [ ] Introduce parameter object
- [ ] Replace temp with query

### TestingAgent ðŸ†•
- Test coverage analysis
- Edge case identification
- Integration test suggestions
- Test performance analysis

**TODOs (8):**
- [ ] Unit test generation
- [ ] Edge case exploration
- [ ] Mock suggestion
- [ ] Integration test patterns
- [ ] Performance test generation
- [ ] Mutation testing
- [ ] Coverage gap analysis
- [ ] Test data generation

### DocumentationAgent ðŸ†•
- Docstring coverage analysis
- Type hint suggestions
- API documentation generation
- Example code generation

**TODOs (8):**
- [ ] Auto docstring generation
- [ ] Type hint inference
- [ ] API reference generation
- [ ] Usage example generation
- [ ] Changelog generation
- [ ] README suggestion
- [ ] Doctest generation
- [ ] Documentation linting

### MetricsAgent ðŸ†•
- Code complexity metrics
- Coupling analysis
- Cohesion metrics
- Churn analysis

**TODOs (10):**
- [ ] LCOM calculation
- [ ] DIT analysis
- [ ] Response set metrics
- [ ] Instability metrics
- [ ] Abstractness metrics
- [ ] Code churn tracking
- [ ] Technical debt estimation
- [ ] Maintainability index
- [ ] Architecture metrics
- [ ] Trend analysis

---

## How Agents Use MCP Tools

Agents act as **intelligent wrappers** around MCP tools:

```
Agent.execute_ooda_loop()
    â†“
    OBSERVE: Call MCP tools
    â”œâ”€â”€ get_file_context()        # File structure
    â”œâ”€â”€ get_symbol_references()   # Usage tracking
    â”œâ”€â”€ security_scan()           # Vulnerabilities
    â””â”€â”€ analyze_code()            # Metrics
    
    â†“
    ORIENT: Analyze results
    â”œâ”€â”€ Classify by severity
    â”œâ”€â”€ Filter by threshold
    â””â”€â”€ Prioritize findings
    
    â†“
    DECIDE: Plan changes
    â”œâ”€â”€ simulate_refactor()       # Test change safety
    â””â”€â”€ estimate_impact()         # Calculate effects
    
    â†“
    ACT: Apply changes
    â”œâ”€â”€ extract_code()            # Get target
    â”œâ”€â”€ update_symbol()           # Apply safely
    â””â”€â”€ verify_results()          # Confirm success
```

---

## Best Practices

### When to Use Each Agent

| Task | Agent | Example |
|------|-------|---------|
| Quality assurance | CodeReviewAgent | "Review src/handlers.py for code quality" |
| Security audit | SecurityAgent | "Find security vulnerabilities in app.py" |
| Performance improvement | OptimizationAgent | "Suggest performance optimizations" |
| Code restructuring | RefactoringAgent | "Identify design pattern violations" |
| Test coverage | TestingAgent | "Generate tests for missing coverage" |
| Documentation gaps | DocumentationAgent | "Improve API documentation" |
| Metrics collection | MetricsAgent | "Calculate project complexity metrics" |

### Chaining Agents

For comprehensive analysis, chain multiple agents:

```python
# Phase 1: Find issues
security_results = security_agent.execute_ooda_loop(file)
quality_results = review_agent.execute_ooda_loop(file)

# Phase 2: Plan fixes
refactoring_results = refactoring_agent.execute_ooda_loop(file)

# Phase 3: Verify improvements
testing_results = testing_agent.execute_ooda_loop(file)

# Phase 4: Document changes
doc_results = documentation_agent.execute_ooda_loop(file)
```

### Safety Constraints

All agents respect safety parameters:

```python
agent = SecurityAgent(
    preserve_behavior=True,    # Never change semantics
    max_changes_per_file=10,   # Limit modifications
    require_tests=True,        # Require test coverage
    human_approval=True        # Need approval for breaking changes
)
```

---

## Integration Points

### With MCP Server
Agents are instantiated by `mcp_server.py` when clients request analysis:
```
Claude â†’ MCP Tool Call â†’ mcp_server.py â†’ Agent â†’ Analysis Results
```

### With External Frameworks
See [`autonomy/integrations/`](../autonomy/integrations/) for:
- AutoGen integration
- CrewAI integration  
- LangGraph integration

### With Autonomy Engine
See [`autonomy/engine.py`](../autonomy/engine.py) for orchestration.

---

## File Structure

```
agents/
â”œâ”€â”€ README.md                          [This file]
â”œâ”€â”€ __init__.py                        [Exports all agents]
â”œâ”€â”€ base_agent.py                      [OODA loop framework]
â”œâ”€â”€ code_review_agent.py               [Quality analysis]
â”œâ”€â”€ security_agent.py                  [Vulnerability detection]
â”œâ”€â”€ optimazation_agent.py              [Performance optimization]
â”œâ”€â”€ refactoring_agent.py               [Code restructuring]
â”œâ”€â”€ testing_agent.py                   [Test generation]
â”œâ”€â”€ documentation_agent.py             [Documentation]
â””â”€â”€ metrics_agent.py                   [Code metrics]
```

---

---

## Data Flow

### Input (FROM)
```
MCP Server (mcp_server.py)
    â†“ (agent instantiation)
User Request
    â†“ (file path, options)
Autonomy Engine (autonomy/engine.py)
    â†“ (orchestration signals)
External Frameworks (AutoGen, CrewAI, LangGraph)
```

### Processing (WITHIN)
```
Agent.execute_ooda_loop()
    â†“ (OBSERVE)
MCP Tools (security_scan, analyze_code, get_file_context, etc.)
    â†“ (ORIENT)
Internal Analysis (classify, prioritize findings)
    â†“ (DECIDE)
Decision Engine (plan actions, estimate impact)
    â†“ (ACT)
MCP Tools (simulate_refactor, update_symbol, generate_unit_tests)
```

### Output (TO)
```
Analysis Results
    â”œâ”€ Recommendations (severity-ranked)
    â”œâ”€ Findings (with locations)
    â”œâ”€ Suggested Changes (with impact estimates)
    â””â”€ Safety Assessments (verify before applying)
    â†“
Autonomy Engine
    â†“
External Frameworks
    â†“
User / Claude / Copilot
```

---

## Development Roadmap

### Phase 1: Enhance Stable Agents (44 TODOs)
- **CodeReviewAgent (5 TODOs)**
  - [ ] Custom metrics plugins
  - [ ] Linter integration hooks
  - [ ] CI/CD reporting
  - [ ] Code smell patterns
  - [ ] Style guide enforcement

- **SecurityAgent (5 TODOs)**
  - [ ] CVSS scoring
  - [ ] Exploit reachability assessment
  - [ ] Threat database integration
  - [ ] Threat modeling
  - [ ] Exploit test generation

- **OptimizationAgent (5 TODOs)**
  - [ ] Profiler integration
  - [ ] Complexity-aware refactoring
  - [ ] Memory leak detection
  - [ ] Benchmark integration
  - [ ] Parallelization suggestions

- **BaseAgent (8 TODOs)**
  - [ ] Context persistence across loops
  - [ ] Agent versioning & compatibility
  - [ ] State serialization
  - [ ] Execution loop timeouts
  - [ ] Telemetry & metrics
  - [ ] Circuit breaker pattern
  - [ ] Human approval gates
  - [ ] Decision logging & auditability

### Phase 2: Implement New Agents (32 TODOs)
- **RefactoringAgent (6 TODOs)**
  - [ ] Extract method suggestions
  - [ ] Extract class patterns
  - [ ] Move fields/methods
  - [ ] Introduce parameter object
  - [ ] Compose methods
  - [ ] Replace temp with query

- **TestingAgent (8 TODOs)**
  - [ ] Unit test generation
  - [ ] Edge case exploration
  - [ ] Mock suggestion
  - [ ] Integration test patterns
  - [ ] Performance test generation
  - [ ] Mutation testing
  - [ ] Coverage gap analysis
  - [ ] Test data generation

- **DocumentationAgent (8 TODOs)**
  - [ ] Auto docstring generation
  - [ ] Type hint inference
  - [ ] API reference generation
  - [ ] Usage example generation
  - [ ] Changelog generation
  - [ ] README suggestion
  - [ ] Doctest generation
  - [ ] Documentation linting

- **MetricsAgent (10 TODOs)**
  - [ ] LCOM calculation
  - [ ] DIT analysis
  - [ ] Response set metrics
  - [ ] Instability metrics
  - [ ] Abstractness metrics
  - [ ] Code churn tracking
  - [ ] Technical debt estimation
  - [ ] Maintainability index
  - [ ] Architecture metrics
  - [ ] Trend analysis

### Phase 3: Advanced Features (Future)
- Multi-agent coordination
- Cross-agent data sharing
- Performance optimization loops
- Human-in-the-loop workflows
- Agent capability negotiation
- Error recovery & retry strategies
- Learning from feedback loops

---

## Data Flow

### Single Agent Execution
```
User Request / MCP / Framework
    â†“
Agent.execute_ooda_loop()
    â”œâ”€ OBSERVE: Get code structure
    â”‚  â”œâ”€ read_file()
    â”‚  â”œâ”€ analyze_code()
    â”‚  â””â”€ extract_references()
    â”‚
    â”œâ”€ ORIENT: Interpret findings
    â”‚  â”œâ”€ Pattern matching
    â”‚  â”œâ”€ Risk assessment
    â”‚  â””â”€ Recommendation scoring
    â”‚
    â”œâ”€ DECIDE: Generate recommendations
    â”‚  â”œâ”€ Filter by severity
    â”‚  â”œâ”€ Check policies
    â”‚  â””â”€ Prioritize findings
    â”‚
    â””â”€ ACT: Deliver results
       â”œâ”€ Format output
       â”œâ”€ Attach evidence
       â””â”€ Return to caller
    â†“
Agent Output (Findings + Recommendations)
```

### Multi-Agent Coordination
```
AutonomyEngine Request
    â†“
Policy Engine: Determine required agents
    â”œâ”€ SecurityAgent
    â”œâ”€ CodeReviewAgent
    â”œâ”€ OptimizationAgent
    â””â”€ Other agents...
    â†“
Sequential/Parallel Execution
    â”œâ”€ Each agent executes OODA loop
    â”œâ”€ Results cached for other agents
    â””â”€ Cross-agent data sharing
    â†“
Result Synthesis
    â”œâ”€ Aggregate findings
    â”œâ”€ Resolve conflicts
    â””â”€ Apply policies
    â†“
Final Report
```

---

## Development Roadmap

### Phase 1: Stub Completion (In Progress ðŸ”„)

#### RefactoringAgent (12 TODOs)
- [ ] Method extraction detection
- [ ] Parameter object suggestions
- [ ] Duplicate code detection
- [ ] Design pattern violation detection
- [ ] Replace magic numbers
- [ ] Extract method suggestions
- [ ] Extract class patterns
- [ ] Move fields/methods
- [ ] Introduce parameter object
- [ ] Compose methods
- [ ] Replace temp with query
- [ ] Decompose conditional

#### TestingAgent (10 TODOs)
- [ ] Unit test generation
- [ ] Edge case exploration (symbolic execution)
- [ ] Mock suggestion
- [ ] Integration test patterns
- [ ] Performance test generation
- [ ] Mutation testing
- [ ] Coverage gap analysis
- [ ] Test data generation
- [ ] Parameterized test suggestions
- [ ] Test documentation generation

#### DocumentationAgent (10 TODOs)
- [ ] Auto docstring generation
- [ ] Type hint inference
- [ ] API reference generation
- [ ] Usage example generation
- [ ] Changelog generation
- [ ] README suggestion
- [ ] Doctest generation
- [ ] Documentation linting
- [ ] API deprecation documentation
- [ ] Architecture decision documentation

#### MetricsAgent (12 TODOs)
- [ ] LCOM (Lack of Cohesion of Methods)
- [ ] DIT (Depth of Inheritance Tree)
- [ ] Response set metrics
- [ ] Instability metrics
- [ ] Abstractness metrics
- [ ] Code churn tracking
- [ ] Technical debt estimation
- [ ] Maintainability index
- [ ] Architecture metrics
- [ ] Trend analysis
- [ ] Hotspot identification
- [ ] Complexity distribution

### Phase 2: Enhanced Capabilities (Planned)

#### Agent Enhancements (15 TODOs)
- [ ] Caching for repeated analysis
- [ ] Incremental analysis (only changed files)
- [ ] Parallel code analysis
- [ ] Result streaming
- [ ] Progress reporting
- [ ] Cancellation support
- [ ] Timeout handling
- [ ] Memory optimization
- [ ] Batch processing
- [ ] Result filtering
- [ ] Evidence attachment
- [ ] Confidence scoring
- [ ] Explanation generation
- [ ] Interactive mode
- [ ] Custom rule definitions

#### Coordination Framework (14 TODOs)
- [ ] Agent dependency graphs
- [ ] Data sharing between agents
- [ ] Result aggregation
- [ ] Conflict resolution
- [ ] Cross-agent communication
- [ ] Shared cache mechanism
- [ ] Agent capability negotiation
- [ ] Dynamic agent selection
- [ ] Feedback loops
- [ ] Learning from corrections
- [ ] Agent performance tracking
- [ ] Optimization suggestions
- [ ] Team composition optimization
- [ ] Delegation patterns

### Phase 3: Intelligence & Learning (Future)

#### Intelligent Analysis (12 TODOs)
- [ ] Machine learning for priority scoring
- [ ] Anomaly detection in code patterns
- [ ] Auto-tuning of thresholds
- [ ] Context-aware recommendations
- [ ] User preference learning
- [ ] False positive reduction
- [ ] Trend prediction
- [ ] Risk forecasting
- [ ] Impact simulation
- [ ] Root cause analysis
- [ ] Holistic code health scoring
- [ ] AI-guided refactoring

#### Advanced Workflows (10 TODOs)
- [ ] Automated refactoring application
- [ ] Continuous monitoring mode
- [ ] Scheduled analysis runs
- [ ] Change impact analysis
- [ ] Regression test generation
- [ ] Deployment risk assessment
- [ ] A/B testing support
- [ ] Feature flag analysis
- [ ] Security compliance checking
- [ ] Performance SLA enforcement

---

**Last Updated:** December 21, 2025  
**Version:** v3.0.0 - Autonomy Release  
**Status:** 4 Stable âœ… + 4 Stubs ðŸ†• (Total TODOs: 81)
